current work directory:  /home/imsuhan22/few-shot-tc/JointMatch_SSL/codebert/code

data_path:  ../data/../data_split(java)

There are 1 GPU(s) available.
We will use the GPU- 0 NVIDIA GeForce RTX 3090
n_labeled_per_class:  1
train_df samples: 3911
train_labeled_df samples: 7
train_unlabeled_df samples: 3904
n_classes:  7
line 147 모델 =>  microsoft/codebert-base
net_arch:  microsoft/codebert-base lr:  1e-05

line 257 => epoch 0
line 303 => train data수 7
line 258 => 인스턴스 수 1
=======test_loader=======
=======dev_loader=======
=======train_labeled_loader=======
=======finish=======
>>Epoch 0 Step 0 acc_test 0.124744 f1_test 0.040804 acc_val 0.122699 f1_val 0.034861 acc_train 0.142857 f1_train 0.035714 psl_cor 0 psl_totl 0 pslt_global 0.000000  Tim 0:00:22
acc_train_cw [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_eval:  [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0]
psl_acc: None cw_psl_acc:  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/test/output/
line 681 - total_unsup_loss_nets [tensor(0., device='cuda:0')]

tokenizer BertTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={
	0: AddedToken("[PAD]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	100: AddedToken("[UNK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	101: AddedToken("[CLS]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	102: AddedToken("[SEP]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	103: AddedToken("[MASK]", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
} 


line 257 => epoch 1
line 303 => train data수 7
line 258 => 인스턴스 수 1
=======test_loader=======
=======dev_loader=======
=======train_labeled_loader=======
=======finish=======
>>Epoch 1 Step 1 acc_test 0.120654 f1_test 0.034359 acc_val 0.120654 f1_val 0.030817 acc_train 0.142857 f1_train 0.035714 psl_cor 0 psl_totl 0 pslt_global 0.700000  Tim 0:01:25
acc_train_cw [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_eval:  [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0]
psl_acc: None cw_psl_acc:  [nan, nan, nan, nan, nan, nan, nan]
line 681 - total_unsup_loss_nets [tensor(0., device='cuda:0')]

line 257 => epoch 2
line 303 => train data수 7
line 258 => 인스턴스 수 1
=======test_loader=======
=======dev_loader=======
=======train_labeled_loader=======
=======finish=======
>>Epoch 2 Step 2 acc_test 0.120654 f1_test 0.034344 acc_val 0.120654 f1_val 0.030817 acc_train 0.142857 f1_train 0.035714 psl_cor 0 psl_totl 0 pslt_global 0.700000  Tim 0:02:13
acc_train_cw [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_eval:  [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0]
psl_acc: None cw_psl_acc:  [nan, nan, nan, nan, nan, nan, nan]
line 681 - total_unsup_loss_nets [tensor(0., device='cuda:0')]

line 257 => epoch 3
line 303 => train data수 7
line 258 => 인스턴스 수 1
=======test_loader=======
=======dev_loader=======
=======train_labeled_loader=======
=======finish=======
>>Epoch 3 Step 3 acc_test 0.122699 f1_test 0.034846 acc_val 0.120654 f1_val 0.030817 acc_train 0.142857 f1_train 0.035714 psl_cor 0 psl_totl 0 pslt_global 0.700000  Tim 0:03:15
acc_train_cw [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_eval:  [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0]
psl_acc: None cw_psl_acc:  [nan, nan, nan, nan, nan, nan, nan]
line 681 - total_unsup_loss_nets [tensor(0., device='cuda:0')]

line 257 => epoch 4
line 303 => train data수 7
line 258 => 인스턴스 수 1
=======test_loader=======
=======dev_loader=======
=======train_labeled_loader=======
=======finish=======
>>Epoch 4 Step 4 acc_test 0.122699 f1_test 0.034846 acc_val 0.120654 f1_val 0.030817 acc_train 0.285714 f1_train 0.183673 psl_cor 0 psl_totl 0 pslt_global 0.700000  Tim 0:04:15
acc_train_cw [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]
cw_psl_eval:  [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0]
psl_acc: None cw_psl_acc:  [nan, nan, nan, nan, nan, nan, nan]
line 681 - total_unsup_loss_nets [tensor(0., device='cuda:0')]

line 257 => epoch 5
line 303 => train data수 7
line 258 => 인스턴스 수 1
=======test_loader=======
=======dev_loader=======
=======train_labeled_loader=======
=======finish=======
>>Epoch 5 Step 5 acc_test 0.122699 f1_test 0.031513 acc_val 0.120654 f1_val 0.030761 acc_train 0.285714 f1_train 0.183673 psl_cor 0 psl_totl 0 pslt_global 0.700000  Tim 0:05:03
acc_train_cw [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]
cw_psl_eval:  [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0]
psl_acc: None cw_psl_acc:  [nan, nan, nan, nan, nan, nan, nan]
line 681 - total_unsup_loss_nets [tensor(0., device='cuda:0')]

line 257 => epoch 6
line 303 => train data수 7
line 258 => 인스턴스 수 1
=======test_loader=======
=======dev_loader=======
=======train_labeled_loader=======
=======finish=======
>>Epoch 6 Step 6 acc_test 0.122699 f1_test 0.031513 acc_val 0.120654 f1_val 0.030761 acc_train 0.285714 f1_train 0.183673 psl_cor 0 psl_totl 0 pslt_global 0.700000  Tim 0:06:07
acc_train_cw [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]
cw_psl_eval:  [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0]
psl_acc: None cw_psl_acc:  [nan, nan, nan, nan, nan, nan, nan]
line 681 - total_unsup_loss_nets [tensor(0., device='cuda:0')]

line 257 => epoch 7
line 303 => train data수 7
line 258 => 인스턴스 수 1
=======test_loader=======
=======dev_loader=======
=======train_labeled_loader=======
=======finish=======
>>Epoch 7 Step 7 acc_test 0.122699 f1_test 0.031397 acc_val 0.120654 f1_val 0.030761 acc_train 0.285714 f1_train 0.183673 psl_cor 0 psl_totl 0 pslt_global 0.700000  Tim 0:07:04
acc_train_cw [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]
cw_psl_eval:  [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0]
psl_acc: None cw_psl_acc:  [nan, nan, nan, nan, nan, nan, nan]
line 681 - total_unsup_loss_nets [tensor(0., device='cuda:0')]

line 257 => epoch 8
line 303 => train data수 7
line 258 => 인스턴스 수 1
=======test_loader=======
=======dev_loader=======
=======train_labeled_loader=======
=======finish=======
>>Epoch 8 Step 8 acc_test 0.122699 f1_test 0.031340 acc_val 0.120654 f1_val 0.030761 acc_train 0.285714 f1_train 0.183673 psl_cor 0 psl_totl 0 pslt_global 0.700000  Tim 0:07:50
acc_train_cw [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]
cw_psl_eval:  [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0]
psl_acc: None cw_psl_acc:  [nan, nan, nan, nan, nan, nan, nan]
line 681 - total_unsup_loss_nets [tensor(0., device='cuda:0')]

line 257 => epoch 9
line 303 => train data수 7
line 258 => 인스턴스 수 1
=======test_loader=======
=======dev_loader=======
=======train_labeled_loader=======
=======finish=======
>>Epoch 9 Step 9 acc_test 0.122699 f1_test 0.031283 acc_val 0.120654 f1_val 0.030761 acc_train 0.285714 f1_train 0.183673 psl_cor 0 psl_totl 0 pslt_global 0.700000  Tim 0:08:49
acc_train_cw [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]
cw_psl_eval:  [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0]
psl_acc: None cw_psl_acc:  [nan, nan, nan, nan, nan, nan, nan]
line 681 - total_unsup_loss_nets [tensor(0., device='cuda:0')]

line 257 => epoch 10
line 303 => train data수 7
line 258 => 인스턴스 수 1
=======test_loader=======
=======dev_loader=======
=======train_labeled_loader=======
=======finish=======
>>Epoch 10 Step 10 acc_test 0.124744 f1_test 0.035099 acc_val 0.122699 f1_val 0.034577 acc_train 0.428571 f1_train 0.333333 psl_cor 0 psl_totl 0 pslt_global 0.700000  Tim 0:09:48
acc_train_cw [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]
cw_psl_eval:  [0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0]
psl_acc: None cw_psl_acc:  [nan, nan, nan, nan, nan, nan, nan]
Early stopping trigger at step:  10
Best model at step:  0
**조기종료됨**
line 681 - total_unsup_loss_nets [tensor(0., device='cuda:0')]
종료된 epoch시점 :  11 (epoch - 11에서부터 acc_val증가 안됨.)
조기종료 early_stop_flag 

Training complete!
Total training took 0:10:19 (h:mm:ss)
