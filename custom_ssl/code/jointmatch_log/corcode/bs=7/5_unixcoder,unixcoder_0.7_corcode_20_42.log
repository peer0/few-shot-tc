current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code

bs for corcod =>  7
Data set -> jointmatch
save_name: 5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'corcode'}

data_path:  ../data/jointmatch/corcode

There are 1 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base']
**tokenizer type =  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base'] 

n_labeled_per_class:  5
train_df samples: 739
train_labeled_df samples: 25
train_unlabeled_df samples: 714
Check n_smaples_per_class in the original training set:  OrderedDict([(1, 121), (2, 44), (3, 306), (4, 114), (5, 154)])
Check n_smaples_per_class in the labeled training set:  OrderedDict([(1, 5), (2, 5), (3, 5), (4, 5), (5, 5)])
Check n_smaples_per_class in the unlabeled training set:  OrderedDict([(1, 116), (2, 39), (3, 301), (4, 109), (5, 149)])
n_classes:  5

net_arch:  microsoft/unixcoder-base 
lr:  0.0004 
lr_linear:  0.001 


net_arch:  microsoft/unixcoder-base 
lr:  0.0002 
lr_linear:  0.001 

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 679]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 142]
psl_acc(PSL 평가에서의 정확도):  0.209 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.20913107693195343]
loss for labeled data =>  tensor(3.6400, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8844, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 3, Time: 0:02:01
Train F1: 0.0667, Val F1: 0.0787, Test F1: 0.0752
Epoch 1/20, Train Acc: 0.2000, Val Acc: 0.2449, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 714, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 39, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.055 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.054621849209070206, nan, nan, nan]
loss for labeled data =>  tensor(0.2263, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.1139, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 6, Time: 0:03:38
Train F1: 0.0667, Val F1: 0.0231, Test F1: 0.0200
Epoch 2/20, Train Acc: 0.2000, Val Acc: 0.0612, Test Acc: 0.0526, Test F1(macro): 0.0200, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 697, 0, 3]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 294, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.42 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.42180773615837097, nan, 0.0]
loss for labeled data =>  tensor(5.2742, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.9689, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 9, Time: 0:05:37
Train F1: 0.0667, Val F1: 0.1239, Test F1: 0.1054
Epoch 3/20, Train Acc: 0.2000, Val Acc: 0.4490, Test Acc: 0.3579, Test F1(macro): 0.1054, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 689]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 139]
psl_acc(PSL 평가에서의 정확도):  0.202 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.20174165070056915]
loss for labeled data =>  tensor(4.7319, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8945, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 12, Time: 0:07:18
Train F1: 0.0667, Val F1: 0.0787, Test F1: 0.0752
Epoch 4/20, Train Acc: 0.2000, Val Acc: 0.2449, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 713]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 149]
psl_acc(PSL 평가에서의 정확도):  0.209 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.2089761644601822]
loss for labeled data =>  tensor(11.3501, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(5.0405, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 15, Time: 0:09:00
Train F1: 0.0667, Val F1: 0.0787, Test F1: 0.0752
Epoch 5/20, Train Acc: 0.2000, Val Acc: 0.2449, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 648, 0, 0, 14]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 37, 0, 0, 2]
psl_acc(PSL 평가에서의 정확도):  0.059 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.057098764926195145, nan, nan, 0.1428571492433548]
loss for labeled data =>  tensor(4.9748, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(9.8149, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 18, Time: 0:10:38
Train F1: 0.0667, Val F1: 0.0231, Test F1: 0.0200
Epoch 6/20, Train Acc: 0.2000, Val Acc: 0.0612, Test Acc: 0.0526, Test F1(macro): 0.0200, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [28, 10, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [2, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.053 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.0714285746216774, 0.0, nan, nan, nan]
loss for labeled data =>  tensor(4.6396, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(6.7286, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 21, Time: 0:12:15
Train F1: 0.0667, Val F1: 0.0370, Test F1: 0.0449
Epoch 7/20, Train Acc: 0.2000, Val Acc: 0.1020, Test Acc: 0.1263, Test F1(macro): 0.0449, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [1, 0, 0, 612, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 89, 0]
psl_acc(PSL 평가에서의 정확도):  0.145 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.0, nan, nan, 0.14542484283447266, nan]
loss for labeled data =>  tensor(0.2635, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.5958, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 24, Time: 0:13:55
Train F1: 0.0667, Val F1: 0.0500, Test F1: 0.0752
Epoch 8/20, Train Acc: 0.2000, Val Acc: 0.1429, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 435, 14, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 196, 1, 0]
psl_acc(PSL 평가에서의 정확도):  0.439 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.45057472586631775, 0.0714285746216774, nan]
loss for labeled data =>  tensor(5.1068, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(5.7716, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 27, Time: 0:15:36
Train F1: 0.0667, Val F1: 0.1239, Test F1: 0.1054
Epoch 9/20, Train Acc: 0.2000, Val Acc: 0.4490, Test Acc: 0.3579, Test F1(macro): 0.1054, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 4, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 682, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 286, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.419 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.4193548262119293, nan, nan]
loss for labeled data =>  tensor(0.0974, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 30, Time: 0:17:16
Train F1: 0.0667, Val F1: 0.1239, Test F1: 0.1054
Epoch 10/20, Train Acc: 0.2000, Val Acc: 0.4490, Test Acc: 0.3579, Test F1(macro): 0.1054, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [373, 0, 16, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [64, 0, 7, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.183 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.17158177495002747, nan, 0.4375, nan, nan]
loss for labeled data =>  tensor(4.9325, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.7998, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 33, Time: 0:18:53
Train F1: 0.0667, Val F1: 0.0370, Test F1: 0.0449
Epoch 11/20, Train Acc: 0.2000, Val Acc: 0.1020, Test Acc: 0.1263, Test F1(macro): 0.0449, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [11, 0, 0, 469, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [1, 0, 0, 67, 0]
psl_acc(PSL 평가에서의 정확도):  0.142 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.09090909361839294, nan, nan, 0.1428571492433548, nan]
loss for labeled data =>  tensor(4.5953, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.9583, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 36, Time: 0:20:33
Train F1: 0.0667, Val F1: 0.0500, Test F1: 0.0752
Epoch 12/20, Train Acc: 0.2000, Val Acc: 0.1429, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 14, 563]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 1, 120]
psl_acc(PSL 평가에서의 정확도):  0.21 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.0714285746216774, 0.21314387023448944]
loss for labeled data =>  tensor(4.2831, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.4080, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 39, Time: 0:22:12
Train F1: 0.0667, Val F1: 0.0787, Test F1: 0.0752
Epoch 13/20, Train Acc: 0.2000, Val Acc: 0.2449, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 7, 14]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 2, 5]
psl_acc(PSL 평가에서의 정확도):  0.333 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.2857142984867096, 0.3571428656578064]
loss for labeled data =>  tensor(5.1880, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.6919, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 42, Time: 0:23:52
Train F1: 0.0667, Val F1: 0.0500, Test F1: 0.0752
Epoch 14/20, Train Acc: 0.2000, Val Acc: 0.1429, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 2, Correct Pseudo-Labels: 1, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 672, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 37, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.055 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.0550595223903656, nan, nan, nan]
loss for labeled data =>  tensor(2.5949, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.2396, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 45, Time: 0:25:32
Train F1: 0.0667, Val F1: 0.0231, Test F1: 0.0200
Epoch 15/20, Train Acc: 0.2000, Val Acc: 0.0612, Test Acc: 0.0526, Test F1(macro): 0.0200, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 683, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 37, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.054 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.05417276546359062, nan, nan, nan]
loss for labeled data =>  tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 48, Time: 0:27:10
Train F1: 0.0667, Val F1: 0.0231, Test F1: 0.0200
Epoch 16/20, Train Acc: 0.2000, Val Acc: 0.0612, Test Acc: 0.0526, Test F1(macro): 0.0200, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 21, 0, 0, 564]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 3, 0, 0, 121]
psl_acc(PSL 평가에서의 정확도):  0.212 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1428571492433548, nan, nan, 0.21453900635242462]
loss for labeled data =>  tensor(5.0100, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.1411, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 51, Time: 0:28:50
Train F1: 0.0667, Val F1: 0.0787, Test F1: 0.0752
Epoch 17/20, Train Acc: 0.2000, Val Acc: 0.2449, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 681]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 142]
psl_acc(PSL 평가에서의 정확도):  0.209 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.20851688086986542]
loss for labeled data =>  tensor(0.0649, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.0362, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 54, Time: 0:30:31
Train F1: 0.0667, Val F1: 0.0787, Test F1: 0.0752
Epoch 18/20, Train Acc: 0.2000, Val Acc: 0.2449, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 570, 23]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 86, 10]
psl_acc(PSL 평가에서의 정확도):  0.162 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.1508771926164627, 0.43478259444236755]
loss for labeled data =>  tensor(5.2147, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.2680, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 57, Time: 0:32:12
Train F1: 0.0667, Val F1: 0.0500, Test F1: 0.0752
Epoch 19/20, Train Acc: 0.2000, Val Acc: 0.1429, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1, Train Data Number: 25

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 636, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 99, 0]
psl_acc(PSL 평가에서의 정확도):  0.156 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.15566037595272064, nan]
loss for labeled data =>  tensor(4.5093, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(5.0803, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 60, Time: 0:33:52
Train F1: 0.0667, Val F1: 0.0500, Test F1: 0.0752
Epoch 20/20, Train Acc: 0.2000, Val Acc: 0.1429, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0, Train Data Number: 25


Training complete!
Total training took 0:33:52 (h:mm:ss)
Load model from ./experiment/jointmatch/output/5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'corcode'}_net0.pth
Load model from ./experiment/jointmatch/output/5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'corcode'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/unixcoder/joint_match//5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'corcode'}/training_statistics.csv


Best_step:  9 
Best_val_epoch:  3 
best_val_acc:  0.4489795918367347 
best_val_test_acc:  0.35789473684210527 
best_val_test_f1:  0.1054263565891473
Save best record in:  ./experiment/jointmatch/log/unixcoder/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
