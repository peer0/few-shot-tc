current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code

bs for corcod =>  5
Data set -> jointmatch
save_name: 10_['codet5p', 'codet5p']_[2e-05, 3e-05]_0.7_jointmatch_20_[43]_{'corcode'}

data_path:  ../data/jointmatch/corcode

There are 1 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding']
**tokenizer type =  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding'] 

n_labeled_per_class:  10
train_df samples: 739
train_labeled_df samples: 50
train_unlabeled_df samples: 689
Check n_smaples_per_class in the original training set:  OrderedDict([(1, 121), (2, 44), (3, 306), (4, 114), (5, 154)])
Check n_smaples_per_class in the labeled training set:  OrderedDict([(1, 10), (2, 10), (3, 10), (4, 10), (5, 10)])
Check n_smaples_per_class in the unlabeled training set:  OrderedDict([(1, 111), (2, 34), (3, 296), (4, 104), (5, 144)])
n_classes:  5

net_arch:  Salesforce/codet5p-110m-embedding 
lr:  2e-05 
lr_linear:  0.001 


net_arch:  Salesforce/codet5p-110m-embedding 
lr:  3e-05 
lr_linear:  0.001 

**pseudo_label ->  [0.2125, 0.1927, 0.1948, 0.1971, 0.2029] **
max =  0.2125 | max_idx =  0
**pseudo_label ->  [0.2155, 0.1911, 0.1895, 0.2006, 0.2033] **
max =  0.2155 | max_idx =  0
**pseudo_label ->  [0.1953, 0.1937, 0.2059, 0.1956, 0.2095] **
max =  0.2095 | max_idx =  4
**pseudo_label ->  [0.2181, 0.1938, 0.1891, 0.2003, 0.1988] **
max =  0.2181 | max_idx =  0
**pseudo_label ->  [0.2031, 0.1902, 0.2041, 0.198, 0.2048] **
max =  0.2048 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 0.7, 0.4, 0.5, 0.3]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.6160, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.6099, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 10, Time: 0:01:45
Train F1: 0.5877, Val F1: 0.2271, Test F1: 0.3326
Epoch 1/20, Train Acc: 0.5800, Val Acc: 0.2245, Test Acc: 0.3263, Test F1(macro): 0.3326, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.2276, 0.1817, 0.193, 0.1997, 0.198] **
max =  0.2276 | max_idx =  0
**pseudo_label ->  [0.1828, 0.1911, 0.1961, 0.205, 0.2249] **
max =  0.2249 | max_idx =  4
**pseudo_label ->  [0.1843, 0.1881, 0.21, 0.2079, 0.2097] **
max =  0.21 | max_idx =  2
**pseudo_label ->  [0.1743, 0.2019, 0.2091, 0.2078, 0.207] **
max =  0.2091 | max_idx =  2
**pseudo_label ->  [0.1851, 0.1884, 0.2026, 0.2001, 0.2238] **
max =  0.2238 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.7, 0.7, 0.2, 0.1, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.5284, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.5113, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 20, Time: 0:03:47
Train F1: 0.5185, Val F1: 0.3043, Test F1: 0.2537
Epoch 2/20, Train Acc: 0.5400, Val Acc: 0.3367, Test Acc: 0.2947, Test F1(macro): 0.2537, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1716, 0.1697, 0.2094, 0.2076, 0.2418] **
max =  0.2418 | max_idx =  4
**pseudo_label ->  [0.218, 0.1637, 0.2015, 0.2017, 0.2151] **
max =  0.218 | max_idx =  0
**pseudo_label ->  [0.1777, 0.2005, 0.1998, 0.2035, 0.2186] **
max =  0.2186 | max_idx =  4
**pseudo_label ->  [0.2264, 0.2201, 0.1837, 0.1925, 0.1773] **
max =  0.2264 | max_idx =  0
**pseudo_label ->  [0.2212, 0.1582, 0.2096, 0.2135, 0.1975] **
max =  0.2212 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [0.9, 0.8, 0.6, 0.9, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3848, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3889, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 30, Time: 0:05:49
Train F1: 0.8368, Val F1: 0.4111, Test F1: 0.4189
Epoch 3/20, Train Acc: 0.8400, Val Acc: 0.3673, Test Acc: 0.3789, Test F1(macro): 0.4189, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1965, 0.1523, 0.2065, 0.2108, 0.2339] **
max =  0.2339 | max_idx =  4
**pseudo_label ->  [0.187, 0.1797, 0.2111, 0.1905, 0.2316] **
max =  0.2316 | max_idx =  4
**pseudo_label ->  [0.2792, 0.1721, 0.2036, 0.1611, 0.184] **
max =  0.2792 | max_idx =  0
**pseudo_label ->  [0.1595, 0.1825, 0.1854, 0.2374, 0.2352] **
max =  0.2374 | max_idx =  3
**pseudo_label ->  [0.2183, 0.1697, 0.2279, 0.196, 0.1881] **
max =  0.2279 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [1.0, 0.9, 0.6, 0.9, 0.9]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2959, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2982, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 40, Time: 0:07:34
Train F1: 0.8604, Val F1: 0.2794, Test F1: 0.3557
Epoch 4/20, Train Acc: 0.8600, Val Acc: 0.2551, Test Acc: 0.3158, Test F1(macro): 0.3557, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1512, 0.1702, 0.2178, 0.229, 0.2318] **
max =  0.2318 | max_idx =  4
**pseudo_label ->  [0.1732, 0.1499, 0.2044, 0.2525, 0.22] **
max =  0.2525 | max_idx =  3
**pseudo_label ->  [0.2805, 0.2031, 0.1959, 0.1687, 0.1518] **
max =  0.2805 | max_idx =  0
**pseudo_label ->  [0.1502, 0.2651, 0.1916, 0.1976, 0.1954] **
max =  0.2651 | max_idx =  1
**pseudo_label ->  [0.1895, 0.1555, 0.2665, 0.1912, 0.1974] **
max =  0.2665 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [1.0, 0.7, 0.0, 0.8, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2600, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2248, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 50, Time: 0:09:16
Train F1: 0.5758, Val F1: 0.1936, Test F1: 0.2803
Epoch 5/20, Train Acc: 0.6000, Val Acc: 0.1531, Test Acc: 0.2421, Test F1(macro): 0.2803, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1375, 0.1962, 0.1771, 0.2281, 0.2612] **
max =  0.2612 | max_idx =  4
**pseudo_label ->  [0.1558, 0.167, 0.2446, 0.1971, 0.2355] **
max =  0.2446 | max_idx =  2
**pseudo_label ->  [0.1418, 0.2581, 0.1992, 0.1775, 0.2235] **
max =  0.2581 | max_idx =  1
**pseudo_label ->  [0.1534, 0.2854, 0.1588, 0.1967, 0.2057] **
max =  0.2854 | max_idx =  1
**pseudo_label ->  [0.1813, 0.1939, 0.2786, 0.1659, 0.1803] **
max =  0.2786 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.2, 0.9, 0.9]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2172, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1711, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 60, Time: 0:11:01
Train F1: 0.7641, Val F1: 0.2752, Test F1: 0.2923
Epoch 6/20, Train Acc: 0.8000, Val Acc: 0.2755, Test Acc: 0.3158, Test F1(macro): 0.2923, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.2348, 0.1936, 0.1657, 0.1633, 0.2425] **
max =  0.2425 | max_idx =  4
**pseudo_label ->  [0.1865, 0.2287, 0.2652, 0.1641, 0.1556] **
max =  0.2652 | max_idx =  2
**pseudo_label ->  [0.2146, 0.1973, 0.2526, 0.189, 0.1465] **
max =  0.2526 | max_idx =  2
**pseudo_label ->  [0.2975, 0.1888, 0.1678, 0.192, 0.154] **
max =  0.2975 | max_idx =  0
**pseudo_label ->  [0.2611, 0.1912, 0.1783, 0.1715, 0.1979] **
max =  0.2611 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.2, 0.7, 0.1]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1697, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1715, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 70, Time: 0:12:46
Train F1: 0.5356, Val F1: 0.1088, Test F1: 0.1535
Epoch 7/20, Train Acc: 0.6000, Val Acc: 0.1531, Test Acc: 0.1895, Test F1(macro): 0.1535, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1921, 0.1385, 0.2459, 0.2044, 0.219] **
max =  0.2459 | max_idx =  2
**pseudo_label ->  [0.1539, 0.2871, 0.1646, 0.195, 0.1994] **
max =  0.2871 | max_idx =  1
**pseudo_label ->  [0.1664, 0.1436, 0.2246, 0.181, 0.2844] **
max =  0.2844 | max_idx =  4
**pseudo_label ->  [0.3097, 0.1367, 0.1784, 0.1968, 0.1784] **
max =  0.3097 | max_idx =  0
**pseudo_label ->  [0.2645, 0.1285, 0.2399, 0.161, 0.2061] **
max =  0.2645 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [0.8, 0.7, 0.8, 0.9, 0.9]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1758, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1428, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 80, Time: 0:14:29
Train F1: 0.8337, Val F1: 0.3236, Test F1: 0.3765
Epoch 8/20, Train Acc: 0.8200, Val Acc: 0.3061, Test Acc: 0.3789, Test F1(macro): 0.3765, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1662, 0.1505, 0.225, 0.1571, 0.3012] **
max =  0.3012 | max_idx =  4
**pseudo_label ->  [0.1767, 0.1628, 0.3041, 0.1485, 0.208] **
max =  0.3041 | max_idx =  2
**pseudo_label ->  [0.1582, 0.1601, 0.2781, 0.1548, 0.2487] **
max =  0.2781 | max_idx =  2
**pseudo_label ->  [0.2295, 0.1527, 0.1846, 0.1586, 0.2746] **
max =  0.2746 | max_idx =  4
**pseudo_label ->  [0.1612, 0.3143, 0.1562, 0.184, 0.1843] **
max =  0.3143 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.5, 0.9, 0.7]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1243, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1839, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 90, Time: 0:16:10
Train F1: 0.8208, Val F1: 0.1600, Test F1: 0.2869
Epoch 9/20, Train Acc: 0.8200, Val Acc: 0.1633, Test Acc: 0.2947, Test F1(macro): 0.2869, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1911, 0.17, 0.2862, 0.1634, 0.1892] **
max =  0.2862 | max_idx =  2
**pseudo_label ->  [0.1768, 0.2833, 0.223, 0.148, 0.1688] **
max =  0.2833 | max_idx =  1
**pseudo_label ->  [0.3344, 0.1652, 0.1843, 0.1602, 0.1558] **
max =  0.3344 | max_idx =  0
**pseudo_label ->  [0.3057, 0.1594, 0.2252, 0.1428, 0.1669] **
max =  0.3057 | max_idx =  0
**pseudo_label ->  [0.1694, 0.1673, 0.2064, 0.155, 0.3019] **
max =  0.3019 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 0.9, 0.8, 0.9, 0.9]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1237, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1228, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 100, Time: 0:17:54
Train F1: 0.9037, Val F1: 0.3754, Test F1: 0.3938
Epoch 10/20, Train Acc: 0.9000, Val Acc: 0.3469, Test Acc: 0.4000, Test F1(macro): 0.3938, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.2438, 0.1333, 0.1736, 0.1811, 0.2682] **
max =  0.2682 | max_idx =  4
**pseudo_label ->  [0.1467, 0.1564, 0.1676, 0.2026, 0.3267] **
max =  0.3267 | max_idx =  4
**pseudo_label ->  [0.2107, 0.2916, 0.1741, 0.137, 0.1867] **
max =  0.2916 | max_idx =  1
**pseudo_label ->  [0.3291, 0.1473, 0.1876, 0.1525, 0.1835] **
max =  0.3291 | max_idx =  0
**pseudo_label ->  [0.1446, 0.1567, 0.1645, 0.2258, 0.3084] **
max =  0.3084 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.8, 0.9, 0.8]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1049, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0827, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 110, Time: 0:19:38
Train F1: 0.9022, Val F1: 0.2476, Test F1: 0.3716
Epoch 11/20, Train Acc: 0.9000, Val Acc: 0.2857, Test Acc: 0.3684, Test F1(macro): 0.3716, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1301, 0.2029, 0.1616, 0.1954, 0.3101] **
max =  0.3101 | max_idx =  4
**pseudo_label ->  [0.152, 0.1701, 0.1582, 0.1794, 0.3404] **
max =  0.3404 | max_idx =  4
**pseudo_label ->  [0.1587, 0.3258, 0.1725, 0.1676, 0.1753] **
max =  0.3258 | max_idx =  1
**pseudo_label ->  [0.162, 0.333, 0.17, 0.1636, 0.1715] **
max =  0.333 | max_idx =  1
**pseudo_label ->  [0.1928, 0.1959, 0.2901, 0.1551, 0.1662] **
max =  0.2901 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [1.0, 0.9, 0.8, 0.9, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0945, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0540, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 120, Time: 0:21:24
Train F1: 0.9205, Val F1: 0.3384, Test F1: 0.3746
Epoch 12/20, Train Acc: 0.9200, Val Acc: 0.3265, Test Acc: 0.3684, Test F1(macro): 0.3746, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1564, 0.1566, 0.249, 0.27, 0.1679] **
max =  0.27 | max_idx =  3
**pseudo_label ->  [0.1856, 0.145, 0.3071, 0.146, 0.2162] **
max =  0.3071 | max_idx =  2
**pseudo_label ->  [0.1516, 0.1514, 0.1548, 0.2361, 0.3059] **
max =  0.3059 | max_idx =  4
**pseudo_label ->  [0.2203, 0.1623, 0.3067, 0.1592, 0.1515] **
max =  0.3067 | max_idx =  2
**pseudo_label ->  [0.1656, 0.3234, 0.1834, 0.1455, 0.1821] **
max =  0.3234 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.9, 0.9, 0.9]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0799, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0391, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 130, Time: 0:23:26
Train F1: 0.9399, Val F1: 0.3570, Test F1: 0.4410
Epoch 13/20, Train Acc: 0.9400, Val Acc: 0.3980, Test Acc: 0.4421, Test F1(macro): 0.4410, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1616, 0.1573, 0.1643, 0.1653, 0.3515] **
max =  0.3515 | max_idx =  4
**pseudo_label ->  [0.1487, 0.1547, 0.1643, 0.2004, 0.3319] **
max =  0.3319 | max_idx =  4
**pseudo_label ->  [0.1472, 0.1611, 0.1558, 0.1968, 0.339] **
max =  0.339 | max_idx =  4
**pseudo_label ->  [0.2612, 0.1414, 0.2833, 0.1436, 0.1705] **
max =  0.2833 | max_idx =  2
**pseudo_label ->  [0.3347, 0.1681, 0.1829, 0.1575, 0.1568] **
max =  0.3347 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.8, 0.9, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0684, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0241, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 140, Time: 0:25:07
Train F1: 0.9396, Val F1: 0.3341, Test F1: 0.4045
Epoch 14/20, Train Acc: 0.9400, Val Acc: 0.3367, Test Acc: 0.4000, Test F1(macro): 0.4045, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1392, 0.1614, 0.1775, 0.1791, 0.3427] **
max =  0.3427 | max_idx =  4
**pseudo_label ->  [0.1325, 0.1427, 0.2212, 0.2364, 0.2672] **
max =  0.2672 | max_idx =  4
**pseudo_label ->  [0.2713, 0.1487, 0.2816, 0.1444, 0.154] **
max =  0.2816 | max_idx =  2
**pseudo_label ->  [0.1615, 0.1597, 0.2137, 0.1432, 0.3219] **
max =  0.3219 | max_idx =  4
**pseudo_label ->  [0.1644, 0.1567, 0.1747, 0.1538, 0.3504] **
max =  0.3504 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.5, 1.0, 0.8, 0.9, 0.9]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0591, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0154, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 150, Time: 0:26:52
Train F1: 0.8234, Val F1: 0.2008, Test F1: 0.2525
Epoch 15/20, Train Acc: 0.8200, Val Acc: 0.2245, Test Acc: 0.2842, Test F1(macro): 0.2525, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1657, 0.3429, 0.1673, 0.1484, 0.1758] **
max =  0.3429 | max_idx =  1
**pseudo_label ->  [0.1987, 0.1412, 0.2942, 0.1367, 0.2291] **
max =  0.2942 | max_idx =  2
**pseudo_label ->  [0.172, 0.3369, 0.1685, 0.1544, 0.1681] **
max =  0.3369 | max_idx =  1
**pseudo_label ->  [0.1488, 0.1323, 0.1828, 0.2415, 0.2946] **
max =  0.2946 | max_idx =  4
**pseudo_label ->  [0.1609, 0.1532, 0.1563, 0.1764, 0.3532] **
max =  0.3532 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 0.8, 0.9, 0.9, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0506, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0236, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 160, Time: 0:28:35
Train F1: 0.9212, Val F1: 0.3054, Test F1: 0.4023
Epoch 16/20, Train Acc: 0.9200, Val Acc: 0.3061, Test Acc: 0.3895, Test F1(macro): 0.4023, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.3587, 0.1562, 0.1764, 0.1537, 0.1549] **
max =  0.3587 | max_idx =  0
**pseudo_label ->  [0.1535, 0.1433, 0.1468, 0.3265, 0.2299] **
max =  0.3265 | max_idx =  3
**pseudo_label ->  [0.167, 0.1582, 0.3346, 0.1592, 0.181] **
max =  0.3346 | max_idx =  2
**pseudo_label ->  [0.1483, 0.151, 0.285, 0.1516, 0.264] **
max =  0.285 | max_idx =  2
**pseudo_label ->  [0.1225, 0.2437, 0.2063, 0.1533, 0.2742] **
max =  0.2742 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.8, 0.9, 0.9]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0427, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.9951, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 170, Time: 0:30:19
Train F1: 0.9195, Val F1: 0.3376, Test F1: 0.3622
Epoch 17/20, Train Acc: 0.9200, Val Acc: 0.3367, Test Acc: 0.3684, Test F1(macro): 0.3622, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1423, 0.15, 0.1529, 0.3213, 0.2335] **
max =  0.3213 | max_idx =  3
**pseudo_label ->  [0.146, 0.1294, 0.221, 0.2069, 0.2967] **
max =  0.2967 | max_idx =  4
**pseudo_label ->  [0.1628, 0.1493, 0.1843, 0.1713, 0.3323] **
max =  0.3323 | max_idx =  4
**pseudo_label ->  [0.3638, 0.1527, 0.1676, 0.1533, 0.1625] **
max =  0.3638 | max_idx =  0
**pseudo_label ->  [0.2, 0.1545, 0.3356, 0.1472, 0.1627] **
max =  0.3356 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.9, 0.9, 0.9]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0328, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.9778, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 180, Time: 0:32:00
Train F1: 0.9407, Val F1: 0.3384, Test F1: 0.4026
Epoch 18/20, Train Acc: 0.9400, Val Acc: 0.3571, Test Acc: 0.4211, Test F1(macro): 0.4026, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1461, 0.1566, 0.1552, 0.3489, 0.1931] **
max =  0.3489 | max_idx =  3
**pseudo_label ->  [0.1824, 0.1786, 0.3266, 0.1696, 0.1427] **
max =  0.3266 | max_idx =  2
**pseudo_label ->  [0.1296, 0.2022, 0.1746, 0.1984, 0.2952] **
max =  0.2952 | max_idx =  4
**pseudo_label ->  [0.142, 0.1811, 0.1724, 0.1478, 0.3566] **
max =  0.3566 | max_idx =  4
**pseudo_label ->  [0.1317, 0.1454, 0.2196, 0.2813, 0.222] **
max =  0.2813 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.8, 0.9, 0.8]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0250, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.9649, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 190, Time: 0:33:45
Train F1: 0.8985, Val F1: 0.3048, Test F1: 0.3538
Epoch 19/20, Train Acc: 0.9000, Val Acc: 0.3061, Test Acc: 0.3684, Test F1(macro): 0.3538, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50

**pseudo_label ->  [0.1767, 0.1271, 0.2626, 0.1672, 0.2664] **
max =  0.2664 | max_idx =  4
**pseudo_label ->  [0.1709, 0.1548, 0.344, 0.1642, 0.1662] **
max =  0.344 | max_idx =  2
**pseudo_label ->  [0.1572, 0.1585, 0.175, 0.1463, 0.3631] **
max =  0.3631 | max_idx =  4
**pseudo_label ->  [0.1538, 0.3563, 0.1596, 0.1577, 0.1726] **
max =  0.3563 | max_idx =  1
**pseudo_label ->  [0.1394, 0.1741, 0.2678, 0.1367, 0.282] **
max =  0.282 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.6, 0.9, 0.9]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0172, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.9601, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 200, Time: 0:35:30
Train F1: 0.8774, Val F1: 0.2748, Test F1: 0.3310
Epoch 20/20, Train Acc: 0.8800, Val Acc: 0.3061, Test Acc: 0.3579, Test F1(macro): 0.3310, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 50


Training complete!
Total training took 0:35:30 (h:mm:ss)
Load model from ./experiment/jointmatch/output/10_['codet5p', 'codet5p']_[2e-05, 3e-05]_0.7_jointmatch_20_[43]_{'corcode'}_net0.pth
Load model from ./experiment/jointmatch/output/10_['codet5p', 'codet5p']_[2e-05, 3e-05]_0.7_jointmatch_20_[43]_{'corcode'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/codet5p/joint_match//10_['codet5p', 'codet5p']_[2e-05, 3e-05]_0.7_jointmatch_20_[43]_{'corcode'}/training_statistics.csv


Best_step:  130 
Best_val_epoch:  13 
best_val_acc:  0.3979591836734694 
best_val_test_acc:  0.4421052631578947 
best_val_test_f1:  0.4410319661363305
Save best record in:  ./experiment/jointmatch/log/codet5p/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
