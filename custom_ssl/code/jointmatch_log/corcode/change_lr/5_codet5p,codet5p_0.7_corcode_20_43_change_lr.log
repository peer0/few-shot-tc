current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code

bs for corcod =>  5
Data set -> jointmatch
save_name: 5_['codet5p', 'codet5p']_[2e-05, 3e-05]_0.7_jointmatch_20_[43]_{'corcode'}

data_path:  ../data/jointmatch/corcode

There are 1 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding']
**tokenizer type =  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding'] 

n_labeled_per_class:  5
train_df samples: 739
train_labeled_df samples: 25
train_unlabeled_df samples: 714
Check n_smaples_per_class in the original training set:  OrderedDict([(1, 121), (2, 44), (3, 306), (4, 114), (5, 154)])
Check n_smaples_per_class in the labeled training set:  OrderedDict([(1, 5), (2, 5), (3, 5), (4, 5), (5, 5)])
Check n_smaples_per_class in the unlabeled training set:  OrderedDict([(1, 116), (2, 39), (3, 301), (4, 109), (5, 149)])
n_classes:  5

net_arch:  Salesforce/codet5p-110m-embedding 
lr:  2e-05 
lr_linear:  0.001 


net_arch:  Salesforce/codet5p-110m-embedding 
lr:  3e-05 
lr_linear:  0.001 

**pseudo_label ->  [0.2028, 0.1864, 0.1936, 0.1997, 0.2175] **
max =  0.2175 | max_idx =  4
**pseudo_label ->  [0.2116, 0.1906, 0.1958, 0.192, 0.2101] **
max =  0.2116 | max_idx =  0
**pseudo_label ->  [0.206, 0.1897, 0.2074, 0.1873, 0.2096] **
max =  0.2096 | max_idx =  4
**pseudo_label ->  [0.2053, 0.1916, 0.1999, 0.2022, 0.201] **
max =  0.2053 | max_idx =  0
**pseudo_label ->  [0.1995, 0.1961, 0.1944, 0.1988, 0.2112] **
max =  0.2112 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 0.8, 0.8, 0.8, 0.6]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.6366, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.6210, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 5, Time: 0:01:46
Train F1: 0.8095, Val F1: 0.2194, Test F1: 0.3335
Epoch 1/20, Train Acc: 0.8000, Val Acc: 0.2449, Test Acc: 0.3053, Test F1(macro): 0.3335, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.2081, 0.1931, 0.2044, 0.1971, 0.1972] **
max =  0.2081 | max_idx =  0
**pseudo_label ->  [0.2047, 0.1886, 0.1915, 0.2171, 0.1981] **
max =  0.2171 | max_idx =  3
**pseudo_label ->  [0.2012, 0.197, 0.1859, 0.1995, 0.2163] **
max =  0.2163 | max_idx =  4
**pseudo_label ->  [0.1971, 0.1969, 0.2097, 0.1988, 0.1976] **
max =  0.2097 | max_idx =  2
**pseudo_label ->  [0.2063, 0.1902, 0.1974, 0.1928, 0.2132] **
max =  0.2132 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.8, 0.2, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.5675, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.4741, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 10, Time: 0:03:32
Train F1: 0.5873, Val F1: 0.1897, Test F1: 0.1833
Epoch 2/20, Train Acc: 0.6400, Val Acc: 0.2245, Test Acc: 0.2211, Test F1(macro): 0.1833, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.1728, 0.1818, 0.218, 0.2081, 0.2193] **
max =  0.2193 | max_idx =  4
**pseudo_label ->  [0.2303, 0.1759, 0.1854, 0.1948, 0.2135] **
max =  0.2303 | max_idx =  0
**pseudo_label ->  [0.1808, 0.181, 0.2142, 0.219, 0.205] **
max =  0.219 | max_idx =  3
**pseudo_label ->  [0.2181, 0.176, 0.1747, 0.1943, 0.2369] **
max =  0.2369 | max_idx =  4
**pseudo_label ->  [0.226, 0.1803, 0.2084, 0.1588, 0.2266] **
max =  0.2266 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.8, 0.8, 0.8]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.4309, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3627, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 15, Time: 0:05:38
Train F1: 0.8796, Val F1: 0.2908, Test F1: 0.3304
Epoch 3/20, Train Acc: 0.8800, Val Acc: 0.2653, Test Acc: 0.2947, Test F1(macro): 0.3304, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.2433, 0.1705, 0.2111, 0.1642, 0.211] **
max =  0.2433 | max_idx =  0
**pseudo_label ->  [0.1792, 0.1921, 0.2395, 0.1829, 0.2062] **
max =  0.2395 | max_idx =  2
**pseudo_label ->  [0.2023, 0.1799, 0.1949, 0.2073, 0.2155] **
max =  0.2155 | max_idx =  4
**pseudo_label ->  [0.1749, 0.2126, 0.2343, 0.1744, 0.2038] **
max =  0.2343 | max_idx =  2
**pseudo_label ->  [0.2386, 0.1726, 0.1949, 0.1725, 0.2213] **
max =  0.2386 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.8, 0.8, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3488, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3233, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 20, Time: 0:07:41
Train F1: 0.9222, Val F1: 0.2699, Test F1: 0.3282
Epoch 4/20, Train Acc: 0.9200, Val Acc: 0.3265, Test Acc: 0.3263, Test F1(macro): 0.3282, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.2247, 0.1985, 0.191, 0.1677, 0.2181] **
max =  0.2247 | max_idx =  0
**pseudo_label ->  [0.1795, 0.1769, 0.2514, 0.1983, 0.1938] **
max =  0.2514 | max_idx =  2
**pseudo_label ->  [0.1747, 0.1998, 0.1778, 0.1788, 0.2688] **
max =  0.2688 | max_idx =  4
**pseudo_label ->  [0.1617, 0.1879, 0.1745, 0.2747, 0.2012] **
max =  0.2747 | max_idx =  3
**pseudo_label ->  [0.1609, 0.2569, 0.1839, 0.2066, 0.1917] **
max =  0.2569 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.8, 0.8, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2923, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2400, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 25, Time: 0:09:26
Train F1: 0.9192, Val F1: 0.0963, Test F1: 0.0956
Epoch 5/20, Train Acc: 0.9200, Val Acc: 0.1224, Test Acc: 0.1368, Test F1(macro): 0.0956, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.1678, 0.1983, 0.2275, 0.218, 0.1884] **
max =  0.2275 | max_idx =  2
**pseudo_label ->  [0.1948, 0.1535, 0.1938, 0.1786, 0.2793] **
max =  0.2793 | max_idx =  4
**pseudo_label ->  [0.1977, 0.1471, 0.2562, 0.1784, 0.2205] **
max =  0.2562 | max_idx =  2
**pseudo_label ->  [0.1975, 0.162, 0.1922, 0.1607, 0.2876] **
max =  0.2876 | max_idx =  4
**pseudo_label ->  [0.2281, 0.143, 0.1937, 0.1781, 0.2571] **
max =  0.2571 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 1.0, 0.8, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2589, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2099, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 30, Time: 0:11:12
Train F1: 0.9596, Val F1: 0.2691, Test F1: 0.3310
Epoch 6/20, Train Acc: 0.9600, Val Acc: 0.2857, Test Acc: 0.3263, Test F1(macro): 0.3310, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.2221, 0.222, 0.1879, 0.1683, 0.1997] **
max =  0.2221 | max_idx =  0
**pseudo_label ->  [0.1762, 0.1735, 0.2898, 0.169, 0.1915] **
max =  0.2898 | max_idx =  2
**pseudo_label ->  [0.1969, 0.1793, 0.2786, 0.1712, 0.1741] **
max =  0.2786 | max_idx =  2
**pseudo_label ->  [0.1783, 0.1638, 0.2701, 0.2079, 0.1799] **
max =  0.2701 | max_idx =  2
**pseudo_label ->  [0.1863, 0.1836, 0.2773, 0.154, 0.1988] **
max =  0.2773 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.8, 0.8, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2672, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1750, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 35, Time: 0:12:58
Train F1: 0.9192, Val F1: 0.1756, Test F1: 0.2263
Epoch 7/20, Train Acc: 0.9200, Val Acc: 0.1735, Test Acc: 0.2211, Test F1(macro): 0.2263, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.2408, 0.1934, 0.1852, 0.1384, 0.2421] **
max =  0.2421 | max_idx =  4
**pseudo_label ->  [0.1678, 0.1973, 0.2003, 0.1464, 0.2883] **
max =  0.2883 | max_idx =  4
**pseudo_label ->  [0.1645, 0.1799, 0.2475, 0.1487, 0.2594] **
max =  0.2594 | max_idx =  4
**pseudo_label ->  [0.1697, 0.2655, 0.1451, 0.1942, 0.2255] **
max =  0.2655 | max_idx =  1
**pseudo_label ->  [0.1875, 0.2083, 0.1819, 0.1583, 0.264] **
max =  0.264 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.8, 0.8, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1955, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1650, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 40, Time: 0:14:43
Train F1: 0.9222, Val F1: 0.2594, Test F1: 0.3592
Epoch 8/20, Train Acc: 0.9200, Val Acc: 0.2755, Test Acc: 0.3368, Test F1(macro): 0.3592, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.1341, 0.2449, 0.1726, 0.2127, 0.2357] **
max =  0.2449 | max_idx =  1
**pseudo_label ->  [0.1758, 0.1581, 0.2916, 0.1745, 0.2] **
max =  0.2916 | max_idx =  2
**pseudo_label ->  [0.1522, 0.2488, 0.1539, 0.2687, 0.1765] **
max =  0.2687 | max_idx =  3
**pseudo_label ->  [0.1559, 0.1795, 0.2308, 0.2343, 0.1995] **
max =  0.2343 | max_idx =  3
**pseudo_label ->  [0.1448, 0.1663, 0.2515, 0.1862, 0.2511] **
max =  0.2515 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.8, 1.0, 0.8, 1.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2302, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1440, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 45, Time: 0:16:25
Train F1: 0.9192, Val F1: 0.2184, Test F1: 0.2826
Epoch 9/20, Train Acc: 0.9200, Val Acc: 0.2551, Test Acc: 0.3158, Test F1(macro): 0.2826, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.2147, 0.2165, 0.1764, 0.2454, 0.147] **
max =  0.2454 | max_idx =  3
**pseudo_label ->  [0.2806, 0.1671, 0.194, 0.1849, 0.1733] **
max =  0.2806 | max_idx =  0
**pseudo_label ->  [0.2972, 0.1723, 0.1863, 0.1634, 0.1809] **
max =  0.2972 | max_idx =  0
**pseudo_label ->  [0.1846, 0.3074, 0.1634, 0.1677, 0.1769] **
max =  0.3074 | max_idx =  1
**pseudo_label ->  [0.249, 0.1728, 0.1961, 0.219, 0.1631] **
max =  0.249 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.8, 0.8, 0.6]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1897, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1382, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 50, Time: 0:18:11
Train F1: 0.8412, Val F1: 0.1694, Test F1: 0.1934
Epoch 10/20, Train Acc: 0.8400, Val Acc: 0.2143, Test Acc: 0.2211, Test F1(macro): 0.1934, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.1651, 0.2074, 0.1703, 0.1559, 0.3013] **
max =  0.3013 | max_idx =  4
**pseudo_label ->  [0.2296, 0.184, 0.1907, 0.1305, 0.2653] **
max =  0.2653 | max_idx =  4
**pseudo_label ->  [0.1552, 0.2502, 0.2078, 0.1893, 0.1975] **
max =  0.2502 | max_idx =  1
**pseudo_label ->  [0.1706, 0.1778, 0.2779, 0.1569, 0.2168] **
max =  0.2779 | max_idx =  2
**pseudo_label ->  [0.178, 0.2199, 0.1646, 0.1439, 0.2936] **
max =  0.2936 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.8, 1.0, 1.0, 1.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1575, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1338, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 55, Time: 0:19:56
Train F1: 0.9596, Val F1: 0.1820, Test F1: 0.2500
Epoch 11/20, Train Acc: 0.9600, Val Acc: 0.2551, Test Acc: 0.2842, Test F1(macro): 0.2500, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.1662, 0.1544, 0.2071, 0.2822, 0.1902] **
max =  0.2822 | max_idx =  3
**pseudo_label ->  [0.172, 0.2226, 0.1555, 0.156, 0.2938] **
max =  0.2938 | max_idx =  4
**pseudo_label ->  [0.1768, 0.1784, 0.164, 0.1937, 0.2872] **
max =  0.2872 | max_idx =  4
**pseudo_label ->  [0.1688, 0.173, 0.2981, 0.176, 0.1841] **
max =  0.2981 | max_idx =  2
**pseudo_label ->  [0.1675, 0.1604, 0.171, 0.332, 0.1691] **
max =  0.332 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 0.8, 0.8, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1291, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1072, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 60, Time: 0:21:40
Train F1: 0.9222, Val F1: 0.1526, Test F1: 0.2159
Epoch 12/20, Train Acc: 0.9200, Val Acc: 0.2041, Test Acc: 0.2526, Test F1(macro): 0.2159, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.2212, 0.1591, 0.191, 0.1394, 0.2893] **
max =  0.2893 | max_idx =  4
**pseudo_label ->  [0.2555, 0.1529, 0.2206, 0.1342, 0.2369] **
max =  0.2555 | max_idx =  0
**pseudo_label ->  [0.2131, 0.1574, 0.2934, 0.139, 0.1971] **
max =  0.2934 | max_idx =  2
**pseudo_label ->  [0.1781, 0.1573, 0.2295, 0.1604, 0.2747] **
max =  0.2747 | max_idx =  4
**pseudo_label ->  [0.185, 0.1939, 0.176, 0.1797, 0.2654] **
max =  0.2654 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 1.0, 0.8, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1189, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0938, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 65, Time: 0:23:23
Train F1: 0.9596, Val F1: 0.1811, Test F1: 0.2353
Epoch 13/20, Train Acc: 0.9600, Val Acc: 0.2041, Test Acc: 0.2421, Test F1(macro): 0.2353, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.1629, 0.1644, 0.3079, 0.1678, 0.197] **
max =  0.3079 | max_idx =  2
**pseudo_label ->  [0.1633, 0.222, 0.15, 0.1611, 0.3036] **
max =  0.3036 | max_idx =  4
**pseudo_label ->  [0.1653, 0.1793, 0.3097, 0.1727, 0.1729] **
max =  0.3097 | max_idx =  2
**pseudo_label ->  [0.2447, 0.1594, 0.1731, 0.1788, 0.2439] **
max =  0.2447 | max_idx =  0
**pseudo_label ->  [0.1578, 0.1905, 0.1577, 0.1688, 0.3252] **
max =  0.3252 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 1.0, 0.8, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1079, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0720, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 70, Time: 0:25:07
Train F1: 0.9596, Val F1: 0.2804, Test F1: 0.3149
Epoch 14/20, Train Acc: 0.9600, Val Acc: 0.2959, Test Acc: 0.2947, Test F1(macro): 0.3149, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.189, 0.141, 0.1943, 0.1551, 0.3206] **
max =  0.3206 | max_idx =  4
**pseudo_label ->  [0.269, 0.254, 0.1657, 0.1432, 0.1681] **
max =  0.269 | max_idx =  0
**pseudo_label ->  [0.1824, 0.1538, 0.3177, 0.1646, 0.1814] **
max =  0.3177 | max_idx =  2
**pseudo_label ->  [0.3202, 0.1448, 0.205, 0.1494, 0.1806] **
max =  0.3202 | max_idx =  0
**pseudo_label ->  [0.2057, 0.1504, 0.2636, 0.1556, 0.2246] **
max =  0.2636 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 1.0, 0.8, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1047, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0575, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 75, Time: 0:26:53
Train F1: 0.9596, Val F1: 0.2558, Test F1: 0.2941
Epoch 15/20, Train Acc: 0.9600, Val Acc: 0.2755, Test Acc: 0.2947, Test F1(macro): 0.2941, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.1633, 0.1955, 0.2586, 0.176, 0.2066] **
max =  0.2586 | max_idx =  2
**pseudo_label ->  [0.2623, 0.1795, 0.1515, 0.1397, 0.2671] **
max =  0.2671 | max_idx =  4
**pseudo_label ->  [0.1479, 0.2037, 0.1658, 0.1812, 0.3014] **
max =  0.3014 | max_idx =  4
**pseudo_label ->  [0.2754, 0.1602, 0.2065, 0.1529, 0.205] **
max =  0.2754 | max_idx =  0
**pseudo_label ->  [0.1623, 0.185, 0.3109, 0.1595, 0.1823] **
max =  0.3109 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 1.0, 0.8, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0925, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0460, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 80, Time: 0:28:38
Train F1: 0.9596, Val F1: 0.2312, Test F1: 0.3101
Epoch 16/20, Train Acc: 0.9600, Val Acc: 0.2245, Test Acc: 0.2947, Test F1(macro): 0.3101, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.1473, 0.1852, 0.146, 0.228, 0.2935] **
max =  0.2935 | max_idx =  4
**pseudo_label ->  [0.2044, 0.1554, 0.1632, 0.16, 0.317] **
max =  0.317 | max_idx =  4
**pseudo_label ->  [0.1681, 0.157, 0.159, 0.174, 0.3419] **
max =  0.3419 | max_idx =  4
**pseudo_label ->  [0.1643, 0.1592, 0.2946, 0.1827, 0.1991] **
max =  0.2946 | max_idx =  2
**pseudo_label ->  [0.2563, 0.1552, 0.1818, 0.1511, 0.2556] **
max =  0.2563 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 1.0, 1.0, 0.8, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0790, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0377, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 85, Time: 0:30:25
Train F1: 0.9596, Val F1: 0.2147, Test F1: 0.2670
Epoch 17/20, Train Acc: 0.9600, Val Acc: 0.2347, Test Acc: 0.2737, Test F1(macro): 0.2670, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.166, 0.1647, 0.3137, 0.1789, 0.1767] **
max =  0.3137 | max_idx =  2
**pseudo_label ->  [0.2443, 0.1426, 0.2048, 0.1962, 0.2121] **
max =  0.2443 | max_idx =  0
**pseudo_label ->  [0.177, 0.1583, 0.327, 0.1595, 0.1782] **
max =  0.327 | max_idx =  2
**pseudo_label ->  [0.1808, 0.1911, 0.1337, 0.2339, 0.2604] **
max =  0.2604 | max_idx =  4
**pseudo_label ->  [0.1885, 0.17, 0.2788, 0.153, 0.2096] **
max =  0.2788 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.8, 1.0, 1.0, 1.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0718, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0314, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 90, Time: 0:32:07
Train F1: 0.9596, Val F1: 0.2149, Test F1: 0.2598
Epoch 18/20, Train Acc: 0.9600, Val Acc: 0.2857, Test Acc: 0.3053, Test F1(macro): 0.2598, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.1691, 0.1589, 0.3198, 0.1831, 0.1691] **
max =  0.3198 | max_idx =  2
**pseudo_label ->  [0.1841, 0.1729, 0.1632, 0.1494, 0.3303] **
max =  0.3303 | max_idx =  4
**pseudo_label ->  [0.1671, 0.1541, 0.2832, 0.1924, 0.2031] **
max =  0.2832 | max_idx =  2
**pseudo_label ->  [0.1775, 0.2326, 0.2121, 0.1205, 0.2573] **
max =  0.2573 | max_idx =  4
**pseudo_label ->  [0.1773, 0.1671, 0.3135, 0.1735, 0.1686] **
max =  0.3135 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.8, 1.0, 0.8, 1.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0648, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0326, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 95, Time: 0:33:53
Train F1: 0.9192, Val F1: 0.1913, Test F1: 0.2277
Epoch 19/20, Train Acc: 0.9200, Val Acc: 0.1939, Test Acc: 0.2211, Test F1(macro): 0.2277, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.2365, 0.1739, 0.1832, 0.153, 0.2534] **
max =  0.2534 | max_idx =  4
**pseudo_label ->  [0.149, 0.1924, 0.1524, 0.333, 0.1731] **
max =  0.333 | max_idx =  3
**pseudo_label ->  [0.3075, 0.1539, 0.1856, 0.1375, 0.2155] **
max =  0.3075 | max_idx =  0
**pseudo_label ->  [0.1779, 0.1482, 0.168, 0.333, 0.1729] **
max =  0.333 | max_idx =  3
**pseudo_label ->  [0.2043, 0.1636, 0.1625, 0.1476, 0.322] **
max =  0.322 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.8, 1.0, 1.0, 1.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0589, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.0188, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 100, Time: 0:35:39
Train F1: 0.9596, Val F1: 0.2345, Test F1: 0.2771
Epoch 20/20, Train Acc: 0.9600, Val Acc: 0.2653, Test Acc: 0.3053, Test F1(macro): 0.2771, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25


Training complete!
Total training took 0:35:39 (h:mm:ss)
Load model from ./experiment/jointmatch/output/5_['codet5p', 'codet5p']_[2e-05, 3e-05]_0.7_jointmatch_20_[43]_{'corcode'}_net0.pth
Load model from ./experiment/jointmatch/output/5_['codet5p', 'codet5p']_[2e-05, 3e-05]_0.7_jointmatch_20_[43]_{'corcode'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/codet5p/joint_match//5_['codet5p', 'codet5p']_[2e-05, 3e-05]_0.7_jointmatch_20_[43]_{'corcode'}/training_statistics.csv


Best_step:  20 
Best_val_epoch:  4 
best_val_acc:  0.32653061224489793 
best_val_test_acc:  0.3263157894736842 
best_val_test_f1:  0.3282067971723144
Save best record in:  ./experiment/jointmatch/log/codet5p/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
