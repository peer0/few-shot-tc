current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code

bs for corcod =>  5
Data set -> jointmatch
save_name: 5_['unixcoder', 'unixcoder']_[1e-05, 2e-06]_0.7_jointmatch_20_[45]_{'corcode'}

data_path:  ../data/jointmatch/corcode

There are 1 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base']
**tokenizer type =  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base'] 

n_labeled_per_class:  5
train_df samples: 739
train_labeled_df samples: 25
train_unlabeled_df samples: 714
Check n_smaples_per_class in the original training set:  OrderedDict([(1, 121), (2, 44), (3, 306), (4, 114), (5, 154)])
Check n_smaples_per_class in the labeled training set:  OrderedDict([(1, 5), (2, 5), (3, 5), (4, 5), (5, 5)])
Check n_smaples_per_class in the unlabeled training set:  OrderedDict([(1, 116), (2, 39), (3, 301), (4, 109), (5, 149)])
n_classes:  5

net_arch:  microsoft/unixcoder-base 
lr:  1e-05 
lr_linear:  0.001 


net_arch:  microsoft/unixcoder-base 
lr:  2e-06 
lr_linear:  0.001 

**pseudo_label ->  [0.2322, 0.132, 0.1647, 0.2825, 0.1885] **
max =  0.2825 | max_idx =  3
**pseudo_label ->  [0.1442, 0.198, 0.2374, 0.2454, 0.175] **
max =  0.2454 | max_idx =  3
**pseudo_label ->  [0.1541, 0.1432, 0.2271, 0.2796, 0.1961] **
max =  0.2796 | max_idx =  3
**pseudo_label ->  [0.2499, 0.14, 0.164, 0.3207, 0.1253] **
max =  0.3207 | max_idx =  3
**pseudo_label ->  [0.1684, 0.1693, 0.3101, 0.1927, 0.1595] **
max =  0.3101 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.6, 0.8, 1.0, 0.4, 0.4]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.7094, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.5010, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 5, Time: 0:01:51
Train F1: 0.6267, Val F1: 0.1862, Test F1: 0.2184
Epoch 1/20, Train Acc: 0.6400, Val Acc: 0.3265, Test Acc: 0.2842, Test F1(macro): 0.2184, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.1162, 0.2949, 0.2584, 0.1295, 0.201] **
max =  0.2949 | max_idx =  1
**pseudo_label ->  [0.1828, 0.2248, 0.2176, 0.2276, 0.1472] **
max =  0.2276 | max_idx =  3
**pseudo_label ->  [0.1449, 0.2317, 0.2395, 0.1408, 0.2432] **
max =  0.2432 | max_idx =  4
**pseudo_label ->  [0.1531, 0.2138, 0.1681, 0.251, 0.2139] **
max =  0.251 | max_idx =  3
**pseudo_label ->  [0.0817, 0.2064, 0.3265, 0.1374, 0.248] **
max =  0.3265 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.6, 0.6, 0.8, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.4246, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.5472, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 10, Time: 0:03:36
Train F1: 0.5510, Val F1: 0.1631, Test F1: 0.2601
Epoch 2/20, Train Acc: 0.6000, Val Acc: 0.1939, Test Acc: 0.2737, Test F1(macro): 0.2601, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.3016, 0.0583, 0.2001, 0.2952, 0.1447] **
max =  0.3016 | max_idx =  0
**pseudo_label ->  [0.2743, 0.2189, 0.1471, 0.2228, 0.1369] **
max =  0.2743 | max_idx =  0
**pseudo_label ->  [0.4457, 0.1034, 0.1659, 0.2301, 0.0549] **
max =  0.4457 | max_idx =  0
**pseudo_label ->  [0.3044, 0.1287, 0.0734, 0.4158, 0.0778] **
max =  0.4158 | max_idx =  3
**pseudo_label ->  [0.2095, 0.3597, 0.1983, 0.0812, 0.1513] **
max =  0.3597 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [1.0, 0.6, 0.4, 0.0, 0.6]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [4, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.0 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.0, nan, nan, nan, nan]
loss for labeled data =>  tensor(0.9579, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.5135, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 15, Time: 0:05:22
Train F1: 0.4929, Val F1: 0.1418, Test F1: 0.2052
Epoch 3/20, Train Acc: 0.5200, Val Acc: 0.1429, Test Acc: 0.1789, Test F1(macro): 0.2052, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.0934, 0.1455, 0.2683, 0.1405, 0.3523] **
max =  0.3523 | max_idx =  4
**pseudo_label ->  [0.0647, 0.3687, 0.1461, 0.2718, 0.1487] **
max =  0.3687 | max_idx =  1
**pseudo_label ->  [0.1757, 0.1865, 0.1698, 0.2316, 0.2364] **
max =  0.2364 | max_idx =  4
**pseudo_label ->  [0.1357, 0.2772, 0.1388, 0.2237, 0.2247] **
max =  0.2772 | max_idx =  1
**pseudo_label ->  [0.0756, 0.1536, 0.2171, 0.3288, 0.225] **
max =  0.3288 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 475, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 67, 0]
psl_acc(PSL 평가에서의 정확도):  0.141 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.14105263352394104, nan]
loss for labeled data =>  tensor(0.9618, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3472, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 20, Time: 0:07:09
Train F1: 0.0667, Val F1: 0.0500, Test F1: 0.0752
Epoch 4/20, Train Acc: 0.2000, Val Acc: 0.1429, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 1, Train Data Number: 25

**pseudo_label ->  [0.0241, 0.0676, 0.0545, 0.7868, 0.067] **
max =  0.7868 | max_idx =  3
**pseudo_label ->  [0.0246, 0.0705, 0.1102, 0.7014, 0.0933] **
max =  0.7014 | max_idx =  3
**pseudo_label ->  [0.1025, 0.0396, 0.0678, 0.6838, 0.1063] **
max =  0.6838 | max_idx =  3
**pseudo_label ->  [0.0574, 0.0669, 0.0364, 0.7889, 0.0505] **
max =  0.7889 | max_idx =  3
**pseudo_label ->  [0.0756, 0.2122, 0.0527, 0.5334, 0.1261] **
max =  0.5334 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 662, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 96, 0]
psl_acc(PSL 평가에서의 정확도):  0.145 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.14501510560512543, nan]
loss for labeled data =>  tensor(1.4823, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.5516, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 25, Time: 0:08:51
Train F1: 0.0667, Val F1: 0.0500, Test F1: 0.0752
Epoch 5/20, Train Acc: 0.2000, Val Acc: 0.1429, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.0184, 0.0128, 0.0126, 0.9257, 0.0305] **
max =  0.9257 | max_idx =  3
**pseudo_label ->  [0.0442, 0.0442, 0.0612, 0.7531, 0.0974] **
max =  0.7531 | max_idx =  3
**pseudo_label ->  [0.0522, 0.0413, 0.0619, 0.7809, 0.0637] **
max =  0.7809 | max_idx =  3
**pseudo_label ->  [0.0298, 0.0208, 0.0275, 0.8942, 0.0277] **
max =  0.8942 | max_idx =  3
**pseudo_label ->  [0.038, 0.0379, 0.062, 0.7422, 0.12] **
max =  0.7422 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 639, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 99, 0]
psl_acc(PSL 평가에서의 정확도):  0.155 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.15492957830429077, nan]
loss for labeled data =>  tensor(1.3966, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8694, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 30, Time: 0:10:38
Train F1: 0.0667, Val F1: 0.0500, Test F1: 0.0752
Epoch 6/20, Train Acc: 0.2000, Val Acc: 0.1429, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 2, Train Data Number: 25

**pseudo_label ->  [0.0075, 0.0109, 0.0092, 0.9592, 0.0132] **
max =  0.9592 | max_idx =  3
**pseudo_label ->  [0.4284, 0.0163, 0.0125, 0.5346, 0.0082] **
max =  0.5346 | max_idx =  3
**pseudo_label ->  [0.0093, 0.164, 0.0655, 0.6974, 0.0637] **
max =  0.6974 | max_idx =  3
**pseudo_label ->  [0.0152, 0.0195, 0.0869, 0.6588, 0.2196] **
max =  0.6588 | max_idx =  3
**pseudo_label ->  [0.0131, 0.0316, 0.0519, 0.6533, 0.2501] **
max =  0.6533 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.2, 0.2, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 569, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 85, 0]
psl_acc(PSL 평가에서의 정확도):  0.149 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.14938488602638245, nan]
loss for labeled data =>  tensor(0.4935, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.7639, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 35, Time: 0:12:24
Train F1: 0.2048, Val F1: 0.0500, Test F1: 0.0752
Epoch 7/20, Train Acc: 0.2800, Val Acc: 0.1429, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.0087, 0.0237, 0.0633, 0.7312, 0.173] **
max =  0.7312 | max_idx =  3
**pseudo_label ->  [0.0383, 0.0036, 0.007, 0.9421, 0.0091] **
max =  0.9421 | max_idx =  3
**pseudo_label ->  [0.0029, 0.0033, 0.0578, 0.9178, 0.0182] **
max =  0.9178 | max_idx =  3
**pseudo_label ->  [0.1755, 0.0051, 0.0304, 0.7624, 0.0266] **
max =  0.7624 | max_idx =  3
**pseudo_label ->  [0.004, 0.0383, 0.2482, 0.2285, 0.481] **
max =  0.481 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.4, 1.0, 0.4, 1.0, 0.6]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [1, 14, 1, 435, 24]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [1, 5, 0, 58, 7]
psl_acc(PSL 평가에서의 정확도):  0.149 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [1.0, 0.3571428656578064, 0.0, 0.13333334028720856, 0.2916666567325592]
loss for labeled data =>  tensor(0.3024, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.6415, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 40, Time: 0:14:10
Train F1: 0.6897, Val F1: 0.0500, Test F1: 0.0724
Epoch 8/20, Train Acc: 0.6800, Val Acc: 0.1429, Test Acc: 0.2211, Test F1(macro): 0.0724, Total Pseudo-Labels: 3, Correct Pseudo-Labels: 1, Train Data Number: 25

**pseudo_label ->  [0.0027, 0.0073, 0.0315, 0.8917, 0.0667] **
max =  0.8917 | max_idx =  3
**pseudo_label ->  [0.0023, 0.0032, 0.0013, 0.9921, 0.0011] **
max =  0.9921 | max_idx =  3
**pseudo_label ->  [0.0026, 0.0094, 0.0067, 0.979, 0.0023] **
max =  0.979 | max_idx =  3
**pseudo_label ->  [0.0039, 0.0156, 0.0201, 0.9362, 0.0241] **
max =  0.9362 | max_idx =  3
**pseudo_label ->  [0.0048, 0.0256, 0.0199, 0.9091, 0.0406] **
max =  0.9091 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.6, 1.0, 0.8]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 20, 3, 501, 9]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 8, 0, 66, 2]
psl_acc(PSL 평가에서의 정확도):  0.143 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.4000000059604645, 0.0, 0.13173653185367584, 0.2222222238779068]
loss for labeled data =>  tensor(0.1232, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2707, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 45, Time: 0:15:53
Train F1: 0.6389, Val F1: 0.0468, Test F1: 0.0696
Epoch 9/20, Train Acc: 0.6800, Val Acc: 0.1327, Test Acc: 0.2105, Test F1(macro): 0.0696, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.0018, 0.0026, 0.004, 0.9901, 0.0015] **
max =  0.9901 | max_idx =  3
**pseudo_label ->  [0.0023, 0.0016, 0.0013, 0.9931, 0.0017] **
max =  0.9931 | max_idx =  3
**pseudo_label ->  [0.008, 0.0245, 0.11, 0.7904, 0.0672] **
max =  0.7904 | max_idx =  3
**pseudo_label ->  [0.0098, 0.0483, 0.0804, 0.5905, 0.271] **
max =  0.5905 | max_idx =  3
**pseudo_label ->  [0.0054, 0.0175, 0.2618, 0.6321, 0.0832] **
max =  0.6321 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.4, 1.0, 0.8, 1.0, 0.4]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [2, 19, 1, 622, 3]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [2, 6, 1, 92, 0]
psl_acc(PSL 평가에서의 정확도):  0.156 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [1.0, 0.31578946113586426, 1.0, 0.1479099690914154, 0.0]
loss for labeled data =>  tensor(0.1123, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2596, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 50, Time: 0:17:40
Train F1: 0.7240, Val F1: 0.0473, Test F1: 0.0730
Epoch 10/20, Train Acc: 0.7200, Val Acc: 0.1327, Test Acc: 0.2211, Test F1(macro): 0.0730, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.0024, 0.0012, 0.0008, 0.9932, 0.0024] **
max =  0.9932 | max_idx =  3
**pseudo_label ->  [0.0016, 0.002, 0.0146, 0.9655, 0.0162] **
max =  0.9655 | max_idx =  3
**pseudo_label ->  [0.0047, 0.0152, 0.0176, 0.9345, 0.0279] **
max =  0.9345 | max_idx =  3
**pseudo_label ->  [0.0083, 0.0017, 0.0012, 0.988, 0.0008] **
max =  0.988 | max_idx =  3
**pseudo_label ->  [0.0028, 0.0038, 0.0111, 0.9419, 0.0404] **
max =  0.9419 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.4, 1.0, 0.6, 0.8, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 36, 3, 439, 34]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 12, 1, 62, 10]
psl_acc(PSL 평가에서의 정확도):  0.166 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.3333333432674408, 0.3333333432674408, 0.14123006165027618, 0.29411765933036804]
loss for labeled data =>  tensor(0.0540, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2434, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 55, Time: 0:19:26
Train F1: 0.7604, Val F1: 0.1035, Test F1: 0.1262
Epoch 11/20, Train Acc: 0.7600, Val Acc: 0.1122, Test Acc: 0.2105, Test F1(macro): 0.1262, Total Pseudo-Labels: 3, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.0046, 0.0947, 0.132, 0.5297, 0.2391] **
max =  0.5297 | max_idx =  3
**pseudo_label ->  [0.1625, 0.0387, 0.0128, 0.7826, 0.0034] **
max =  0.7826 | max_idx =  3
**pseudo_label ->  [0.0015, 0.0054, 0.0166, 0.9657, 0.0108] **
max =  0.9657 | max_idx =  3
**pseudo_label ->  [0.0063, 0.0102, 0.0015, 0.9718, 0.0101] **
max =  0.9718 | max_idx =  3
**pseudo_label ->  [0.0094, 0.1356, 0.1939, 0.3252, 0.336] **
max =  0.336 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.4, 1.0, 0.6, 1.0, 0.8]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 22, 1, 624, 7]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 13, 0, 94, 1]
psl_acc(PSL 평가에서의 정확도):  0.165 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.5909090638160706, 0.0, 0.15064102411270142, 0.1428571492433548]
loss for labeled data =>  tensor(0.1111, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.8297, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 60, Time: 0:21:12
Train F1: 0.7671, Val F1: 0.0505, Test F1: 0.0730
Epoch 12/20, Train Acc: 0.7600, Val Acc: 0.1429, Test Acc: 0.2211, Test F1(macro): 0.0730, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.0029, 0.0059, 0.0055, 0.9737, 0.012] **
max =  0.9737 | max_idx =  3
**pseudo_label ->  [0.0009, 0.0003, 0.0007, 0.9973, 0.0008] **
max =  0.9973 | max_idx =  3
**pseudo_label ->  [0.0018, 0.0013, 0.0009, 0.9932, 0.0028] **
max =  0.9932 | max_idx =  3
**pseudo_label ->  [0.0078, 0.0037, 0.01, 0.9046, 0.0739] **
max =  0.9046 | max_idx =  3
**pseudo_label ->  [0.0005, 0.0014, 0.0022, 0.9935, 0.0024] **
max =  0.9935 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.2, 1.0, 0.6, 0.8, 0.8]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 49, 7, 440, 15]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 23, 0, 58, 7]
psl_acc(PSL 평가에서의 정확도):  0.172 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.4693877696990967, 0.0, 0.13181817531585693, 0.46666666865348816]
loss for labeled data =>  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.6826, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 65, Time: 0:23:00
Train F1: 0.6763, Val F1: 0.1510, Test F1: 0.2090
Epoch 13/20, Train Acc: 0.6800, Val Acc: 0.1429, Test Acc: 0.2526, Test F1(macro): 0.2090, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.0033, 0.9612, 0.0185, 0.0102, 0.0068] **
max =  0.9612 | max_idx =  1
**pseudo_label ->  [0.0438, 0.0339, 0.0254, 0.8885, 0.0084] **
max =  0.8885 | max_idx =  3
**pseudo_label ->  [0.0337, 0.0047, 0.0031, 0.9557, 0.0027] **
max =  0.9557 | max_idx =  3
**pseudo_label ->  [0.014, 0.0021, 0.0014, 0.9821, 0.0004] **
max =  0.9821 | max_idx =  3
**pseudo_label ->  [0.0014, 0.0021, 0.0092, 0.9857, 0.0016] **
max =  0.9857 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.6, 1.0, 0.6, 0.8, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [4, 35, 7, 540, 18]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [2, 22, 0, 82, 3]
psl_acc(PSL 평가에서의 정확도):  0.18 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.5, 0.6285714507102966, 0.0, 0.1518518477678299, 0.1666666716337204]
loss for labeled data =>  tensor(0.0430, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.7116, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 70, Time: 0:24:31
Train F1: 0.8049, Val F1: 0.1636, Test F1: 0.2044
Epoch 14/20, Train Acc: 0.8000, Val Acc: 0.1327, Test Acc: 0.2316, Test F1(macro): 0.2044, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.0009, 0.0012, 0.0004, 0.997, 0.0005] **
max =  0.997 | max_idx =  3
**pseudo_label ->  [0.0013, 0.0029, 0.0221, 0.9616, 0.0121] **
max =  0.9616 | max_idx =  3
**pseudo_label ->  [0.0079, 0.0336, 0.1456, 0.049, 0.7639] **
max =  0.7639 | max_idx =  4
**pseudo_label ->  [0.0051, 0.0185, 0.1142, 0.2416, 0.6207] **
max =  0.6207 | max_idx =  4
**pseudo_label ->  [0.0217, 0.0625, 0.1382, 0.3836, 0.394] **
max =  0.394 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.6, 1.0, 0.8]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [1, 32, 5, 582, 2]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 23, 2, 93, 0]
psl_acc(PSL 평가에서의 정확도):  0.19 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.0, 0.71875, 0.4000000059604645, 0.15979380905628204, 0.0]
loss for labeled data =>  tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.6454, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 75, Time: 0:26:18
Train F1: 0.6389, Val F1: 0.1548, Test F1: 0.2083
Epoch 15/20, Train Acc: 0.6800, Val Acc: 0.1531, Test Acc: 0.2526, Test F1(macro): 0.2083, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.002, 0.07, 0.0029, 0.9201, 0.005] **
max =  0.9201 | max_idx =  3
**pseudo_label ->  [0.0043, 0.013, 0.0224, 0.9516, 0.0086] **
max =  0.9516 | max_idx =  3
**pseudo_label ->  [0.0024, 0.0072, 0.0014, 0.9875, 0.0015] **
max =  0.9875 | max_idx =  3
**pseudo_label ->  [0.0018, 0.0014, 0.0035, 0.9909, 0.0024] **
max =  0.9909 | max_idx =  3
**pseudo_label ->  [0.0019, 0.8637, 0.0278, 0.1021, 0.0046] **
max =  0.8637 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.6, 1.0, 0.8, 1.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3, 29, 1, 596, 8]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [2, 24, 0, 91, 0]
psl_acc(PSL 평가에서의 정확도):  0.184 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.6666666865348816, 0.8275862336158752, 0.0, 0.15268456935882568, 0.0]
loss for labeled data =>  tensor(0.0629, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.4739, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 80, Time: 0:28:04
Train F1: 0.8816, Val F1: 0.1905, Test F1: 0.2061
Epoch 16/20, Train Acc: 0.8800, Val Acc: 0.1735, Test Acc: 0.2421, Test F1(macro): 0.2061, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 2, Train Data Number: 25

**pseudo_label ->  [0.0004, 0.001, 0.0005, 0.9977, 0.0005] **
max =  0.9977 | max_idx =  3
**pseudo_label ->  [0.0026, 0.006, 0.0237, 0.5124, 0.4553] **
max =  0.5124 | max_idx =  3
**pseudo_label ->  [0.0026, 0.0672, 0.0474, 0.7988, 0.0839] **
max =  0.7988 | max_idx =  3
**pseudo_label ->  [0.0032, 0.9462, 0.0162, 0.0296, 0.0048] **
max =  0.9462 | max_idx =  1
**pseudo_label ->  [0.002, 0.0005, 0.0006, 0.9962, 0.0007] **
max =  0.9962 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.6, 1.0, 0.8, 1.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 47, 18, 486, 22]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 27, 4, 70, 4]
psl_acc(PSL 평가에서의 정확도):  0.183 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.5744680762290955, 0.2222222238779068, 0.14403292536735535, 0.1818181872367859]
loss for labeled data =>  tensor(0.0191, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.6477, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 85, Time: 0:29:52
Train F1: 0.8816, Val F1: 0.1506, Test F1: 0.2162
Epoch 17/20, Train Acc: 0.8800, Val Acc: 0.1224, Test Acc: 0.2421, Test F1(macro): 0.2162, Total Pseudo-Labels: 3, Correct Pseudo-Labels: 0, Train Data Number: 25

**pseudo_label ->  [0.0007, 0.0009, 0.0004, 0.9976, 0.0004] **
max =  0.9976 | max_idx =  3
**pseudo_label ->  [0.0004, 0.0065, 0.0022, 0.9898, 0.0011] **
max =  0.9898 | max_idx =  3
**pseudo_label ->  [0.0007, 0.013, 0.0087, 0.9743, 0.0033] **
max =  0.9743 | max_idx =  3
**pseudo_label ->  [0.0039, 0.0092, 0.39, 0.5668, 0.0301] **
max =  0.5668 | max_idx =  3
**pseudo_label ->  [0.0005, 0.0017, 0.0028, 0.9931, 0.0019] **
max =  0.9931 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.6, 1.0, 0.8, 1.0, 0.6]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 35, 0, 662, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 26, 0, 102, 0]
psl_acc(PSL 평가에서의 정확도):  0.184 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.7428571581840515, nan, 0.15407854318618774, nan]
loss for labeled data =>  tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.4188, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 90, Time: 0:31:38
Train F1: 0.8111, Val F1: 0.1544, Test F1: 0.2077
Epoch 18/20, Train Acc: 0.8000, Val Acc: 0.1531, Test Acc: 0.2526, Test F1(macro): 0.2077, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 2, Train Data Number: 25

**pseudo_label ->  [0.0022, 0.0007, 0.0003, 0.996, 0.0008] **
max =  0.996 | max_idx =  3
**pseudo_label ->  [0.0015, 0.0034, 0.0027, 0.9908, 0.0015] **
max =  0.9908 | max_idx =  3
**pseudo_label ->  [0.0004, 0.0012, 0.0003, 0.9978, 0.0003] **
max =  0.9978 | max_idx =  3
**pseudo_label ->  [0.0011, 0.985, 0.0076, 0.0034, 0.0029] **
max =  0.985 | max_idx =  1
**pseudo_label ->  [0.0095, 0.0123, 0.0022, 0.9671, 0.0089] **
max =  0.9671 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.4, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 24, 5, 228, 384]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 12, 1, 37, 82]
psl_acc(PSL 평가에서의 정확도):  0.206 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.5, 0.20000000298023224, 0.16228070855140686, 0.2135416716337204]
loss for labeled data =>  tensor(0.0352, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(0.5054, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 95, Time: 0:33:20
Train F1: 0.1857, Val F1: 0.0787, Test F1: 0.0752
Epoch 19/20, Train Acc: 0.2800, Val Acc: 0.2449, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 2, Train Data Number: 25

**pseudo_label ->  [0.0012, 0.0043, 0.0824, 0.038, 0.8742] **
max =  0.8742 | max_idx =  4
**pseudo_label ->  [0.0089, 0.0125, 0.1736, 0.0992, 0.7058] **
max =  0.7058 | max_idx =  4
**pseudo_label ->  [0.0014, 0.0023, 0.0139, 0.0254, 0.957] **
max =  0.957 | max_idx =  4
**pseudo_label ->  [0.0015, 0.0015, 0.0907, 0.0252, 0.8812] **
max =  0.8812 | max_idx =  4
**pseudo_label ->  [0.0034, 0.0131, 0.7762, 0.1386, 0.0688] **
max =  0.7762 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.2, 0.4, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [1, 14, 4, 0, 667]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 12, 1, 0, 140]
psl_acc(PSL 평가에서의 정확도):  0.223 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.0, 0.8571428656578064, 0.25, nan, 0.209895059466362]
loss for labeled data =>  tensor(0.7732, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8956, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 100, Time: 0:35:07
Train F1: 0.2550, Val F1: 0.0787, Test F1: 0.0752
Epoch 20/20, Train Acc: 0.3200, Val Acc: 0.2449, Test Acc: 0.2316, Test F1(macro): 0.0752, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 1, Train Data Number: 25


Training complete!
Total training took 0:35:07 (h:mm:ss)
Load model from ./experiment/jointmatch/output/5_['unixcoder', 'unixcoder']_[1e-05, 2e-06]_0.7_jointmatch_20_[45]_{'corcode'}_net0.pth
Load model from ./experiment/jointmatch/output/5_['unixcoder', 'unixcoder']_[1e-05, 2e-06]_0.7_jointmatch_20_[45]_{'corcode'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/unixcoder/joint_match//5_['unixcoder', 'unixcoder']_[1e-05, 2e-06]_0.7_jointmatch_20_[45]_{'corcode'}/training_statistics.csv


Best_step:  5 
Best_val_epoch:  1 
best_val_acc:  0.32653061224489793 
best_val_test_acc:  0.28421052631578947 
best_val_test_f1:  0.21840599487658313
Save best record in:  ./experiment/jointmatch/log/unixcoder/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
