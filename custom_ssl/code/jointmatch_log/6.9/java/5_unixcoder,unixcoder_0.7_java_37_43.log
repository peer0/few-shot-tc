current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code
Data set -> jointmatch
save_name: 5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[43]_{'jointmatch'}

data_path:  ../data/jointmatch/java

There are 2 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base']
**tokenizer type =  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base'] 

n_labeled_per_class:  5
train_df samples: 3851
train_labeled_df samples: 35
train_unlabeled_df samples: 3816
Check n_smaples_per_class in the original training set:  {1: 632, 7: 597, 3: 583, 4: 559, 2: 555, 5: 493, 6: 432}
Check n_smaples_per_class in the labeled training set:  {1: 5, 5: 5, 6: 5, 4: 5, 3: 5, 7: 5, 2: 5}
Check n_smaples_per_class in the unlabeled training set:  {1: 627, 7: 592, 3: 578, 4: 554, 2: 550, 5: 488, 6: 427}
n_classes:  7

net_arch:  microsoft/unixcoder-base 
lr:  0.0004 
lr_linear:  0.001 


net_arch:  microsoft/unixcoder-base 
lr:  0.0002 
lr_linear:  0.001 


acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.2, 0.2, 0.6, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(1.9328, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8338, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 1/37, Train Acc: 0.2857, Val Acc: 0.1641, Test Acc: 0.1275, Test F1(macro): 0.1285, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.1387, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0206, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 2/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7937, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.5704, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 3/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.3669, Test F1(macro): 0.0767, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.8, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(2.7522, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.2065, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 4/37, Train Acc: 0.2286, Val Acc: 0.1760, Test Acc: 0.1879, Test F1(macro): 0.0861, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 3

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 70]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 15]
psl_acc(PSL 평가에서의 정확도):  0.214 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.2142857164144516]
loss for labeled data =>  tensor(6.6611, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(7.0712, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 5/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 5, 0, 0, 0, 0, 53]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 11]
psl_acc(PSL 평가에서의 정확도):  0.19 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.0, nan, nan, nan, nan, 0.2075471729040146]
loss for labeled data =>  tensor(4.8632, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.7115, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 6/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 38]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 7]
psl_acc(PSL 평가에서의 정확도):  0.184 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.18421052396297455]
loss for labeled data =>  tensor(3.7606, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.7199, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 7/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 46]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 6]
psl_acc(PSL 평가에서의 정확도):  0.13 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1304347813129425]
loss for labeled data =>  tensor(2.8043, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.2417, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 8/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 54]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 9]
psl_acc(PSL 평가에서의 정확도):  0.167 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1666666716337204]
loss for labeled data =>  tensor(3.0668, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9317, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 9/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 46]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 8]
psl_acc(PSL 평가에서의 정확도):  0.174 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.17391304671764374]
loss for labeled data =>  tensor(2.9772, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8309, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 10/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 54]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 6]
psl_acc(PSL 평가에서의 정확도):  0.111 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1111111119389534]
loss for labeled data =>  tensor(2.7069, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9897, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 11/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 61]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 9]
psl_acc(PSL 평가에서의 정확도):  0.148 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.14754098653793335]
loss for labeled data =>  tensor(2.9794, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8963, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 12/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 50]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 8]
psl_acc(PSL 평가에서의 정확도):  0.16 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1599999964237213]
loss for labeled data =>  tensor(3.0998, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9716, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 13/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 47]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 11]
psl_acc(PSL 평가에서의 정확도):  0.234 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.23404255509376526]
loss for labeled data =>  tensor(2.8284, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7562, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 14/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 39]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 4]
psl_acc(PSL 평가에서의 정확도):  0.103 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.10256410390138626]
loss for labeled data =>  tensor(2.8917, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7110, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 15/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 44]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 6]
psl_acc(PSL 평가에서의 정확도):  0.136 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.13636364042758942]
loss for labeled data =>  tensor(2.6620, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9081, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 16/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 51]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 12]
psl_acc(PSL 평가에서의 정확도):  0.235 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.23529411852359772]
loss for labeled data =>  tensor(2.8805, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9733, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 17/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 52]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 6]
psl_acc(PSL 평가에서의 정확도):  0.115 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.11538461595773697]
loss for labeled data =>  tensor(2.8716, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.6532, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 18/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 29]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 4]
psl_acc(PSL 평가에서의 정확도):  0.138 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.13793103396892548]
loss for labeled data =>  tensor(2.6329, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7052, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 19/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 33]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 6]
psl_acc(PSL 평가에서의 정확도):  0.182 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1818181872367859]
loss for labeled data =>  tensor(2.9322, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9026, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 20/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 1, 0, 0, 57]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 8]
psl_acc(PSL 평가에서의 정확도):  0.138 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.0, nan, nan, 0.14035087823867798]
loss for labeled data =>  tensor(2.9037, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9248, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 21/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 35]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 4]
psl_acc(PSL 평가에서의 정확도):  0.114 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.11428571492433548]
loss for labeled data =>  tensor(3.4076, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7169, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 22/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 1, 0, 49]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 9]
psl_acc(PSL 평가에서의 정확도):  0.18 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.0, nan, 0.18367347121238708]
loss for labeled data =>  tensor(2.8492, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8668, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 23/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 3

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 1, 0, 54]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 7]
psl_acc(PSL 평가에서의 정확도):  0.127 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.0, nan, 0.12962962687015533]
loss for labeled data =>  tensor(2.8554, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8366, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 24/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 2, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 40]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 5]
psl_acc(PSL 평가에서의 정확도):  0.125 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.125]
loss for labeled data =>  tensor(2.9196, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7769, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 25/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 60]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 16]
psl_acc(PSL 평가에서의 정확도):  0.267 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.2666666805744171]
loss for labeled data =>  tensor(2.9063, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9422, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 26/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 51]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 9]
psl_acc(PSL 평가에서의 정확도):  0.176 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1764705926179886]
loss for labeled data =>  tensor(2.7370, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8792, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 27/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 45]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 7]
psl_acc(PSL 평가에서의 정확도):  0.156 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.15555556118488312]
loss for labeled data =>  tensor(2.8089, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9306, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 28/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 40]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 7]
psl_acc(PSL 평가에서의 정확도):  0.175 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.17499999701976776]
loss for labeled data =>  tensor(2.7598, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7722, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 29/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 61]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 5]
psl_acc(PSL 평가에서의 정확도):  0.082 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.08196721225976944]
loss for labeled data =>  tensor(2.8271, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.6990, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 30/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 48]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 7]
psl_acc(PSL 평가에서의 정확도):  0.146 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1458333283662796]
loss for labeled data =>  tensor(2.9751, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7955, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 31/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 65]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 12]
psl_acc(PSL 평가에서의 정확도):  0.185 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1846153885126114]
loss for labeled data =>  tensor(2.8058, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8019, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 32/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 2, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 28]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 4]
psl_acc(PSL 평가에서의 정확도):  0.143 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1428571492433548]
loss for labeled data =>  tensor(2.5289, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7901, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 33/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 3, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 2, 0, 0, 0, 0, 15]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 1, 0, 0, 0, 0, 3]
psl_acc(PSL 평가에서의 정확도):  0.235 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.5, nan, nan, nan, nan, 0.20000000298023224]
loss for labeled data =>  tensor(2.7910, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7333, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 34/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 1, 0, 0, 0, 0, 2]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 1, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.333 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 1.0, nan, nan, nan, nan, 0.0]
loss for labeled data =>  tensor(2.3948, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.3834, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 35/37, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [1, 1, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.0 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.0, 0.0, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.8702, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1252, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 36/37, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(2.3565, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0170, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 37/37, Train Acc: 0.1429, Val Acc: 0.2064, Test Acc: 0.0425, Test F1(macro): 0.0116, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

Training complete!
Total training took 1:28:49 (h:mm:ss)
Load model from ./experiment/jointmatch/output/5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[43]_{'jointmatch'}_net0.pth
Load model from ./experiment/jointmatch/output/5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[43]_{'jointmatch'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/unixcoder/joint_match//5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[43]_{'jointmatch'}/training_statistics.csv


Best_step:  36 
Best_val_epoch:  37 
best_val_acc:  0.20642978003384094 
best_val_test_acc:  0.042505592841163314 
best_val_test_f1:  0.011649294911097488
Save best record in:  ./experiment/jointmatch/log/unixcoder/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
