current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code
Data set -> jointmatch
save_name: 10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_37_[42]_{'jointmatch'}

data_path:  ../data/jointmatch/java

There are 2 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding']
**tokenizer type =  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding'] 

n_labeled_per_class:  10
train_df samples: 3851
train_labeled_df samples: 70
train_unlabeled_df samples: 3781
Check n_smaples_per_class in the original training set:  {1: 632, 7: 597, 3: 583, 4: 559, 2: 555, 5: 493, 6: 432}
Check n_smaples_per_class in the labeled training set:  {2: 10, 4: 10, 1: 10, 3: 10, 5: 10, 7: 10, 6: 10}
Check n_smaples_per_class in the unlabeled training set:  {1: 622, 7: 587, 3: 573, 4: 549, 2: 545, 5: 483, 6: 422}
n_classes:  7

net_arch:  Salesforce/codet5p-110m-embedding 
lr:  0.0003 
lr_linear:  0.001 


net_arch:  Salesforce/codet5p-110m-embedding 
lr:  0.00025 
lr_linear:  0.001 


acc_train_cw(현재 train의 class별 acc) [0.7, 0.0, 0.3, 0.0, 0.4, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(1.9361, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9552, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 1/37, Train Acc: 0.2000, Val Acc: 0.2521, Test Acc: 0.1096, Test F1(macro): 0.0599, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.8, 0.0, 0.0, 0.1, 0.2, 0.3]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.8099, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8350, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 2/37, Train Acc: 0.2000, Val Acc: 0.1320, Test Acc: 0.2013, Test F1(macro): 0.0891, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.1, 0.4, 0.1, 0.1, 0.1]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.6578, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.6844, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 3/37, Train Acc: 0.2571, Val Acc: 0.1387, Test Acc: 0.1387, Test F1(macro): 0.0407, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.3, 0.1, 0.2, 0.1, 0.1, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.7128, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.6544, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 4/37, Train Acc: 0.2571, Val Acc: 0.0203, Test Acc: 0.0268, Test F1(macro): 0.0230, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.6, 0.5, 0.1, 0.1, 0.2, 0.2, 0.4]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.6320, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.5676, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 5/37, Train Acc: 0.3000, Val Acc: 0.0998, Test Acc: 0.1812, Test F1(macro): 0.1109, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.6, 0.1, 0.1, 0.1, 0.5, 0.1]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.6901, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.5447, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 6/37, Train Acc: 0.2857, Val Acc: 0.1946, Test Acc: 0.1812, Test F1(macro): 0.1211, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.2, 0.4, 0.1, 0.5, 0.1, 0.3, 0.6]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.6215, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.4960, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 7/37, Train Acc: 0.3143, Val Acc: 0.1574, Test Acc: 0.1119, Test F1(macro): 0.1060, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.4, 0.6, 0.1, 0.1, 0.1, 0.2, 0.7]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.6831, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.4478, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 8/37, Train Acc: 0.3143, Val Acc: 0.1455, Test Acc: 0.1298, Test F1(macro): 0.1011, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.3, 0.6, 0.1, 0.1, 0.1, 0.4, 0.3]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.5289, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.4152, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 9/37, Train Acc: 0.2714, Val Acc: 0.1878, Test Acc: 0.1879, Test F1(macro): 0.1226, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.6, 0.1, 0.1, 0.1, 0.3, 0.3]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.4630, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3979, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 10/37, Train Acc: 0.2286, Val Acc: 0.1489, Test Acc: 0.0984, Test F1(macro): 0.0812, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.4, 0.6, 0.1, 0.1, 0.1, 0.3, 0.4]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.4114, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3830, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 11/37, Train Acc: 0.2857, Val Acc: 0.1523, Test Acc: 0.1499, Test F1(macro): 0.1136, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.5, 0.1, 0.1, 0.1, 0.4, 0.4]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3836, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3715, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 12/37, Train Acc: 0.3000, Val Acc: 0.1404, Test Acc: 0.1879, Test F1(macro): 0.1178, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3577, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3585, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 13/37, Train Acc: 0.3143, Val Acc: 0.1387, Test Acc: 0.1611, Test F1(macro): 0.1006, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3406, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3466, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 14/37, Train Acc: 0.3143, Val Acc: 0.1438, Test Acc: 0.1790, Test F1(macro): 0.1228, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.1, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3243, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3373, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 15/37, Train Acc: 0.3000, Val Acc: 0.1421, Test Acc: 0.1790, Test F1(macro): 0.1105, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3102, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3286, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 16/37, Train Acc: 0.3143, Val Acc: 0.1286, Test Acc: 0.1745, Test F1(macro): 0.1050, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2986, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3176, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 17/37, Train Acc: 0.3143, Val Acc: 0.1404, Test Acc: 0.1745, Test F1(macro): 0.1151, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.6, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2863, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3073, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 18/37, Train Acc: 0.3286, Val Acc: 0.1404, Test Acc: 0.1723, Test F1(macro): 0.1096, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2736, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2973, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 19/37, Train Acc: 0.3143, Val Acc: 0.1371, Test Acc: 0.1723, Test F1(macro): 0.1115, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.6, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2630, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2861, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 20/37, Train Acc: 0.3286, Val Acc: 0.1371, Test Acc: 0.1678, Test F1(macro): 0.0934, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.6, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2502, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2750, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 21/37, Train Acc: 0.3286, Val Acc: 0.1438, Test Acc: 0.1767, Test F1(macro): 0.1055, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.6, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2373, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2669, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 22/37, Train Acc: 0.3286, Val Acc: 0.1320, Test Acc: 0.1767, Test F1(macro): 0.1124, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2254, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2587, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 23/37, Train Acc: 0.3143, Val Acc: 0.1354, Test Acc: 0.1767, Test F1(macro): 0.1238, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.6, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2142, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2469, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 24/37, Train Acc: 0.3286, Val Acc: 0.1337, Test Acc: 0.1700, Test F1(macro): 0.0935, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2020, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2375, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 25/37, Train Acc: 0.3143, Val Acc: 0.1371, Test Acc: 0.1767, Test F1(macro): 0.1173, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1912, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2284, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 26/37, Train Acc: 0.3143, Val Acc: 0.1387, Test Acc: 0.1812, Test F1(macro): 0.1246, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1806, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2201, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 27/37, Train Acc: 0.3143, Val Acc: 0.1286, Test Acc: 0.1745, Test F1(macro): 0.1016, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1680, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2110, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 28/37, Train Acc: 0.3143, Val Acc: 0.1387, Test Acc: 0.1767, Test F1(macro): 0.1205, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1571, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2003, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 29/37, Train Acc: 0.3143, Val Acc: 0.1404, Test Acc: 0.1767, Test F1(macro): 0.1164, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1460, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1898, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 30/37, Train Acc: 0.3143, Val Acc: 0.1354, Test Acc: 0.1723, Test F1(macro): 0.1117, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1357, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1802, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 31/37, Train Acc: 0.3143, Val Acc: 0.1421, Test Acc: 0.1745, Test F1(macro): 0.1210, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1252, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1713, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 32/37, Train Acc: 0.3143, Val Acc: 0.1371, Test Acc: 0.1745, Test F1(macro): 0.1009, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1140, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1620, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 33/37, Train Acc: 0.3143, Val Acc: 0.1472, Test Acc: 0.1700, Test F1(macro): 0.1107, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1039, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1533, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 34/37, Train Acc: 0.3143, Val Acc: 0.1472, Test Acc: 0.1745, Test F1(macro): 0.1149, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0934, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1435, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 35/37, Train Acc: 0.3143, Val Acc: 0.1387, Test Acc: 0.1745, Test F1(macro): 0.1015, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0839, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1355, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 36/37, Train Acc: 0.3143, Val Acc: 0.1354, Test Acc: 0.1745, Test F1(macro): 0.0988, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.5, 0.4, 0.1, 0.2, 0.1, 0.4, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0718, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1264, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 37/37, Train Acc: 0.3143, Val Acc: 0.1472, Test Acc: 0.1745, Test F1(macro): 0.1017, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

Training complete!
Total training took 3:12:52 (h:mm:ss)
Load model from ./experiment/jointmatch/output/10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_37_[42]_{'jointmatch'}_net0.pth
Load model from ./experiment/jointmatch/output/10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_37_[42]_{'jointmatch'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/codet5p/joint_match//10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_37_[42]_{'jointmatch'}/training_statistics.csv


Best_step:  0 
Best_val_epoch:  1 
best_val_acc:  0.2521150592216582 
best_val_test_acc:  0.10961968680089486 
best_val_test_f1:  0.059877791585108656
Save best record in:  ./experiment/jointmatch/log/codet5p/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
