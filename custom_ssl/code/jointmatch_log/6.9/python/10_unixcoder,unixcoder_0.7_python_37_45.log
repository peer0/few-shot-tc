current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code
Data set -> jointmatch
save_name: 10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[45]_{'jointmatch'}

data_path:  ../data/jointmatch/python

There are 2 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base']
**tokenizer type =  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base'] 

n_labeled_per_class:  10
train_df samples: 3974
train_labeled_df samples: 70
train_unlabeled_df samples: 3904
Check n_smaples_per_class in the original training set:  {3: 707, 1: 704, 4: 585, 5: 580, 2: 514, 7: 458, 6: 426}
Check n_smaples_per_class in the labeled training set:  {6: 10, 2: 10, 3: 10, 7: 10, 5: 10, 1: 10, 4: 10}
Check n_smaples_per_class in the unlabeled training set:  {3: 697, 1: 694, 4: 575, 5: 570, 2: 504, 7: 448, 6: 416}
n_classes:  7

net_arch:  microsoft/unixcoder-base 
lr:  0.0004 
lr_linear:  0.001 


net_arch:  microsoft/unixcoder-base 
lr:  0.0002 
lr_linear:  0.001 


acc_train_cw(현재 train의 class별 acc) [0.0, 0.1, 0.2, 0.5, 0.1, 0.3, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(1.9564, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0228, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 1/37, Train Acc: 0.1714, Val Acc: 0.2248, Test Acc: 0.1148, Test F1(macro): 0.0722, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9332, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.2035, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 2/37, Train Acc: 0.1429, Val Acc: 0.0261, Test Acc: 0.2971, Test F1(macro): 0.0654, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.1752, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.3425, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 3/37, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 4, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.0 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, 0.0, nan]
loss for labeled data =>  tensor(3.1393, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.4385, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 4/37, Train Acc: 0.1429, Val Acc: 0.0261, Test Acc: 0.2971, Test F1(macro): 0.0654, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 69, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 9, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.13 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1304347813129425, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(7.0048, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(6.2324, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 5/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 64, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 7, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.109 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.109375, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(4.3340, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.4287, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 6/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 51, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 8, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.157 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1568627506494522, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(4.3366, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.4651, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 7/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 53, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 4, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.075 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.07547169923782349, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.3644, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7014, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 8/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 56, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 5, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.089 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.0892857164144516, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9319, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.1033, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 9/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 56, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 6, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.107 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1071428582072258, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.0033, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7707, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 10/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 40, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 2, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.05 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.05000000074505806, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9837, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8851, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 11/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 61, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 9, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.148 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.14754098653793335, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9628, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8451, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 12/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 42, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 7, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.167 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1666666716337204, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.6729, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7819, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 13/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 49, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 1, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.02 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.020408162847161293, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7328, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8406, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 14/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 53, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 7, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.132 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1320754736661911, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8315, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.1959, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 15/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 52, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 9, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.173 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.17307692766189575, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9501, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7667, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 16/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 37, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.0 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.0, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9464, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7404, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 17/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 30, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 5, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.167 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1666666716337204, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7122, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7902, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 18/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 52, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 10, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.192 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.19230769574642181, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9878, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8334, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 19/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 3, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 48, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 5, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.104 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1041666641831398, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8182, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9174, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 20/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 27, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 9, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.333 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.3333333432674408, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7467, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.6337, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 21/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 35, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 10, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.286 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.2857142984867096, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.0109, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9113, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 22/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 57, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 6, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.105 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.10526315867900848, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9467, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8743, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 23/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 54, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 5, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.093 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.09259258955717087, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9152, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8443, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 24/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 46, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 8, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.174 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.17391304671764374, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8315, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8801, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 25/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 49, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 6, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.122 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.12244898080825806, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8572, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8421, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 26/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 2, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 29, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 3, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.103 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1034482792019844, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.5752, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7639, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 27/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 26, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.0 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.0, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9238, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7411, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 28/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 53, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 4, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.075 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.07547169923782349, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8980, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9210, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 29/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 50, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 2, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.04 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.03999999910593033, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8574, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9299, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 30/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 44, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 7, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.159 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.15909090638160706, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7050, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8041, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 31/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 4

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 53, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 12, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.226 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.22641509771347046, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9120, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8807, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 32/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 58, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 10, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.172 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.17241379618644714, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8733, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7501, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 33/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 46, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 11, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.239 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.239130437374115, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8185, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.0385, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 34/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 47, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 6, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.128 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.12765957415103912, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9042, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7727, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 35/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 46, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 4, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.087 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.08695652335882187, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9320, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8117, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 36/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 60, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 7, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.117 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.11666666716337204, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7961, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8745, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 37/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 0

Training complete!
Total training took 1:31:21 (h:mm:ss)
Load model from ./experiment/jointmatch/output/10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[45]_{'jointmatch'}_net0.pth
Load model from ./experiment/jointmatch/output/10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[45]_{'jointmatch'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/unixcoder/joint_match//10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[45]_{'jointmatch'}/training_statistics.csv


Best_step:  0 
Best_val_epoch:  1 
best_val_acc:  0.2247557003257329 
best_val_test_acc:  0.11475409836065574 
best_val_test_f1:  0.07221689354576123
Save best record in:  ./experiment/jointmatch/log/unixcoder/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
