current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code
Data set -> jointmatch
save_name: 10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_37_[43]_{'jointmatch'}

data_path:  ../data/jointmatch/python

There are 2 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding']
**tokenizer type =  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding'] 

n_labeled_per_class:  10
train_df samples: 3974
train_labeled_df samples: 70
train_unlabeled_df samples: 3904
Check n_smaples_per_class in the original training set:  {3: 707, 1: 704, 4: 585, 5: 580, 2: 514, 7: 458, 6: 426}
Check n_smaples_per_class in the labeled training set:  {2: 10, 5: 10, 3: 10, 7: 10, 4: 10, 6: 10, 1: 10}
Check n_smaples_per_class in the unlabeled training set:  {3: 697, 1: 694, 4: 575, 5: 570, 2: 504, 7: 448, 6: 416}
n_classes:  7

net_arch:  Salesforce/codet5p-110m-embedding 
lr:  0.0003 
lr_linear:  0.001 


net_arch:  Salesforce/codet5p-110m-embedding 
lr:  0.00025 
lr_linear:  0.001 


acc_train_cw(현재 train의 class별 acc) [0.0, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(1.9366, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9467, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 1/37, Train Acc: 0.0857, Val Acc: 0.0651, Test Acc: 0.1107, Test F1(macro): 0.0480, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.2, 0.7, 0.0, 0.1, 0.0, 0.1, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.8154, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8143, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 2/37, Train Acc: 0.1571, Val Acc: 0.0261, Test Acc: 0.2746, Test F1(macro): 0.1104, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.3, 1.0, 0.2, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(1.7153, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.6505, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 3/37, Train Acc: 0.2857, Val Acc: 0.2378, Test Acc: 0.1270, Test F1(macro): 0.0510, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.1, 0.0, 0.3, 0.0, 0.1, 0.9]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.6251, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.6935, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 4/37, Train Acc: 0.2143, Val Acc: 0.1498, Test Acc: 0.0574, Test F1(macro): 0.0391, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [1.0, 0.3, 0.0, 0.2, 0.2, 0.1, 0.1]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.6933, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.5366, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 5/37, Train Acc: 0.2714, Val Acc: 0.1075, Test Acc: 0.0922, Test F1(macro): 0.0422, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.4, 0.1, 0.4, 0.2, 0.4, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.5504, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.5390, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 6/37, Train Acc: 0.2571, Val Acc: 0.1401, Test Acc: 0.2664, Test F1(macro): 0.1966, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.1, 0.0, 1.0, 0.1, 0.0, 0.1]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(1.6830, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.5037, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 7/37, Train Acc: 0.1857, Val Acc: 0.3876, Test Acc: 0.1557, Test F1(macro): 0.0388, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.7, 0.0, 0.1, 0.2, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.5337, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.4806, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 8/37, Train Acc: 0.2000, Val Acc: 0.0847, Test Acc: 0.2828, Test F1(macro): 0.1257, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.1, 0.4, 0.2, 0.2, 0.4]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.5391, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.4414, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 9/37, Train Acc: 0.2286, Val Acc: 0.2248, Test Acc: 0.2336, Test F1(macro): 0.1672, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.4, 0.1, 0.7, 0.2, 0.2, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.4442, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.4094, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 10/37, Train Acc: 0.2714, Val Acc: 0.1857, Test Acc: 0.3730, Test F1(macro): 0.2330, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.3, 0.2, 0.7, 0.3, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3957, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3900, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 11/37, Train Acc: 0.2714, Val Acc: 0.1954, Test Acc: 0.2152, Test F1(macro): 0.1655, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.2, 0.7, 0.2, 0.2, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3766, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3777, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 12/37, Train Acc: 0.2571, Val Acc: 0.1987, Test Acc: 0.2172, Test F1(macro): 0.1620, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.2, 0.7, 0.2, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3556, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3663, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 13/37, Train Acc: 0.2429, Val Acc: 0.2378, Test Acc: 0.1783, Test F1(macro): 0.1403, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.2, 0.4, 0.2, 0.6, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3416, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3544, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 14/37, Train Acc: 0.2571, Val Acc: 0.2215, Test Acc: 0.1947, Test F1(macro): 0.1524, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.1, 0.8, 0.2, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3270, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3453, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 15/37, Train Acc: 0.2429, Val Acc: 0.2313, Test Acc: 0.1967, Test F1(macro): 0.1489, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.1, 0.7, 0.2, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3129, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3349, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 16/37, Train Acc: 0.2286, Val Acc: 0.2476, Test Acc: 0.1557, Test F1(macro): 0.1243, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.1, 0.8, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.3009, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3269, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 17/37, Train Acc: 0.2286, Val Acc: 0.2476, Test Acc: 0.1598, Test F1(macro): 0.1183, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.1, 0.8, 0.1, 0.2, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2871, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3162, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 18/37, Train Acc: 0.2429, Val Acc: 0.2378, Test Acc: 0.1988, Test F1(macro): 0.1402, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.1, 0.8, 0.2, 0.2, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2748, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3066, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 19/37, Train Acc: 0.2571, Val Acc: 0.2345, Test Acc: 0.1885, Test F1(macro): 0.1343, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.1, 0.8, 0.1, 0.2, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2636, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2979, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 20/37, Train Acc: 0.2429, Val Acc: 0.2280, Test Acc: 0.2111, Test F1(macro): 0.1392, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.1, 0.7, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2508, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2925, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 21/37, Train Acc: 0.2143, Val Acc: 0.2443, Test Acc: 0.1762, Test F1(macro): 0.1192, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.3, 0.1, 0.7, 0.1, 0.2, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2392, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2918, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 22/37, Train Acc: 0.2429, Val Acc: 0.1759, Test Acc: 0.1906, Test F1(macro): 0.1263, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.1, 0.9, 0.2, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2271, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2986, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 23/37, Train Acc: 0.2571, Val Acc: 0.2671, Test Acc: 0.1107, Test F1(macro): 0.0766, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.1, 0.8, 0.1, 0.1, 0.3]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2158, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3417, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 24/37, Train Acc: 0.2429, Val Acc: 0.2313, Test Acc: 0.1311, Test F1(macro): 0.0776, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.1, 0.7, 0.3, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.2036, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2943, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 25/37, Train Acc: 0.2429, Val Acc: 0.2508, Test Acc: 0.1086, Test F1(macro): 0.0824, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.1, 0.8, 0.1, 0.1, 0.5]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1920, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.5371, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 26/37, Train Acc: 0.2714, Val Acc: 0.2671, Test Acc: 0.0902, Test F1(macro): 0.0585, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.1, 1.0, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1821, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3883, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 27/37, Train Acc: 0.2571, Val Acc: 0.2606, Test Acc: 0.2131, Test F1(macro): 0.1318, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.2, 1.0, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1707, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.3277, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 28/37, Train Acc: 0.2714, Val Acc: 0.2997, Test Acc: 0.1414, Test F1(macro): 0.0753, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.3, 0.1, 1.0, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1588, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.4172, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 29/37, Train Acc: 0.2714, Val Acc: 0.2541, Test Acc: 0.1086, Test F1(macro): 0.0662, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.2, 0.5, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1490, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2676, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 30/37, Train Acc: 0.2000, Val Acc: 0.1987, Test Acc: 0.1578, Test F1(macro): 0.1327, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.2, 0.7, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1373, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.2225, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 31/37, Train Acc: 0.2286, Val Acc: 0.2378, Test Acc: 0.1475, Test F1(macro): 0.1239, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.2, 0.6, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1254, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1994, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 32/37, Train Acc: 0.2143, Val Acc: 0.1857, Test Acc: 0.1168, Test F1(macro): 0.1063, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.2, 0.5, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1151, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1842, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 33/37, Train Acc: 0.2000, Val Acc: 0.1857, Test Acc: 0.1107, Test F1(macro): 0.1030, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.2, 0.6, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.1042, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1731, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 34/37, Train Acc: 0.2143, Val Acc: 0.1987, Test Acc: 0.0963, Test F1(macro): 0.0906, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.2, 0.6, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0935, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1644, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 35/37, Train Acc: 0.2143, Val Acc: 0.1824, Test Acc: 0.1168, Test F1(macro): 0.1077, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.2, 0.5, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0832, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1545, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 36/37, Train Acc: 0.2000, Val Acc: 0.1792, Test Acc: 0.1373, Test F1(macro): 0.1217, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.2, 0.6, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.0720, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1449, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 37/37, Train Acc: 0.2143, Val Acc: 0.1954, Test Acc: 0.0984, Test F1(macro): 0.0934, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

Training complete!
Total training took 1:26:06 (h:mm:ss)
Load model from ./experiment/jointmatch/output/10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_37_[43]_{'jointmatch'}_net0.pth
Load model from ./experiment/jointmatch/output/10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_37_[43]_{'jointmatch'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/codet5p/joint_match//10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_37_[43]_{'jointmatch'}/training_statistics.csv


Best_step:  6 
Best_val_epoch:  7 
best_val_acc:  0.38762214983713356 
best_val_test_acc:  0.1557377049180328 
best_val_test_f1:  0.03877551020408163
Save best record in:  ./experiment/jointmatch/log/codet5p/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
