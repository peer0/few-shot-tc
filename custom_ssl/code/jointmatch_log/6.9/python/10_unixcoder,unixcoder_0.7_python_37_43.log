current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code
Data set -> jointmatch
save_name: 10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[43]_{'jointmatch'}

data_path:  ../data/jointmatch/python

There are 2 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base']
**tokenizer type =  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base'] 

n_labeled_per_class:  10
train_df samples: 3974
train_labeled_df samples: 70
train_unlabeled_df samples: 3904
Check n_smaples_per_class in the original training set:  {3: 707, 1: 704, 4: 585, 5: 580, 2: 514, 7: 458, 6: 426}
Check n_smaples_per_class in the labeled training set:  {2: 10, 5: 10, 3: 10, 7: 10, 4: 10, 6: 10, 1: 10}
Check n_smaples_per_class in the unlabeled training set:  {3: 697, 1: 694, 4: 575, 5: 570, 2: 504, 7: 448, 6: 416}
n_classes:  7

net_arch:  microsoft/unixcoder-base 
lr:  0.0004 
lr_linear:  0.001 


net_arch:  microsoft/unixcoder-base 
lr:  0.0002 
lr_linear:  0.001 


acc_train_cw(현재 train의 class별 acc) [0.0, 0.4, 0.0, 0.0, 0.1, 0.1, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(2.1253, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9923, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 1/37, Train Acc: 0.1143, Val Acc: 0.0293, Test Acc: 0.1680, Test F1(macro): 0.1253, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(2.1277, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1918, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 2/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.0340, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.4448, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 3/37, Train Acc: 0.1429, Val Acc: 0.0261, Test Acc: 0.2971, Test F1(macro): 0.0654, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.1, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(2.4933, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1451, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 4/37, Train Acc: 0.1571, Val Acc: 0.3876, Test Acc: 0.1619, Test F1(macro): 0.0398, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.5057, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.5687, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 5/37, Train Acc: 0.1857, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.1, 0.2, 0.0, 0.5, 0.0, 0.2, 0.2]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7136, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.1195, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 6/37, Train Acc: 0.1714, Val Acc: 0.2117, Test Acc: 0.2049, Test F1(macro): 0.1013, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 29, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 5, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.172 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.17241379618644714, nan, nan]
loss for labeled data =>  tensor(4.2198, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(5.0188, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 7/37, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3, 5, 35]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 6]
psl_acc(PSL 평가에서의 정확도):  0.14 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.0, 0.0, 0.17142857611179352]
loss for labeled data =>  tensor(5.6189, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(5.6496, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 8/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 5, 2, 0, 10, 49]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 1, 8]
psl_acc(PSL 평가에서의 정확도):  0.136 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.0, 0.0, nan, 0.10000000149011612, 0.16326530277729034]
loss for labeled data =>  tensor(7.5443, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.1363, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 9/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 59]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 9]
psl_acc(PSL 평가에서의 정확도):  0.153 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1525423675775528]
loss for labeled data =>  tensor(4.1664, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.3097, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 10/37, Train Acc: 0.1571, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 43]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 4]
psl_acc(PSL 평가에서의 정확도):  0.093 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.09302325546741486]
loss for labeled data =>  tensor(2.8382, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.1261, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 11/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 60]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 5]
psl_acc(PSL 평가에서의 정확도):  0.083 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.0833333358168602]
loss for labeled data =>  tensor(2.9667, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.3779, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 12/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 50]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 6]
psl_acc(PSL 평가에서의 정확도):  0.12 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.11999999731779099]
loss for labeled data =>  tensor(2.8519, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7684, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 13/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 45]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 6]
psl_acc(PSL 평가에서의 정확도):  0.133 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.13333334028720856]
loss for labeled data =>  tensor(2.9271, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7621, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 14/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 59]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 7]
psl_acc(PSL 평가에서의 정확도):  0.119 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.11864406615495682]
loss for labeled data =>  tensor(2.8843, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8371, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 15/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 50]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 8]
psl_acc(PSL 평가에서의 정확도):  0.16 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1599999964237213]
loss for labeled data =>  tensor(2.8303, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7898, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 16/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 55]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 5]
psl_acc(PSL 평가에서의 정확도):  0.091 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.09090909361839294]
loss for labeled data =>  tensor(2.8661, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.6791, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 17/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 46]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 9]
psl_acc(PSL 평가에서의 정확도):  0.196 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.19565217196941376]
loss for labeled data =>  tensor(2.8687, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.6369, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 18/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 57]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 8]
psl_acc(PSL 평가에서의 정확도):  0.14 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.14035087823867798]
loss for labeled data =>  tensor(2.7496, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.1181, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 19/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 29]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 2]
psl_acc(PSL 평가에서의 정확도):  0.069 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.06896551698446274]
loss for labeled data =>  tensor(2.7061, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1711, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 20/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 2, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 19]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 1]
psl_acc(PSL 평가에서의 정확도):  0.053 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.05263157933950424]
loss for labeled data =>  tensor(2.6466, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7378, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 21/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 52]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 7]
psl_acc(PSL 평가에서의 정확도):  0.135 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.13461539149284363]
loss for labeled data =>  tensor(3.0377, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.5411, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 22/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 64]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 5]
psl_acc(PSL 평가에서의 정확도):  0.078 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.078125]
loss for labeled data =>  tensor(2.7169, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.1251, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 23/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 37]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 3]
psl_acc(PSL 평가에서의 정확도):  0.081 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.0810810774564743]
loss for labeled data =>  tensor(2.7948, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8346, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 24/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 52]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 6]
psl_acc(PSL 평가에서의 정확도):  0.115 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.11538461595773697]
loss for labeled data =>  tensor(2.9450, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8547, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 25/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 56]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 7]
psl_acc(PSL 평가에서의 정확도):  0.125 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.125]
loss for labeled data =>  tensor(2.9108, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.0185, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 26/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 50]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 6]
psl_acc(PSL 평가에서의 정확도):  0.12 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.11999999731779099]
loss for labeled data =>  tensor(2.7568, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7498, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 27/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 31]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 2]
psl_acc(PSL 평가에서의 정확도):  0.065 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.06451612710952759]
loss for labeled data =>  tensor(2.6032, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.6937, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 28/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 7]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 2]
psl_acc(PSL 평가에서의 정확도):  0.286 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.2857142984867096]
loss for labeled data =>  tensor(2.4161, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.3807, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 29/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.2262, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0555, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 30/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9939, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9581, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 31/37, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9021, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9174, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 32/37, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0914, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9519, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 33/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0262, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9844, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 34/37, Train Acc: 0.1429, Val Acc: 0.3876, Test Acc: 0.1619, Test F1(macro): 0.0398, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0552, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9160, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 35/37, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9398, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9155, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 36/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9591, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9691, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 37/37, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

Training complete!
Total training took 1:26:32 (h:mm:ss)
Load model from ./experiment/jointmatch/output/10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[43]_{'jointmatch'}_net0.pth
Load model from ./experiment/jointmatch/output/10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[43]_{'jointmatch'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/unixcoder/joint_match//10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[43]_{'jointmatch'}/training_statistics.csv


Best_step:  3 
Best_val_epoch:  4 
best_val_acc:  0.38762214983713356 
best_val_test_acc:  0.16188524590163936 
best_val_test_f1:  0.0398085159989922
Save best record in:  ./experiment/jointmatch/log/unixcoder/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
