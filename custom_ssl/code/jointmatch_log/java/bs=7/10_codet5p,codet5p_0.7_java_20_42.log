current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code

bs =>  7
Data set -> jointmatch
save_name: 10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_20_[42]_{'java'}

data_path:  ../data/jointmatch/java

There are 1 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding']
**tokenizer type =  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding'] 

n_labeled_per_class:  10
train_df samples: 3851
train_labeled_df samples: 70
train_unlabeled_df samples: 3781
Check n_smaples_per_class in the original training set:  OrderedDict([(1, 632), (2, 555), (3, 583), (4, 559), (5, 493), (6, 432), (7, 597)])
Check n_smaples_per_class in the labeled training set:  OrderedDict([(1, 10), (2, 10), (3, 10), (4, 10), (5, 10), (6, 10), (7, 10)])
Check n_smaples_per_class in the unlabeled training set:  OrderedDict([(1, 622), (2, 545), (3, 573), (4, 549), (5, 483), (6, 422), (7, 587)])
n_classes:  7

net_arch:  Salesforce/codet5p-110m-embedding 
lr:  0.0003 
lr_linear:  0.001 


net_arch:  Salesforce/codet5p-110m-embedding 
lr:  0.00025 
lr_linear:  0.001 

**pseudo_label ->  [0.1478, 0.1888, 0.1427, 0.1094, 0.1337, 0.1418, 0.1358] **
max =  0.1888 | max_idx =  1
**pseudo_label ->  [0.1274, 0.1839, 0.144, 0.1082, 0.1298, 0.1623, 0.1445] **
max =  0.1839 | max_idx =  1
**pseudo_label ->  [0.2155, 0.1482, 0.147, 0.1165, 0.1237, 0.1342, 0.1149] **
max =  0.2155 | max_idx =  0
**pseudo_label ->  [0.2038, 0.1304, 0.1523, 0.1376, 0.1256, 0.1305, 0.1197] **
max =  0.2038 | max_idx =  0
**pseudo_label ->  [0.1228, 0.1856, 0.1441, 0.1132, 0.1357, 0.1521, 0.1465] **
max =  0.1856 | max_idx =  1
**pseudo_label ->  [0.1008, 0.1331, 0.1485, 0.1423, 0.1572, 0.1408, 0.1773] **
max =  0.1773 | max_idx =  6
**pseudo_label ->  [0.1019, 0.1284, 0.1527, 0.1457, 0.152, 0.1412, 0.1781] **
max =  0.1781 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.2, 0.8, 0.5, 0.0, 0.8]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.8259, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9042, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 10, Time: 0:05:55
Train F1: 0.2495, Val F1: 0.0823, Test F1: 0.0807
Epoch 1/20, Train Acc: 0.3286, Val Acc: 0.1387, Test Acc: 0.0940, Test F1(macro): 0.0807, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1366, 0.2089, 0.1318, 0.1191, 0.1454, 0.1081, 0.15] **
max =  0.2089 | max_idx =  1
**pseudo_label ->  [0.1321, 0.2092, 0.1306, 0.113, 0.1606, 0.1061, 0.1484] **
max =  0.2092 | max_idx =  1
**pseudo_label ->  [0.1304, 0.2263, 0.1278, 0.1033, 0.152, 0.1118, 0.1483] **
max =  0.2263 | max_idx =  1
**pseudo_label ->  [0.125, 0.192, 0.1413, 0.1056, 0.1796, 0.1155, 0.1409] **
max =  0.192 | max_idx =  1
**pseudo_label ->  [0.1439, 0.1531, 0.1391, 0.1245, 0.1311, 0.1395, 0.1687] **
max =  0.1687 | max_idx =  6
**pseudo_label ->  [0.136, 0.1843, 0.1334, 0.145, 0.1461, 0.0979, 0.1573] **
max =  0.1843 | max_idx =  1
**pseudo_label ->  [0.1523, 0.1133, 0.1449, 0.1839, 0.1354, 0.1098, 0.1603] **
max =  0.1839 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.2, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.7973, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8822, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 20, Time: 0:12:24
Train F1: 0.0842, Val F1: 0.0972, Test F1: 0.0165
Epoch 2/20, Train Acc: 0.1714, Val Acc: 0.2166, Test Acc: 0.0604, Test F1(macro): 0.0165, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1429, 0.1219, 0.1305, 0.2225, 0.1244, 0.105, 0.1529] **
max =  0.2225 | max_idx =  3
**pseudo_label ->  [0.1453, 0.1193, 0.1356, 0.2224, 0.1226, 0.1023, 0.1525] **
max =  0.2224 | max_idx =  3
**pseudo_label ->  [0.1432, 0.1229, 0.1279, 0.2223, 0.1273, 0.1037, 0.1528] **
max =  0.2223 | max_idx =  3
**pseudo_label ->  [0.1473, 0.1287, 0.128, 0.2199, 0.1235, 0.1015, 0.1511] **
max =  0.2199 | max_idx =  3
**pseudo_label ->  [0.1464, 0.1249, 0.1295, 0.2225, 0.1212, 0.1034, 0.1521] **
max =  0.2225 | max_idx =  3
**pseudo_label ->  [0.1485, 0.1156, 0.135, 0.2233, 0.1204, 0.1049, 0.1524] **
max =  0.2233 | max_idx =  3
**pseudo_label ->  [0.1465, 0.1197, 0.1308, 0.2251, 0.12, 0.1057, 0.1521] **
max =  0.2251 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.8626, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8948, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 30, Time: 0:18:17
Train F1: 0.0362, Val F1: 0.0357, Test F1: 0.0338
Epoch 3/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1456, 0.1634, 0.155, 0.1453, 0.1266, 0.1148, 0.1492] **
max =  0.1634 | max_idx =  1
**pseudo_label ->  [0.1469, 0.1664, 0.1526, 0.1372, 0.1324, 0.114, 0.1505] **
max =  0.1664 | max_idx =  1
**pseudo_label ->  [0.1477, 0.1657, 0.1547, 0.1373, 0.1285, 0.1152, 0.1509] **
max =  0.1657 | max_idx =  1
**pseudo_label ->  [0.1471, 0.1597, 0.1538, 0.146, 0.1271, 0.1148, 0.1516] **
max =  0.1597 | max_idx =  1
**pseudo_label ->  [0.1508, 0.1721, 0.1502, 0.1362, 0.1267, 0.1172, 0.1468] **
max =  0.1721 | max_idx =  1
**pseudo_label ->  [0.1437, 0.1631, 0.1552, 0.1408, 0.1294, 0.1146, 0.1531] **
max =  0.1631 | max_idx =  1
**pseudo_label ->  [0.1447, 0.1608, 0.1549, 0.1426, 0.1307, 0.114, 0.1524] **
max =  0.1608 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9635, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9086, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 40, Time: 0:24:07
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 4/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1385, 0.0859, 0.1925, 0.1743, 0.1119, 0.1502, 0.1468] **
max =  0.1925 | max_idx =  2
**pseudo_label ->  [0.143, 0.0892, 0.1839, 0.1731, 0.1143, 0.1484, 0.1482] **
max =  0.1839 | max_idx =  2
**pseudo_label ->  [0.142, 0.085, 0.1958, 0.1724, 0.1105, 0.1507, 0.1437] **
max =  0.1958 | max_idx =  2
**pseudo_label ->  [0.1443, 0.0873, 0.1956, 0.1704, 0.1089, 0.1506, 0.1429] **
max =  0.1956 | max_idx =  2
**pseudo_label ->  [0.1408, 0.0846, 0.1958, 0.1732, 0.1075, 0.1532, 0.1449] **
max =  0.1958 | max_idx =  2
**pseudo_label ->  [0.1436, 0.0879, 0.1859, 0.1748, 0.1115, 0.1502, 0.1461] **
max =  0.1859 | max_idx =  2
**pseudo_label ->  [0.1436, 0.0883, 0.1895, 0.1743, 0.1145, 0.1473, 0.1423] **
max =  0.1895 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.8914, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9807, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 50, Time: 0:29:57
Train F1: 0.0362, Val F1: 0.0026, Test F1: 0.0032
Epoch 5/20, Train Acc: 0.1429, Val Acc: 0.0017, Test Acc: 0.0112, Test F1(macro): 0.0032, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1481, 0.0978, 0.1706, 0.14, 0.1175, 0.1674, 0.1585] **
max =  0.1706 | max_idx =  2
**pseudo_label ->  [0.1432, 0.0947, 0.168, 0.1547, 0.1161, 0.1632, 0.1602] **
max =  0.168 | max_idx =  2
**pseudo_label ->  [0.147, 0.0966, 0.1727, 0.1411, 0.1197, 0.1646, 0.1581] **
max =  0.1727 | max_idx =  2
**pseudo_label ->  [0.148, 0.0962, 0.1731, 0.1413, 0.1191, 0.1655, 0.1568] **
max =  0.1731 | max_idx =  2
**pseudo_label ->  [0.1433, 0.0942, 0.1749, 0.1468, 0.1225, 0.1592, 0.159] **
max =  0.1749 | max_idx =  2
**pseudo_label ->  [0.1467, 0.0964, 0.174, 0.1428, 0.1182, 0.1646, 0.1573] **
max =  0.174 | max_idx =  2
**pseudo_label ->  [0.1453, 0.0969, 0.1727, 0.1411, 0.1209, 0.1651, 0.158] **
max =  0.1727 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9641, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9588, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 60, Time: 0:35:48
Train F1: 0.0714, Val F1: 0.0758, Test F1: 0.0525
Epoch 6/20, Train Acc: 0.1714, Val Acc: 0.1218, Test Acc: 0.1298, Test F1(macro): 0.0525, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1401, 0.1565, 0.1302, 0.132, 0.1326, 0.1556, 0.153] **
max =  0.1565 | max_idx =  1
**pseudo_label ->  [0.1217, 0.1369, 0.1306, 0.1462, 0.1612, 0.1356, 0.1678] **
max =  0.1678 | max_idx =  6
**pseudo_label ->  [0.1557, 0.1477, 0.1312, 0.1546, 0.1138, 0.1613, 0.1357] **
max =  0.1613 | max_idx =  5
**pseudo_label ->  [0.1258, 0.1296, 0.1292, 0.1628, 0.1503, 0.1375, 0.1648] **
max =  0.1648 | max_idx =  6
**pseudo_label ->  [0.1468, 0.1559, 0.1313, 0.1309, 0.1271, 0.1557, 0.1522] **
max =  0.1559 | max_idx =  1
**pseudo_label ->  [0.1182, 0.1304, 0.1317, 0.1481, 0.1677, 0.1306, 0.1733] **
max =  0.1733 | max_idx =  6
**pseudo_label ->  [0.1721, 0.1554, 0.1322, 0.1435, 0.103, 0.1691, 0.1246] **
max =  0.1721 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.1, 0.1, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9225, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9341, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 70, Time: 0:41:39
Train F1: 0.0853, Val F1: 0.0674, Test F1: 0.0425
Epoch 7/20, Train Acc: 0.1714, Val Acc: 0.2047, Test Acc: 0.0940, Test F1(macro): 0.0425, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1798, 0.1934, 0.1432, 0.0749, 0.1255, 0.1621, 0.1213] **
max =  0.1934 | max_idx =  1
**pseudo_label ->  [0.1792, 0.1934, 0.1427, 0.0743, 0.1279, 0.1618, 0.1206] **
max =  0.1934 | max_idx =  1
**pseudo_label ->  [0.1829, 0.1933, 0.145, 0.0763, 0.1177, 0.1643, 0.1205] **
max =  0.1933 | max_idx =  1
**pseudo_label ->  [0.1818, 0.193, 0.145, 0.0752, 0.1229, 0.1627, 0.1194] **
max =  0.193 | max_idx =  1
**pseudo_label ->  [0.1799, 0.1936, 0.1425, 0.075, 0.1247, 0.1628, 0.1214] **
max =  0.1936 | max_idx =  1
**pseudo_label ->  [0.1524, 0.1815, 0.1298, 0.0761, 0.1881, 0.1429, 0.1291] **
max =  0.1881 | max_idx =  4
**pseudo_label ->  [0.1807, 0.1931, 0.1445, 0.0747, 0.1241, 0.1626, 0.1204] **
max =  0.1931 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.7779, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8971, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 80, Time: 0:47:30
Train F1: 0.0357, Val F1: 0.0000, Test F1: 0.0767
Epoch 8/20, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.3669, Test F1(macro): 0.0767, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1595, 0.1698, 0.1393, 0.076, 0.1806, 0.1344, 0.1405] **
max =  0.1806 | max_idx =  4
**pseudo_label ->  [0.1686, 0.1753, 0.1424, 0.0751, 0.1629, 0.1378, 0.1379] **
max =  0.1753 | max_idx =  1
**pseudo_label ->  [0.175, 0.1767, 0.1435, 0.0752, 0.154, 0.14, 0.1356] **
max =  0.1767 | max_idx =  1
**pseudo_label ->  [0.1232, 0.1116, 0.1373, 0.241, 0.1144, 0.1413, 0.1312] **
max =  0.241 | max_idx =  3
**pseudo_label ->  [0.185, 0.1807, 0.1455, 0.0754, 0.1354, 0.1449, 0.1332] **
max =  0.185 | max_idx =  0
**pseudo_label ->  [0.1835, 0.1802, 0.1443, 0.0755, 0.1391, 0.1438, 0.1336] **
max =  0.1835 | max_idx =  0
**pseudo_label ->  [0.1159, 0.109, 0.1376, 0.2425, 0.1252, 0.138, 0.1318] **
max =  0.2425 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.1, 0.0, 0.0, 0.1, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0502, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9248, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 90, Time: 0:53:38
Train F1: 0.0845, Val F1: 0.1350, Test F1: 0.0729
Epoch 9/20, Train Acc: 0.1714, Val Acc: 0.2910, Test Acc: 0.2349, Test F1(macro): 0.0729, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.2109, 0.1472, 0.1743, 0.1134, 0.079, 0.1506, 0.1246] **
max =  0.2109 | max_idx =  0
**pseudo_label ->  [0.2106, 0.1477, 0.1729, 0.1135, 0.0787, 0.1507, 0.1259] **
max =  0.2106 | max_idx =  0
**pseudo_label ->  [0.2111, 0.1486, 0.165, 0.1167, 0.0751, 0.1523, 0.1312] **
max =  0.2111 | max_idx =  0
**pseudo_label ->  [0.2108, 0.1486, 0.168, 0.1151, 0.076, 0.1517, 0.1298] **
max =  0.2108 | max_idx =  0
**pseudo_label ->  [0.2111, 0.1476, 0.1729, 0.1132, 0.0789, 0.1508, 0.1257] **
max =  0.2111 | max_idx =  0
**pseudo_label ->  [0.2103, 0.1483, 0.1657, 0.1173, 0.0745, 0.1522, 0.1317] **
max =  0.2103 | max_idx =  0
**pseudo_label ->  [0.211, 0.1485, 0.1674, 0.1156, 0.0759, 0.1515, 0.1301] **
max =  0.211 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.8388, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9493, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 100, Time: 0:59:31
Train F1: 0.0922, Val F1: 0.0575, Test F1: 0.0608
Epoch 10/20, Train Acc: 0.1857, Val Acc: 0.1134, Test Acc: 0.1588, Test F1(macro): 0.0608, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1329, 0.1489, 0.1138, 0.1675, 0.0977, 0.157, 0.1821] **
max =  0.1821 | max_idx =  6
**pseudo_label ->  [0.1263, 0.1473, 0.1089, 0.1661, 0.1092, 0.1561, 0.1862] **
max =  0.1862 | max_idx =  6
**pseudo_label ->  [0.0913, 0.123, 0.1057, 0.1177, 0.2932, 0.1236, 0.1456] **
max =  0.2932 | max_idx =  4
**pseudo_label ->  [0.1229, 0.1468, 0.1067, 0.1642, 0.1156, 0.1553, 0.1885] **
max =  0.1885 | max_idx =  6
**pseudo_label ->  [0.0915, 0.1232, 0.1058, 0.117, 0.2935, 0.124, 0.1451] **
max =  0.2935 | max_idx =  4
**pseudo_label ->  [0.1237, 0.1472, 0.1072, 0.165, 0.1144, 0.1554, 0.1871] **
max =  0.1871 | max_idx =  6
**pseudo_label ->  [0.0913, 0.1234, 0.1053, 0.1176, 0.2925, 0.124, 0.146] **
max =  0.2925 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9936, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9440, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 110, Time: 1:05:21
Train F1: 0.0357, Val F1: 0.0885, Test F1: 0.0531
Epoch 11/20, Train Acc: 0.1429, Val Acc: 0.2843, Test Acc: 0.2282, Test F1(macro): 0.0531, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1044, 0.1371, 0.1437, 0.118, 0.2385, 0.1239, 0.1343] **
max =  0.2385 | max_idx =  4
**pseudo_label ->  [0.1045, 0.1368, 0.1432, 0.1182, 0.239, 0.1239, 0.1344] **
max =  0.239 | max_idx =  4
**pseudo_label ->  [0.1043, 0.1365, 0.1428, 0.1182, 0.2393, 0.1238, 0.1351] **
max =  0.2393 | max_idx =  4
**pseudo_label ->  [0.1043, 0.1372, 0.1431, 0.1179, 0.2384, 0.124, 0.1352] **
max =  0.2384 | max_idx =  4
**pseudo_label ->  [0.1044, 0.1371, 0.1435, 0.1181, 0.2386, 0.1234, 0.1349] **
max =  0.2386 | max_idx =  4
**pseudo_label ->  [0.1044, 0.1368, 0.143, 0.1183, 0.2394, 0.1235, 0.1347] **
max =  0.2394 | max_idx =  4
**pseudo_label ->  [0.1044, 0.1374, 0.1429, 0.118, 0.2387, 0.1237, 0.1349] **
max =  0.2387 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9841, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8890, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 120, Time: 1:11:10
Train F1: 0.1230, Val F1: 0.1146, Test F1: 0.0575
Epoch 12/20, Train Acc: 0.2286, Val Acc: 0.2792, Test Acc: 0.2215, Test F1(macro): 0.0575, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1281, 0.1466, 0.1504, 0.1357, 0.1588, 0.1423, 0.138] **
max =  0.1588 | max_idx =  4
**pseudo_label ->  [0.1271, 0.147, 0.1476, 0.1358, 0.16, 0.143, 0.1396] **
max =  0.16 | max_idx =  4
**pseudo_label ->  [0.1277, 0.1465, 0.1491, 0.1357, 0.1594, 0.1428, 0.1387] **
max =  0.1594 | max_idx =  4
**pseudo_label ->  [0.1279, 0.1468, 0.149, 0.1354, 0.1595, 0.1427, 0.1387] **
max =  0.1595 | max_idx =  4
**pseudo_label ->  [0.1277, 0.1466, 0.1491, 0.1352, 0.1603, 0.1421, 0.1391] **
max =  0.1603 | max_idx =  4
**pseudo_label ->  [0.1273, 0.1463, 0.1498, 0.1361, 0.1601, 0.1422, 0.1383] **
max =  0.1601 | max_idx =  4
**pseudo_label ->  [0.1278, 0.1466, 0.1479, 0.1357, 0.1598, 0.1428, 0.1394] **
max =  0.1598 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.9, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9502, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.7822, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 130, Time: 1:16:59
Train F1: 0.1310, Val F1: 0.0556, Test F1: 0.0333
Epoch 13/20, Train Acc: 0.2143, Val Acc: 0.1083, Test Acc: 0.1253, Test F1(macro): 0.0333, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1442, 0.1431, 0.1454, 0.1432, 0.1389, 0.1445, 0.1408] **
max =  0.1454 | max_idx =  2
**pseudo_label ->  [0.1439, 0.1433, 0.1445, 0.1429, 0.1403, 0.1436, 0.1415] **
max =  0.1445 | max_idx =  2
**pseudo_label ->  [0.1437, 0.1434, 0.1459, 0.1436, 0.1395, 0.1432, 0.1408] **
max =  0.1459 | max_idx =  2
**pseudo_label ->  [0.144, 0.1425, 0.1454, 0.1426, 0.141, 0.1433, 0.1412] **
max =  0.1454 | max_idx =  2
**pseudo_label ->  [0.1428, 0.1432, 0.1432, 0.1429, 0.1416, 0.1436, 0.1427] **
max =  0.1436 | max_idx =  5
**pseudo_label ->  [0.1437, 0.1427, 0.1444, 0.1434, 0.1407, 0.1439, 0.1413] **
max =  0.1444 | max_idx =  2
**pseudo_label ->  [0.1437, 0.1422, 0.1441, 0.1436, 0.1409, 0.1442, 0.1413] **
max =  0.1442 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [0.9, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9468, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0131, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 140, Time: 1:22:48
Train F1: 0.0951, Val F1: 0.0419, Test F1: 0.0329
Epoch 14/20, Train Acc: 0.1714, Val Acc: 0.0998, Test Acc: 0.1298, Test F1(macro): 0.0329, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.142, 0.1432, 0.1391, 0.1433, 0.1443, 0.1433, 0.1449] **
max =  0.1449 | max_idx =  6
**pseudo_label ->  [0.142, 0.1421, 0.1397, 0.1431, 0.1455, 0.1426, 0.1449] **
max =  0.1455 | max_idx =  4
**pseudo_label ->  [0.1413, 0.1433, 0.1374, 0.1428, 0.1452, 0.1431, 0.1469] **
max =  0.1469 | max_idx =  6
**pseudo_label ->  [0.142, 0.1431, 0.141, 0.1429, 0.1438, 0.1424, 0.1448] **
max =  0.1448 | max_idx =  6
**pseudo_label ->  [0.1432, 0.1434, 0.1405, 0.1428, 0.1421, 0.1436, 0.1444] **
max =  0.1444 | max_idx =  6
**pseudo_label ->  [0.1429, 0.1435, 0.1405, 0.1421, 0.1427, 0.1437, 0.1446] **
max =  0.1446 | max_idx =  6
**pseudo_label ->  [0.141, 0.144, 0.14, 0.143, 0.1422, 0.1431, 0.1467] **
max =  0.1467 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9446, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9483, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 150, Time: 1:28:37
Train F1: 0.0357, Val F1: 0.0885, Test F1: 0.0531
Epoch 15/20, Train Acc: 0.1429, Val Acc: 0.2843, Test Acc: 0.2282, Test F1(macro): 0.0531, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1535, 0.1455, 0.1653, 0.1399, 0.1242, 0.143, 0.1286] **
max =  0.1653 | max_idx =  2
**pseudo_label ->  [0.1512, 0.1454, 0.1611, 0.139, 0.1284, 0.1428, 0.132] **
max =  0.1611 | max_idx =  2
**pseudo_label ->  [0.1488, 0.1434, 0.1544, 0.1392, 0.1363, 0.1428, 0.1351] **
max =  0.1544 | max_idx =  2
**pseudo_label ->  [0.1486, 0.1431, 0.1545, 0.1396, 0.1369, 0.1423, 0.135] **
max =  0.1545 | max_idx =  2
**pseudo_label ->  [0.1517, 0.144, 0.1571, 0.1406, 0.1301, 0.1434, 0.1331] **
max =  0.1571 | max_idx =  2
**pseudo_label ->  [0.1486, 0.143, 0.1528, 0.1383, 0.1387, 0.1424, 0.1362] **
max =  0.1528 | max_idx =  2
**pseudo_label ->  [0.1507, 0.1443, 0.157, 0.1391, 0.1322, 0.1434, 0.1332] **
max =  0.157 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.5, 0.0, 0.3, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9407, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9200, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 160, Time: 1:34:26
Train F1: 0.0505, Val F1: 0.0902, Test F1: 0.0435
Epoch 16/20, Train Acc: 0.1143, Val Acc: 0.1574, Test Acc: 0.0984, Test F1(macro): 0.0435, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1551, 0.145, 0.1623, 0.1761, 0.0926, 0.1382, 0.1308] **
max =  0.1761 | max_idx =  3
**pseudo_label ->  [0.155, 0.1456, 0.1627, 0.1755, 0.0921, 0.1382, 0.1309] **
max =  0.1755 | max_idx =  3
**pseudo_label ->  [0.1547, 0.1445, 0.1619, 0.1766, 0.0927, 0.1378, 0.1317] **
max =  0.1766 | max_idx =  3
**pseudo_label ->  [0.1546, 0.1451, 0.161, 0.1762, 0.093, 0.1384, 0.1318] **
max =  0.1762 | max_idx =  3
**pseudo_label ->  [0.1547, 0.1456, 0.1623, 0.1754, 0.0926, 0.1381, 0.1313] **
max =  0.1754 | max_idx =  3
**pseudo_label ->  [0.1551, 0.1457, 0.163, 0.1755, 0.0922, 0.1378, 0.1308] **
max =  0.1755 | max_idx =  3
**pseudo_label ->  [0.1547, 0.1454, 0.1619, 0.1758, 0.0927, 0.1382, 0.1313] **
max =  0.1758 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9348, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.6864, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 170, Time: 1:40:15
Train F1: 0.0376, Val F1: 0.0076, Test F1: 0.0819
Epoch 17/20, Train Acc: 0.1429, Val Acc: 0.0051, Test Acc: 0.3468, Test F1(macro): 0.0819, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1542, 0.1462, 0.1437, 0.1739, 0.1159, 0.1324, 0.1337] **
max =  0.1739 | max_idx =  3
**pseudo_label ->  [0.1544, 0.1457, 0.1441, 0.174, 0.1167, 0.132, 0.1331] **
max =  0.174 | max_idx =  3
**pseudo_label ->  [0.1528, 0.1467, 0.1425, 0.1745, 0.1163, 0.1325, 0.1348] **
max =  0.1745 | max_idx =  3
**pseudo_label ->  [0.1544, 0.1468, 0.1428, 0.1739, 0.1159, 0.1331, 0.1331] **
max =  0.1739 | max_idx =  3
**pseudo_label ->  [0.1551, 0.1456, 0.1444, 0.1737, 0.1159, 0.1323, 0.1331] **
max =  0.1737 | max_idx =  3
**pseudo_label ->  [0.1545, 0.1465, 0.1434, 0.1738, 0.1162, 0.1329, 0.1328] **
max =  0.1738 | max_idx =  3
**pseudo_label ->  [0.1547, 0.1452, 0.1437, 0.1737, 0.1171, 0.1317, 0.1338] **
max =  0.1737 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9523, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9098, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 180, Time: 1:46:04
Train F1: 0.0357, Val F1: 0.0000, Test F1: 0.0767
Epoch 18/20, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.3669, Test F1(macro): 0.0767, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1496, 0.1515, 0.1378, 0.1499, 0.1261, 0.1421, 0.143] **
max =  0.1515 | max_idx =  1
**pseudo_label ->  [0.1491, 0.1516, 0.1371, 0.1494, 0.1263, 0.1421, 0.1444] **
max =  0.1516 | max_idx =  1
**pseudo_label ->  [0.149, 0.1514, 0.1374, 0.1499, 0.126, 0.1424, 0.1439] **
max =  0.1514 | max_idx =  1
**pseudo_label ->  [0.1494, 0.151, 0.138, 0.1495, 0.1263, 0.1416, 0.1442] **
max =  0.151 | max_idx =  1
**pseudo_label ->  [0.1486, 0.1519, 0.1371, 0.1496, 0.1261, 0.1423, 0.1444] **
max =  0.1519 | max_idx =  1
**pseudo_label ->  [0.1494, 0.1515, 0.1372, 0.1492, 0.1271, 0.1422, 0.1434] **
max =  0.1515 | max_idx =  1
**pseudo_label ->  [0.1491, 0.1516, 0.1369, 0.1496, 0.1262, 0.1422, 0.1444] **
max =  0.1516 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9484, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0198, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 190, Time: 1:51:53
Train F1: 0.0357, Val F1: 0.0000, Test F1: 0.0767
Epoch 19/20, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.3669, Test F1(macro): 0.0767, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1395, 0.1372, 0.1403, 0.1416, 0.1468, 0.1438, 0.1508] **
max =  0.1508 | max_idx =  6
**pseudo_label ->  [0.1381, 0.1376, 0.1409, 0.1423, 0.1453, 0.1436, 0.1523] **
max =  0.1523 | max_idx =  6
**pseudo_label ->  [0.1377, 0.137, 0.1407, 0.1424, 0.147, 0.1439, 0.1513] **
max =  0.1513 | max_idx =  6
**pseudo_label ->  [0.1379, 0.1363, 0.1398, 0.1421, 0.1477, 0.1435, 0.1527] **
max =  0.1527 | max_idx =  6
**pseudo_label ->  [0.1374, 0.1372, 0.14, 0.1418, 0.1474, 0.1442, 0.1521] **
max =  0.1521 | max_idx =  6
**pseudo_label ->  [0.1367, 0.1366, 0.1403, 0.1425, 0.1479, 0.1431, 0.153] **
max =  0.153 | max_idx =  6
**pseudo_label ->  [0.1373, 0.1372, 0.1402, 0.1424, 0.1464, 0.1438, 0.1527] **
max =  0.1527 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9433, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9605, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 200, Time: 1:57:42
Train F1: 0.0357, Val F1: 0.0885, Test F1: 0.0531
Epoch 20/20, Train Acc: 0.1429, Val Acc: 0.2843, Test Acc: 0.2282, Test F1(macro): 0.0531, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70


Training complete!
Total training took 1:57:42 (h:mm:ss)
Load model from ./experiment/jointmatch/output/10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_20_[42]_{'java'}_net0.pth
Load model from ./experiment/jointmatch/output/10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_20_[42]_{'java'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/codet5p/joint_match//10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_20_[42]_{'java'}/training_statistics.csv


Best_step:  90 
Best_val_epoch:  9 
best_val_acc:  0.2910321489001692 
best_val_test_acc:  0.2348993288590604 
best_val_test_f1:  0.07293322062552832
Save best record in:  ./experiment/jointmatch/log/codet5p/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
