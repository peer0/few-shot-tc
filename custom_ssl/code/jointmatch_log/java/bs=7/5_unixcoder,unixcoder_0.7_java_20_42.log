current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code

bs =>  7
Data set -> jointmatch
save_name: 5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'java'}

data_path:  ../data/jointmatch/java

There are 1 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base']
**tokenizer type =  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base'] 

n_labeled_per_class:  5
train_df samples: 3851
train_labeled_df samples: 35
train_unlabeled_df samples: 3816
Check n_smaples_per_class in the original training set:  OrderedDict([(1, 632), (2, 555), (3, 583), (4, 559), (5, 493), (6, 432), (7, 597)])
Check n_smaples_per_class in the labeled training set:  OrderedDict([(1, 5), (2, 5), (3, 5), (4, 5), (5, 5), (6, 5), (7, 5)])
Check n_smaples_per_class in the unlabeled training set:  OrderedDict([(1, 627), (2, 550), (3, 578), (4, 554), (5, 488), (6, 427), (7, 592)])
n_classes:  7

net_arch:  microsoft/unixcoder-base 
lr:  0.0004 
lr_linear:  0.001 


net_arch:  microsoft/unixcoder-base 
lr:  0.0002 
lr_linear:  0.001 

acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0727, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9010, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 5, Time: 0:05:53
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 1/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3757, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 480, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.128 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.12776151299476624, nan, nan]
loss for labeled data =>  tensor(1.9229, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9810, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 10, Time: 0:12:09
Train F1: 0.0357, Val F1: 0.0885, Test F1: 0.0531
Epoch 2/20, Train Acc: 0.1429, Val Acc: 0.2843, Test Acc: 0.2282, Test F1(macro): 0.0531, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 3781, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 549, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.145 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.14519968628883362, nan, nan, nan]
loss for labeled data =>  tensor(2.6066, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8349, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 15, Time: 0:18:02
Train F1: 0.0357, Val F1: 0.0684, Test F1: 0.0116
Epoch 3/20, Train Acc: 0.1429, Val Acc: 0.2064, Test Acc: 0.0425, Test F1(macro): 0.0116, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3798, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 485, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.128 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.12769879400730133, nan, nan]
loss for labeled data =>  tensor(3.5550, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1984, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 20, Time: 0:23:53
Train F1: 0.0357, Val F1: 0.0885, Test F1: 0.0531
Epoch 4/20, Train Acc: 0.1429, Val Acc: 0.2843, Test Acc: 0.2282, Test F1(macro): 0.0531, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.1048, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8093, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 25, Time: 0:29:42
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 5/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 3746, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 542, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.145 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.14468766748905182, nan, nan, nan]
loss for labeled data =>  tensor(3.8147, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9279, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 30, Time: 0:35:30
Train F1: 0.0357, Val F1: 0.0684, Test F1: 0.0116
Epoch 6/20, Train Acc: 0.1429, Val Acc: 0.2064, Test Acc: 0.0425, Test F1(macro): 0.0116, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 16, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 3, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.188 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.1875, nan, nan, nan]
loss for labeled data =>  tensor(9.0802, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.5947, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 35, Time: 0:41:17
Train F1: 0.0357, Val F1: 0.0698, Test F1: 0.0382
Epoch 7/20, Train Acc: 0.1429, Val Acc: 0.2115, Test Acc: 0.1544, Test F1(macro): 0.0382, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3131, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 396, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.126 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.1264771670103073, nan, nan]
loss for labeled data =>  tensor(2.1115, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0130, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 40, Time: 0:47:06
Train F1: 0.0357, Val F1: 0.0885, Test F1: 0.0531
Epoch 8/20, Train Acc: 0.1429, Val Acc: 0.2843, Test Acc: 0.2282, Test F1(macro): 0.0531, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 3617, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 401, 0]
psl_acc(PSL 평가에서의 정확도):  0.111 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, 0.11086535453796387, nan]
loss for labeled data =>  tensor(2.4292, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.7527, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 45, Time: 0:52:54
Train F1: 0.0357, Val F1: 0.0000, Test F1: 0.0767
Epoch 9/20, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.3669, Test F1(macro): 0.0767, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3757, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [613, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.163 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.16316209733486176, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(6.1140, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(5.0023, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 50, Time: 0:58:43
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 10/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3749, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 566, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.151 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.1509735882282257, nan, nan, nan, nan]
loss for labeled data =>  tensor(5.2886, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(7.4015, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 55, Time: 1:04:30
Train F1: 0.0357, Val F1: 0.0698, Test F1: 0.0382
Epoch 11/20, Train Acc: 0.1429, Val Acc: 0.2115, Test Acc: 0.1544, Test F1(macro): 0.0382, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 3658]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 568]
psl_acc(PSL 평가에서의 정확도):  0.155 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1552761048078537]
loss for labeled data =>  tensor(6.2166, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.3381, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 60, Time: 1:10:18
Train F1: 0.0357, Val F1: 0.0000, Test F1: 0.0038
Epoch 12/20, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 3795, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 548, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.144 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.14440052211284637, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8287, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.1523, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 65, Time: 1:16:07
Train F1: 0.0357, Val F1: 0.0666, Test F1: 0.0163
Epoch 13/20, Train Acc: 0.1429, Val Acc: 0.1997, Test Acc: 0.0604, Test F1(macro): 0.0163, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 3806, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 554, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.146 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.1455596387386322, nan, nan, nan]
loss for labeled data =>  tensor(5.3931, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.0392, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 70, Time: 1:21:55
Train F1: 0.0357, Val F1: 0.0684, Test F1: 0.0116
Epoch 14/20, Train Acc: 0.1429, Val Acc: 0.2064, Test Acc: 0.0425, Test F1(macro): 0.0116, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3632, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 555, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.153 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.15280836820602417, nan, nan, nan, nan]
loss for labeled data =>  tensor(5.7390, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.5313, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 75, Time: 1:27:44
Train F1: 0.0357, Val F1: 0.0698, Test F1: 0.0382
Epoch 15/20, Train Acc: 0.1429, Val Acc: 0.2115, Test Acc: 0.1544, Test F1(macro): 0.0382, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 695, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 76, 0]
psl_acc(PSL 평가에서의 정확도):  0.109 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, 0.10935252159833908, nan]
loss for labeled data =>  tensor(4.8058, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.7869, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 80, Time: 1:33:30
Train F1: 0.0357, Val F1: 0.0000, Test F1: 0.0767
Epoch 16/20, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.3669, Test F1(macro): 0.0767, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 1, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3273, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 414, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.126 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.12648946046829224, nan, nan]
loss for labeled data =>  tensor(6.0714, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.9632, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 85, Time: 1:39:19
Train F1: 0.0357, Val F1: 0.0885, Test F1: 0.0531
Epoch 17/20, Train Acc: 0.1429, Val Acc: 0.2843, Test Acc: 0.2282, Test F1(macro): 0.0531, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 3687, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 535, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.145 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.14510442316532135, nan, nan, nan]
loss for labeled data =>  tensor(8.0928, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(5.6666, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 90, Time: 1:45:08
Train F1: 0.0357, Val F1: 0.0684, Test F1: 0.0116
Epoch 18/20, Train Acc: 0.1429, Val Acc: 0.2064, Test Acc: 0.0425, Test F1(macro): 0.0116, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3809, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 577, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.151 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.15148332715034485, nan, nan, nan, nan]
loss for labeled data =>  tensor(4.5335, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.6279, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 95, Time: 1:50:57
Train F1: 0.0357, Val F1: 0.0698, Test F1: 0.0382
Epoch 19/20, Train Acc: 0.1429, Val Acc: 0.2115, Test Acc: 0.1544, Test F1(macro): 0.0382, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 1, 0, 0, 0, 0, 3787]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 586]
psl_acc(PSL 평가에서의 정확도):  0.155 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.0, nan, nan, nan, nan, 0.15473990142345428]
loss for labeled data =>  tensor(6.5395, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(5.2626, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 100, Time: 1:56:45
Train F1: 0.0357, Val F1: 0.0000, Test F1: 0.0038
Epoch 20/20, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 35


Training complete!
Total training took 1:56:45 (h:mm:ss)
Load model from ./experiment/jointmatch/output/5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'java'}_net0.pth
Load model from ./experiment/jointmatch/output/5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'java'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/unixcoder/joint_match//5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'java'}/training_statistics.csv


Best_step:  10 
Best_val_epoch:  2 
best_val_acc:  0.28426395939086296 
best_val_test_acc:  0.22818791946308725 
best_val_test_f1:  0.05308352849336456
Save best record in:  ./experiment/jointmatch/log/unixcoder/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
