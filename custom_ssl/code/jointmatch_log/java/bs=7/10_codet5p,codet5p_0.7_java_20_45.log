current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code

bs =>  7
Data set -> jointmatch
save_name: 10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_20_[45]_{'java'}

data_path:  ../data/jointmatch/java

There are 1 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding']
**tokenizer type =  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding'] 

n_labeled_per_class:  10
train_df samples: 3851
train_labeled_df samples: 70
train_unlabeled_df samples: 3781
Check n_smaples_per_class in the original training set:  OrderedDict([(1, 632), (2, 555), (3, 583), (4, 559), (5, 493), (6, 432), (7, 597)])
Check n_smaples_per_class in the labeled training set:  OrderedDict([(1, 10), (2, 10), (3, 10), (4, 10), (5, 10), (6, 10), (7, 10)])
Check n_smaples_per_class in the unlabeled training set:  OrderedDict([(1, 622), (2, 545), (3, 573), (4, 549), (5, 483), (6, 422), (7, 587)])
n_classes:  7

net_arch:  Salesforce/codet5p-110m-embedding 
lr:  0.0003 
lr_linear:  0.001 


net_arch:  Salesforce/codet5p-110m-embedding 
lr:  0.00025 
lr_linear:  0.001 

**pseudo_label ->  [0.1725, 0.1397, 0.1437, 0.1362, 0.1274, 0.1504, 0.1302] **
max =  0.1725 | max_idx =  0
**pseudo_label ->  [0.1102, 0.1238, 0.1391, 0.1715, 0.146, 0.1489, 0.1606] **
max =  0.1715 | max_idx =  3
**pseudo_label ->  [0.1175, 0.122, 0.1491, 0.1656, 0.1422, 0.1506, 0.153] **
max =  0.1656 | max_idx =  3
**pseudo_label ->  [0.1246, 0.1353, 0.1654, 0.1547, 0.1265, 0.1474, 0.1462] **
max =  0.1654 | max_idx =  2
**pseudo_label ->  [0.1112, 0.1257, 0.1345, 0.1676, 0.1518, 0.1453, 0.1639] **
max =  0.1676 | max_idx =  3
**pseudo_label ->  [0.1148, 0.1188, 0.1593, 0.1671, 0.1377, 0.1491, 0.1533] **
max =  0.1671 | max_idx =  3
**pseudo_label ->  [0.111, 0.1287, 0.1602, 0.1632, 0.1344, 0.1445, 0.158] **
max =  0.1632 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.1, 0.0, 0.6, 0.0, 0.1, 0.9]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9173, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9067, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 10, Time: 0:05:52
Train F1: 0.1494, Val F1: 0.0685, Test F1: 0.0124
Epoch 1/20, Train Acc: 0.2429, Val Acc: 0.1218, Test Acc: 0.0224, Test F1(macro): 0.0124, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1204, 0.0772, 0.1695, 0.1826, 0.162, 0.1503, 0.138] **
max =  0.1826 | max_idx =  3
**pseudo_label ->  [0.0932, 0.1278, 0.1685, 0.1341, 0.1215, 0.1513, 0.2037] **
max =  0.2037 | max_idx =  6
**pseudo_label ->  [0.1164, 0.1988, 0.1225, 0.1169, 0.1216, 0.1586, 0.1652] **
max =  0.1988 | max_idx =  1
**pseudo_label ->  [0.0935, 0.1344, 0.1585, 0.1247, 0.1299, 0.1748, 0.1842] **
max =  0.1842 | max_idx =  6
**pseudo_label ->  [0.1239, 0.0776, 0.1682, 0.1845, 0.1614, 0.144, 0.1405] **
max =  0.1845 | max_idx =  3
**pseudo_label ->  [0.099, 0.0886, 0.1666, 0.1475, 0.1512, 0.1873, 0.1598] **
max =  0.1873 | max_idx =  5
**pseudo_label ->  [0.0988, 0.0841, 0.177, 0.1632, 0.157, 0.1608, 0.1592] **
max =  0.177 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.3, 0.0, 0.6, 0.7]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.7231, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9423, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 20, Time: 0:11:40
Train F1: 0.1520, Val F1: 0.0309, Test F1: 0.0211
Epoch 2/20, Train Acc: 0.2286, Val Acc: 0.0288, Test Acc: 0.0425, Test F1(macro): 0.0211, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1485, 0.2209, 0.1426, 0.0886, 0.1118, 0.1717, 0.116] **
max =  0.2209 | max_idx =  1
**pseudo_label ->  [0.1259, 0.0765, 0.1458, 0.2149, 0.1621, 0.1154, 0.1593] **
max =  0.2149 | max_idx =  3
**pseudo_label ->  [0.126, 0.076, 0.1455, 0.2135, 0.1635, 0.1164, 0.1591] **
max =  0.2135 | max_idx =  3
**pseudo_label ->  [0.1276, 0.0772, 0.1462, 0.2129, 0.164, 0.1148, 0.1573] **
max =  0.2129 | max_idx =  3
**pseudo_label ->  [0.1264, 0.0771, 0.1448, 0.2143, 0.1634, 0.115, 0.159] **
max =  0.2143 | max_idx =  3
**pseudo_label ->  [0.1482, 0.2217, 0.1456, 0.0888, 0.1119, 0.1678, 0.1158] **
max =  0.2217 | max_idx =  1
**pseudo_label ->  [0.1261, 0.0761, 0.1473, 0.2125, 0.1627, 0.1162, 0.1592] **
max =  0.2125 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.8362, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9567, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 30, Time: 0:17:46
Train F1: 0.0362, Val F1: 0.0684, Test F1: 0.0117
Epoch 3/20, Train Acc: 0.1429, Val Acc: 0.2064, Test Acc: 0.0425, Test F1(macro): 0.0117, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1158, 0.0662, 0.1341, 0.209, 0.182, 0.1411, 0.1518] **
max =  0.209 | max_idx =  3
**pseudo_label ->  [0.1161, 0.0665, 0.1323, 0.2102, 0.1813, 0.1428, 0.1509] **
max =  0.2102 | max_idx =  3
**pseudo_label ->  [0.1166, 0.0664, 0.1325, 0.2101, 0.1825, 0.1409, 0.151] **
max =  0.2101 | max_idx =  3
**pseudo_label ->  [0.1163, 0.0663, 0.1327, 0.21, 0.1812, 0.1411, 0.1523] **
max =  0.21 | max_idx =  3
**pseudo_label ->  [0.1163, 0.0663, 0.1328, 0.2108, 0.18, 0.142, 0.1518] **
max =  0.2108 | max_idx =  3
**pseudo_label ->  [0.117, 0.0666, 0.1317, 0.2092, 0.1825, 0.1417, 0.1513] **
max =  0.2092 | max_idx =  3
**pseudo_label ->  [0.1172, 0.0665, 0.1321, 0.2098, 0.1808, 0.1407, 0.1529] **
max =  0.2098 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0029, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9386, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 40, Time: 0:23:55
Train F1: 0.0357, Val F1: 0.0885, Test F1: 0.0531
Epoch 4/20, Train Acc: 0.1429, Val Acc: 0.2843, Test Acc: 0.2282, Test F1(macro): 0.0531, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1474, 0.0956, 0.1366, 0.1413, 0.1621, 0.1709, 0.1461] **
max =  0.1709 | max_idx =  5
**pseudo_label ->  [0.1469, 0.0943, 0.1375, 0.1426, 0.1642, 0.1684, 0.1461] **
max =  0.1684 | max_idx =  5
**pseudo_label ->  [0.1453, 0.0945, 0.1388, 0.1414, 0.1619, 0.1692, 0.1491] **
max =  0.1692 | max_idx =  5
**pseudo_label ->  [0.1481, 0.0958, 0.1369, 0.14, 0.1611, 0.171, 0.1472] **
max =  0.171 | max_idx =  5
**pseudo_label ->  [0.1477, 0.0958, 0.1368, 0.1398, 0.1637, 0.1695, 0.1467] **
max =  0.1695 | max_idx =  5
**pseudo_label ->  [0.1475, 0.0944, 0.1376, 0.1419, 0.1625, 0.169, 0.1471] **
max =  0.169 | max_idx =  5
**pseudo_label ->  [0.1474, 0.0953, 0.1375, 0.1411, 0.1621, 0.1708, 0.1458] **
max =  0.1708 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9551, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9506, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 50, Time: 0:29:46
Train F1: 0.0357, Val F1: 0.0666, Test F1: 0.0163
Epoch 5/20, Train Acc: 0.1429, Val Acc: 0.1997, Test Acc: 0.0604, Test F1(macro): 0.0163, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1425, 0.1143, 0.1488, 0.1499, 0.152, 0.1373, 0.1551] **
max =  0.1551 | max_idx =  6
**pseudo_label ->  [0.1429, 0.1156, 0.1476, 0.1497, 0.151, 0.139, 0.1541] **
max =  0.1541 | max_idx =  6
**pseudo_label ->  [0.1443, 0.1202, 0.1468, 0.1453, 0.1488, 0.1414, 0.1532] **
max =  0.1532 