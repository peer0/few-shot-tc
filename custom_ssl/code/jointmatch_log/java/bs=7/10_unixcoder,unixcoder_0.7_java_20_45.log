current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code

bs =>  7
Data set -> jointmatch
save_name: 10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[45]_{'java'}

data_path:  ../data/jointmatch/java

There are 1 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base']
**tokenizer type =  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base'] 

n_labeled_per_class:  10
train_df samples: 3851
train_labeled_df samples: 70
train_unlabeled_df samples: 3781
Check n_smaples_per_class in the original training set:  OrderedDict([(1, 632), (2, 555), (3, 583), (4, 559), (5, 493), (6, 432), (7, 597)])
Check n_smaples_per_class in the labeled training set:  OrderedDict([(1, 10), (2, 10), (3, 10), (4, 10), (5, 10), (6, 10), (7, 10)])
Check n_smaples_per_class in the unlabeled training set:  OrderedDict([(1, 622), (2, 545), (3, 573), (4, 549), (5, 483), (6, 422), (7, 587)])
n_classes:  7

net_arch:  microsoft/unixcoder-base 
lr:  0.0004 
lr_linear:  0.001 


net_arch:  microsoft/unixcoder-base 
lr:  0.0002 
lr_linear:  0.001 

**pseudo_label ->  [0.089, 0.1058, 0.1252, 0.2375, 0.1302, 0.1608, 0.1515] **
max =  0.2375 | max_idx =  3
**pseudo_label ->  [0.077, 0.0941, 0.1634, 0.1771, 0.1611, 0.0998, 0.2274] **
max =  0.2274 | max_idx =  6
**pseudo_label ->  [0.1642, 0.2057, 0.1133, 0.1542, 0.0907, 0.1263, 0.1455] **
max =  0.2057 | max_idx =  1
**pseudo_label ->  [0.1289, 0.1333, 0.0957, 0.1301, 0.1249, 0.1565, 0.2307] **
max =  0.2307 | max_idx =  6
**pseudo_label ->  [0.1718, 0.1529, 0.114, 0.1559, 0.1138, 0.114, 0.1775] **
max =  0.1775 | max_idx =  6
**pseudo_label ->  [0.2963, 0.175, 0.0675, 0.1515, 0.055, 0.1067, 0.148] **
max =  0.2963 | max_idx =  0
**pseudo_label ->  [0.1029, 0.1079, 0.1504, 0.1724, 0.125, 0.1659, 0.1754] **
max =  0.1754 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3615, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [592, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.164 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.16376210749149323, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.8805, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9402, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 10, Time: 0:05:55
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 1/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 1, Train Data Number: 70

**pseudo_label ->  [0.2295, 0.1784, 0.0969, 0.0738, 0.132, 0.1303, 0.1592] **
max =  0.2295 | max_idx =  0
**pseudo_label ->  [0.2114, 0.1929, 0.1029, 0.0613, 0.135, 0.1398, 0.1566] **
max =  0.2114 | max_idx =  0
**pseudo_label ->  [0.1901, 0.1825, 0.0864, 0.1847, 0.1262, 0.1291, 0.1011] **
max =  0.1901 | max_idx =  0
**pseudo_label ->  [0.2149, 0.167, 0.1284, 0.0841, 0.136, 0.1236, 0.1459] **
max =  0.2149 | max_idx =  0
**pseudo_label ->  [0.2134, 0.1511, 0.1079, 0.0674, 0.1363, 0.1632, 0.1607] **
max =  0.2134 | max_idx =  0
**pseudo_label ->  [0.2719, 0.1931, 0.1225, 0.0797, 0.0999, 0.1161, 0.1167] **
max =  0.2719 | max_idx =  0
**pseudo_label ->  [0.2493, 0.1721, 0.0996, 0.0578, 0.1268, 0.1419, 0.1525] **
max =  0.2493 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 3687, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 532, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.144 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1442907452583313, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0632, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9230, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 20, Time: 0:12:06
Train F1: 0.0357, Val F1: 0.0666, Test F1: 0.0163
Epoch 2/20, Train Acc: 0.1429, Val Acc: 0.1997, Test Acc: 0.0604, Test F1(macro): 0.0163, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.094, 0.1423, 0.1216, 0.1282, 0.1749, 0.1454, 0.1936] **
max =  0.1936 | max_idx =  6
**pseudo_label ->  [0.1222, 0.1761, 0.0943, 0.1732, 0.1613, 0.1531, 0.1198] **
max =  0.1761 | max_idx =  1
**pseudo_label ->  [0.0929, 0.1754, 0.1627, 0.1423, 0.1703, 0.1371, 0.1192] **
max =  0.1754 | max_idx =  1
**pseudo_label ->  [0.0917, 0.2118, 0.0997, 0.1608, 0.1416, 0.1451, 0.1492] **
max =  0.2118 | max_idx =  1
**pseudo_label ->  [0.0982, 0.2283, 0.1133, 0.1458, 0.1227, 0.1266, 0.1652] **
max =  0.2283 | max_idx =  1
**pseudo_label ->  [0.0752, 0.2202, 0.103, 0.1548, 0.1231, 0.1793, 0.1444] **
max =  0.2202 | max_idx =  1
**pseudo_label ->  [0.1073, 0.1755, 0.1338, 0.1716, 0.125, 0.1355, 0.1514] **
max =  0.1755 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9188, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8795, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 30, Time: 0:20:50
Train F1: 0.0357, Val F1: 0.0666, Test F1: 0.0163
Epoch 3/20, Train Acc: 0.1429, Val Acc: 0.1997, Test Acc: 0.0604, Test F1(macro): 0.0163, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0995, 0.0704, 0.0983, 0.2464, 0.1961, 0.0647, 0.2245] **
max =  0.2464 | max_idx =  3
**pseudo_label ->  [0.1284, 0.0522, 0.1454, 0.131, 0.2057, 0.0803, 0.257] **
max =  0.257 | max_idx =  6
**pseudo_label ->  [0.1332, 0.0707, 0.1051, 0.1684, 0.2354, 0.0794, 0.2077] **
max =  0.2354 | max_idx =  4
**pseudo_label ->  [0.134, 0.0805, 0.1514, 0.1252, 0.2134, 0.1024, 0.1931] **
max =  0.2134 | max_idx =  4
**pseudo_label ->  [0.1387, 0.0686, 0.1417, 0.1791, 0.1608, 0.0881, 0.2231] **
max =  0.2231 | max_idx =  6
**pseudo_label ->  [0.1342, 0.066, 0.0963, 0.1996, 0.2031, 0.0712, 0.2296] **
max =  0.2296 | max_idx =  6
**pseudo_label ->  [0.1383, 0.0543, 0.123, 0.2238, 0.2153, 0.0612, 0.1842] **
max =  0.2238 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.1238, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0526, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 40, Time: 0:29:34
Train F1: 0.0357, Val F1: 0.0000, Test F1: 0.0038
Epoch 4/20, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1308, 0.1045, 0.1535, 0.1707, 0.1741, 0.1396, 0.1269] **
max =  0.1741 | max_idx =  4
**pseudo_label ->  [0.1307, 0.1189, 0.1826, 0.1841, 0.1931, 0.0788, 0.1118] **
max =  0.1931 | max_idx =  4
**pseudo_label ->  [0.0937, 0.1091, 0.172, 0.1354, 0.229, 0.0959, 0.1648] **
max =  0.229 | max_idx =  4
**pseudo_label ->  [0.129, 0.1033, 0.1233, 0.14, 0.196, 0.1285, 0.1798] **
max =  0.196 | max_idx =  4
**pseudo_label ->  [0.1626, 0.1099, 0.1469, 0.1724, 0.1125, 0.146, 0.1497] **
max =  0.1724 | max_idx =  3
**pseudo_label ->  [0.1021, 0.1303, 0.1569, 0.2015, 0.1582, 0.0781, 0.1727] **
max =  0.2015 | max_idx =  3
**pseudo_label ->  [0.1424, 0.1225, 0.1241, 0.1241, 0.1947, 0.1281, 0.164] **
max =  0.1947 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.8843, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0661, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 50, Time: 0:38:33
Train F1: 0.0357, Val F1: 0.0885, Test F1: 0.0531
Epoch 5/20, Train Acc: 0.1429, Val Acc: 0.2843, Test Acc: 0.2282, Test F1(macro): 0.0531, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1676, 0.0934, 0.0715, 0.0812, 0.2299, 0.1528, 0.2036] **
max =  0.2299 | max_idx =  4
**pseudo_label ->  [0.1123, 0.1159, 0.1041, 0.1146, 0.2162, 0.1394, 0.1975] **
max =  0.2162 | max_idx =  4
**pseudo_label ->  [0.1236, 0.1245, 0.1111, 0.0653, 0.1956, 0.1546, 0.2253] **
max =  0.2253 | max_idx =  6
**pseudo_label ->  [0.1215, 0.0892, 0.0949, 0.0787, 0.2406, 0.1527, 0.2224] **
max =  0.2406 | max_idx =  4
**pseudo_label ->  [0.1062, 0.1508, 0.0849, 0.1291, 0.203, 0.0975, 0.2284] **
max =  0.2284 | max_idx =  6
**pseudo_label ->  [0.108, 0.1336, 0.076, 0.1094, 0.2117, 0.1439, 0.2173] **
max =  0.2173 | max_idx =  6
**pseudo_label ->  [0.1066, 0.1146, 0.1394, 0.0674, 0.2648, 0.1013, 0.206] **
max =  0.2648 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 3659]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 569]
psl_acc(PSL 평가에서의 정확도):  0.156 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.15550696849822998]
loss for labeled data =>  tensor(2.0390, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1277, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 60, Time: 0:47:24
Train F1: 0.0357, Val F1: 0.0000, Test F1: 0.0038
Epoch 6/20, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0385, 0.2969, 0.1777, 0.147, 0.1896, 0.1502, 0.0001] **
max =  0.2969 | max_idx =  1
**pseudo_label ->  [0.0315, 0.292, 0.144, 0.1179, 0.2552, 0.1594, 0.0] **
max =  0.292 | max_idx =  1
**pseudo_label ->  [0.0303, 0.2416, 0.1847, 0.1196, 0.2418, 0.182, 0.0001] **
max =  0.2418 | max_idx =  4
**pseudo_label ->  [0.0478, 0.1892, 0.1873, 0.1973, 0.1969, 0.1815, 0.0001] **
max =  0.1973 | max_idx =  3
**pseudo_label ->  [0.0351, 0.2342, 0.1909, 0.1039, 0.268, 0.1678, 0.0001] **
max =  0.268 | max_idx =  4
**pseudo_label ->  [0.0346, 0.2786, 0.1593, 0.1532, 0.1469, 0.2273, 0.0001] **
max =  0.2786 | max_idx =  1
**pseudo_label ->  [0.0359, 0.2996, 0.1571, 0.1765, 0.144, 0.187, 0.0001] **
max =  0.2996 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3744, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [616, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.165 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.1645299196243286, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.0677, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.3622, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 70, Time: 0:56:18
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 7/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0002, 0.1205, 0.1992, 0.27, 0.149, 0.2611, 0.0] **
max =  0.27 | max_idx =  3
**pseudo_label ->  [0.0001, 0.1041, 0.1409, 0.2546, 0.1419, 0.3584, 0.0] **
max =  0.3584 | max_idx =  5
**pseudo_label ->  [0.0001, 0.1179, 0.1677, 0.3609, 0.1844, 0.169, 0.0] **
max =  0.3609 | max_idx =  3
**pseudo_label ->  [0.0001, 0.1152, 0.1541, 0.2743, 0.1863, 0.27, 0.0] **
max =  0.2743 | max_idx =  3
**pseudo_label ->  [0.0001, 0.1206, 0.1539, 0.3297, 0.1978, 0.1979, 0.0] **
max =  0.3297 | max_idx =  3
**pseudo_label ->  [0.0001, 0.1154, 0.1232, 0.3272, 0.1442, 0.2898, 0.0] **
max =  0.3272 | max_idx =  3
**pseudo_label ->  [0.0002, 0.1144, 0.2132, 0.2456, 0.1986, 0.228, 0.0] **
max =  0.2456 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(4.8259, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.3547, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 80, Time: 1:05:03
Train F1: 0.0357, Val F1: 0.0666, Test F1: 0.0163
Epoch 8/20, Train Acc: 0.1429, Val Acc: 0.1997, Test Acc: 0.0604, Test F1(macro): 0.0163, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1669, 0.2152, 0.1092, 0.0928, 0.1396, 0.106, 0.1703] **
max =  0.2152 | max_idx =  1
**pseudo_label ->  [0.1585, 0.1826, 0.1095, 0.1041, 0.1841, 0.1302, 0.131] **
max =  0.1841 | max_idx =  4
**pseudo_label ->  [0.1382, 0.1701, 0.1272, 0.1191, 0.1722, 0.1138, 0.1595] **
max =  0.1722 | max_idx =  4
**pseudo_label ->  [0.2013, 0.1546, 0.122, 0.0767, 0.141, 0.11, 0.1944] **
max =  0.2013 | max_idx =  0
**pseudo_label ->  [0.202, 0.1997, 0.1722, 0.0987, 0.1366, 0.0675, 0.1233] **
max =  0.202 | max_idx =  0
**pseudo_label ->  [0.2056, 0.164, 0.0801, 0.0955, 0.1679, 0.1128, 0.1742] **
max =  0.2056 | max_idx =  0
**pseudo_label ->  [0.1819, 0.2075, 0.1237, 0.0752, 0.1642, 0.1083, 0.1393] **
max =  0.2075 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0623, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9323, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 90, Time: 1:13:46
Train F1: 0.0357, Val F1: 0.0666, Test F1: 0.0163
Epoch 9/20, Train Acc: 0.1429, Val Acc: 0.1997, Test Acc: 0.0604, Test F1(macro): 0.0163, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.2035, 0.1703, 0.0762, 0.1021, 0.1932, 0.0918, 0.1629] **
max =  0.2035 | max_idx =  0
**pseudo_label ->  [0.2323, 0.1616, 0.0735, 0.1065, 0.1699, 0.1275, 0.1286] **
max =  0.2323 | max_idx =  0
**pseudo_label ->  [0.1935, 0.166, 0.075, 0.0883, 0.2027, 0.1467, 0.1279] **
max =  0.2027 | max_idx =  4
**pseudo_label ->  [0.2019, 0.1686, 0.0949, 0.115, 0.1944, 0.0834, 0.1418] **
max =  0.2019 | max_idx =  0
**pseudo_label ->  [0.2112, 0.1798, 0.0768, 0.0963, 0.1568, 0.1308, 0.1483] **
max =  0.2112 | max_idx =  0
**pseudo_label ->  [0.1875, 0.1823, 0.0928, 0.107, 0.1859, 0.0825, 0.1621] **
max =  0.1875 | max_idx =  0
**pseudo_label ->  [0.2208, 0.1515, 0.0806, 0.1123, 0.1627, 0.1212, 0.1509] **
max =  0.2208 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 3698, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 527, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.143 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.14250946044921875, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0609, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0020, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 100, Time: 1:22:37
Train F1: 0.0357, Val F1: 0.0666, Test F1: 0.0163
Epoch 10/20, Train Acc: 0.1429, Val Acc: 0.1997, Test Acc: 0.0604, Test F1(macro): 0.0163, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.2699, 0.0001, 0.1425, 0.1546, 0.1411, 0.1337, 0.1581] **
max =  0.2699 | max_idx =  0
**pseudo_label ->  [0.2341, 0.0001, 0.1179, 0.1293, 0.1152, 0.1699, 0.2337] **
max =  0.2341 | max_idx =  0
**pseudo_label ->  [0.2137, 0.0001, 0.1742, 0.1369, 0.1059, 0.1596, 0.2096] **
max =  0.2137 | max_idx =  0
**pseudo_label ->  [0.2032, 0.0001, 0.1374, 0.157, 0.1074, 0.1339, 0.2611] **
max =  0.2611 | max_idx =  6
**pseudo_label ->  [0.2426, 0.0001, 0.1893, 0.138, 0.102, 0.1343, 0.1937] **
max =  0.2426 | max_idx =  0
**pseudo_label ->  [0.2188, 0.0001, 0.1698, 0.1435, 0.1112, 0.1459, 0.2106] **
max =  0.2188 | max_idx =  0
**pseudo_label ->  [0.2337, 0.0001, 0.1675, 0.1187, 0.1224, 0.1441, 0.2134] **
max =  0.2337 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3706, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [612, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.165 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.1651376187801361, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8305, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1697, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 110, Time: 1:31:30
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 11/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0115, 0.1871, 0.2358, 0.1993, 0.1196, 0.1023, 0.1445] **
max =  0.2358 | max_idx =  2
**pseudo_label ->  [0.0108, 0.1604, 0.1639, 0.1582, 0.1245, 0.1442, 0.238] **
max =  0.238 | max_idx =  6
**pseudo_label ->  [0.0085, 0.1442, 0.1912, 0.1909, 0.087, 0.1837, 0.1945] **
max =  0.1945 | max_idx =  6
**pseudo_label ->  [0.0121, 0.2251, 0.1589, 0.1435, 0.1129, 0.158, 0.1894] **
max =  0.2251 | max_idx =  1
**pseudo_label ->  [0.0151, 0.2189, 0.1341, 0.1866, 0.0869, 0.1412, 0.2172] **
max =  0.2189 | max_idx =  1
**pseudo_label ->  [0.0113, 0.2587, 0.1779, 0.1875, 0.0879, 0.0823, 0.1945] **
max =  0.2587 | max_idx =  1
**pseudo_label ->  [0.0137, 0.1218, 0.1635, 0.1639, 0.0777, 0.1925, 0.2668] **
max =  0.2668 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 3690, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 536, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.145 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.14525745809078217, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.3847, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.9082, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 120, Time: 1:40:19
Train F1: 0.0357, Val F1: 0.0666, Test F1: 0.0163
Epoch 12/20, Train Acc: 0.1429, Val Acc: 0.1997, Test Acc: 0.0604, Test F1(macro): 0.0163, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1312, 0.0011, 0.1359, 0.1225, 0.1081, 0.0887, 0.4126] **
max =  0.4126 | max_idx =  6
**pseudo_label ->  [0.1699, 0.0015, 0.1975, 0.1285, 0.1315, 0.094, 0.277] **
max =  0.277 | max_idx =  6
**pseudo_label ->  [0.1299, 0.0016, 0.1741, 0.1533, 0.1293, 0.0867, 0.3251] **
max =  0.3251 | max_idx =  6
**pseudo_label ->  [0.1568, 0.0011, 0.1956, 0.1214, 0.1032, 0.0912, 0.3307] **
max =  0.3307 | max_idx =  6
**pseudo_label ->  [0.1441, 0.0016, 0.1444, 0.1281, 0.1104, 0.0899, 0.3815] **
max =  0.3815 | max_idx =  6
**pseudo_label ->  [0.153, 0.0012, 0.159, 0.0938, 0.0943, 0.0519, 0.4468] **
max =  0.4468 | max_idx =  6
**pseudo_label ->  [0.1317, 0.0016, 0.156, 0.1019, 0.1233, 0.0848, 0.4007] **
max =  0.4007 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [2713, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [441, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.163 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.162550687789917, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.5136, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.4055, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 130, Time: 1:49:05
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 13/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 1, Train Data Number: 70

**pseudo_label ->  [0.0002, 0.0001, 0.4306, 0.1651, 0.0795, 0.1086, 0.2158] **
max =  0.4306 | max_idx =  2
**pseudo_label ->  [0.0002, 0.0, 0.4759, 0.1646, 0.0521, 0.106, 0.2012] **
max =  0.4759 | max_idx =  2
**pseudo_label ->  [0.0002, 0.0, 0.3793, 0.1334, 0.0837, 0.1255, 0.2778] **
max =  0.3793 | max_idx =  2
**pseudo_label ->  [0.0003, 0.0001, 0.377, 0.1923, 0.1007, 0.1281, 0.2015] **
max =  0.377 | max_idx =  2
**pseudo_label ->  [0.0002, 0.0, 0.3507, 0.2003, 0.0828, 0.085, 0.2811] **
max =  0.3507 | max_idx =  2
**pseudo_label ->  [0.0001, 0.0, 0.3543, 0.1682, 0.0884, 0.0909, 0.298] **
max =  0.3543 | max_idx =  2
**pseudo_label ->  [0.0002, 0.0, 0.4624, 0.1516, 0.0529, 0.1184, 0.2145] **
max =  0.4624 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3598, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 541, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.15 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.1503613144159317, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.7289, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7911, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 140, Time: 1:57:58
Train F1: 0.0357, Val F1: 0.0698, Test F1: 0.0382
Epoch 14/20, Train Acc: 0.1429, Val Acc: 0.2115, Test Acc: 0.1544, Test F1(macro): 0.0382, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0, 0.0674, 0.0003, 0.2945, 0.2097, 0.1909, 0.2372] **
max =  0.2945 | max_idx =  3
**pseudo_label ->  [0.0, 0.0759, 0.0003, 0.2019, 0.3014, 0.1245, 0.296] **
max =  0.3014 | max_idx =  4
**pseudo_label ->  [0.0, 0.0595, 0.0005, 0.1674, 0.2604, 0.2201, 0.292] **
max =  0.292 | max_idx =  6
**pseudo_label ->  [0.0, 0.0866, 0.0005, 0.1783, 0.2953, 0.2209, 0.2185] **
max =  0.2953 | max_idx =  4
**pseudo_label ->  [0.0, 0.0669, 0.0002, 0.2107, 0.2541, 0.186, 0.2821] **
max =  0.2821 | max_idx =  6
**pseudo_label ->  [0.0, 0.0589, 0.0005, 0.1552, 0.2377, 0.2431, 0.3047] **
max =  0.3047 | max_idx =  6
**pseudo_label ->  [0.0, 0.0471, 0.0002, 0.2443, 0.1892, 0.2029, 0.3163] **
max =  0.3163 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 3738, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 535, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.143 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.14312466979026794, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(4.3076, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9973, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 150, Time: 2:06:51
Train F1: 0.0357, Val F1: 0.0666, Test F1: 0.0163
Epoch 15/20, Train Acc: 0.1429, Val Acc: 0.1997, Test Acc: 0.0604, Test F1(macro): 0.0163, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.024, 0.0007, 0.0, 0.4249, 0.225, 0.1287, 0.1967] **
max =  0.4249 | max_idx =  3
**pseudo_label ->  [0.0231, 0.0005, 0.0, 0.3438, 0.2842, 0.1291, 0.2193] **
max =  0.3438 | max_idx =  3
**pseudo_label ->  [0.022, 0.0006, 0.0, 0.2851, 0.2, 0.0932, 0.399] **
max =  0.399 | max_idx =  6
**pseudo_label ->  [0.025, 0.0006, 0.0, 0.4314, 0.1797, 0.1646, 0.1987] **
max =  0.4314 | max_idx =  3
**pseudo_label ->  [0.0266, 0.0007, 0.0, 0.3367, 0.2155, 0.1278, 0.2928] **
max =  0.3367 | max_idx =  3
**pseudo_label ->  [0.0297, 0.0008, 0.0, 0.3209, 0.3091, 0.1129, 0.2266] **
max =  0.3209 | max_idx =  3
**pseudo_label ->  [0.0202, 0.001, 0.0, 0.2696, 0.2554, 0.1685, 0.2853] **
max =  0.2853 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3735, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [615, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.165 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.16465863585472107, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(4.2458, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.3895, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 160, Time: 2:15:50
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 16/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0005, 0.0013, 0.2826, 0.2918, 0.0814, 0.0677, 0.2747] **
max =  0.2918 | max_idx =  3
**pseudo_label ->  [0.0007, 0.0014, 0.1732, 0.3662, 0.1335, 0.0795, 0.2454] **
max =  0.3662 | max_idx =  3
**pseudo_label ->  [0.0004, 0.001, 0.2457, 0.3617, 0.066, 0.1229, 0.2024] **
max =  0.3617 | max_idx =  3
**pseudo_label ->  [0.0004, 0.0008, 0.3146, 0.3844, 0.0687, 0.065, 0.1661] **
max =  0.3844 | max_idx =  3
**pseudo_label ->  [0.0008, 0.0031, 0.2365, 0.357, 0.1068, 0.1021, 0.1938] **
max =  0.357 | max_idx =  3
**pseudo_label ->  [0.0005, 0.001, 0.1807, 0.4334, 0.0807, 0.1018, 0.2019] **
max =  0.4334 | max_idx =  3
**pseudo_label ->  [0.0003, 0.0012, 0.2079, 0.3426, 0.1052, 0.102, 0.2407] **
max =  0.3426 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3718, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 560, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.151 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.15061861276626587, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.3016, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.0172, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 170, Time: 2:24:46
Train F1: 0.0357, Val F1: 0.0698, Test F1: 0.0382
Epoch 17/20, Train Acc: 0.1429, Val Acc: 0.2115, Test Acc: 0.1544, Test F1(macro): 0.0382, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0, 0.189, 0.0003, 0.137, 0.1585, 0.2582, 0.2569] **
max =  0.2582 | max_idx =  5
**pseudo_label ->  [0.0, 0.2033, 0.0004, 0.1163, 0.1797, 0.2946, 0.2057] **
max =  0.2946 | max_idx =  5
**pseudo_label ->  [0.0, 0.1816, 0.0003, 0.1515, 0.1733, 0.299, 0.1943] **
max =  0.299 | max_idx =  5
**pseudo_label ->  [0.0, 0.2459, 0.0003, 0.1013, 0.2565, 0.2055, 0.1906] **
max =  0.2565 | max_idx =  4
**pseudo_label ->  [0.0, 0.1093, 0.0003, 0.1466, 0.1476, 0.3682, 0.2279] **
max =  0.3682 | max_idx =  5
**pseudo_label ->  [0.0, 0.1224, 0.0004, 0.1829, 0.1197, 0.3055, 0.2692] **
max =  0.3055 | max_idx =  5
**pseudo_label ->  [0.0, 0.1601, 0.0002, 0.1091, 0.2045, 0.2735, 0.2525] **
max =  0.2735 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 3702, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 535, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.145 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1445164829492569, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(4.1064, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7578, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 180, Time: 2:33:41
Train F1: 0.0357, Val F1: 0.0666, Test F1: 0.0163
Epoch 18/20, Train Acc: 0.1429, Val Acc: 0.1997, Test Acc: 0.0604, Test F1(macro): 0.0163, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0233, 0.0006, 0.0, 0.2019, 0.2239, 0.2563, 0.294] **
max =  0.294 | max_idx =  6
**pseudo_label ->  [0.0194, 0.0006, 0.0, 0.2578, 0.218, 0.2304, 0.2738] **
max =  0.2738 | max_idx =  6
**pseudo_label ->  [0.014, 0.0006, 0.0, 0.3167, 0.1479, 0.2509, 0.27] **
max =  0.3167 | max_idx =  3
**pseudo_label ->  [0.0227, 0.0006, 0.0, 0.1638, 0.249, 0.2511, 0.3129] **
max =  0.3129 | max_idx =  6
**pseudo_label ->  [0.0165, 0.0004, 0.0, 0.1726, 0.2146, 0.3009, 0.2949] **
max =  0.3009 | max_idx =  5
**pseudo_label ->  [0.0172, 0.0005, 0.0, 0.2271, 0.2747, 0.1937, 0.2868] **
max =  0.2868 | max_idx =  6
**pseudo_label ->  [0.0218, 0.0006, 0.0, 0.165, 0.2112, 0.3335, 0.268] **
max =  0.3335 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3715, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [610, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.164 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.16419918835163116, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(4.2836, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1574, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 190, Time: 2:42:39
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 19/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0005, 0.0, 0.0547, 0.2819, 0.2861, 0.212, 0.1648] **
max =  0.2861 | max_idx =  4
**pseudo_label ->  [0.0006, 0.0, 0.0531, 0.2258, 0.4107, 0.1502, 0.1595] **
max =  0.4107 | max_idx =  4
**pseudo_label ->  [0.0006, 0.0, 0.0421, 0.1378, 0.4093, 0.2463, 0.1639] **
max =  0.4093 | max_idx =  4
**pseudo_label ->  [0.0007, 0.0, 0.0571, 0.2227, 0.3004, 0.1967, 0.2223] **
max =  0.3004 | max_idx =  4
**pseudo_label ->  [0.0007, 0.0, 0.051, 0.2594, 0.2408, 0.2679, 0.1802] **
max =  0.2679 | max_idx =  5
**pseudo_label ->  [0.0004, 0.0, 0.0408, 0.2627, 0.2906, 0.2411, 0.1644] **
max =  0.2906 | max_idx =  4
**pseudo_label ->  [0.001, 0.0, 0.0651, 0.2031, 0.3256, 0.2322, 0.1731] **
max =  0.3256 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3737, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 566, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.151 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.15145838260650635, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.9998, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.6026, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 200, Time: 2:51:32
Train F1: 0.0357, Val F1: 0.0698, Test F1: 0.0382
Epoch 20/20, Train Acc: 0.1429, Val Acc: 0.2115, Test Acc: 0.1544, Test F1(macro): 0.0382, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 1, Train Data Number: 70


Training complete!
Total training took 2:51:32 (h:mm:ss)
Load model from ./experiment/jointmatch/output/10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[45]_{'java'}_net0.pth
Load model from ./experiment/jointmatch/output/10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[45]_{'java'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/unixcoder/joint_match//10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[45]_{'java'}/training_statistics.csv


Best_step:  50 
Best_val_epoch:  5 
best_val_acc:  0.28426395939086296 
best_val_test_acc:  0.22818791946308725 
best_val_test_f1:  0.05308352849336456
Save best record in:  ./experiment/jointmatch/log/unixcoder/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
