current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code

bs =>  7
Data set -> jointmatch
save_name: 10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'java'}

data_path:  ../data/jointmatch/java

There are 1 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base']
**tokenizer type =  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base'] 

n_labeled_per_class:  10
train_df samples: 3851
train_labeled_df samples: 70
train_unlabeled_df samples: 3781
Check n_smaples_per_class in the original training set:  OrderedDict([(1, 632), (2, 555), (3, 583), (4, 559), (5, 493), (6, 432), (7, 597)])
Check n_smaples_per_class in the labeled training set:  OrderedDict([(1, 10), (2, 10), (3, 10), (4, 10), (5, 10), (6, 10), (7, 10)])
Check n_smaples_per_class in the unlabeled training set:  OrderedDict([(1, 622), (2, 545), (3, 573), (4, 549), (5, 483), (6, 422), (7, 587)])
n_classes:  7

net_arch:  microsoft/unixcoder-base 
lr:  0.0004 
lr_linear:  0.001 


net_arch:  microsoft/unixcoder-base 
lr:  0.0002 
lr_linear:  0.001 

**pseudo_label ->  [0.0655, 0.2021, 0.127, 0.1366, 0.183, 0.1043, 0.1814] **
max =  0.2021 | max_idx =  1
**pseudo_label ->  [0.1136, 0.1978, 0.1167, 0.1194, 0.1461, 0.0874, 0.219] **
max =  0.219 | max_idx =  6
**pseudo_label ->  [0.0955, 0.1728, 0.1663, 0.0977, 0.1848, 0.0783, 0.2047] **
max =  0.2047 | max_idx =  6
**pseudo_label ->  [0.1873, 0.1803, 0.1485, 0.0657, 0.133, 0.1215, 0.1637] **
max =  0.1873 | max_idx =  0
**pseudo_label ->  [0.1051, 0.1403, 0.1273, 0.1265, 0.1645, 0.1245, 0.2118] **
max =  0.2118 | max_idx =  6
**pseudo_label ->  [0.0926, 0.205, 0.2257, 0.111, 0.1147, 0.0697, 0.1813] **
max =  0.2257 | max_idx =  2
**pseudo_label ->  [0.0909, 0.1856, 0.1424, 0.1787, 0.1685, 0.0896, 0.1443] **
max =  0.1856 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3739, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [611, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.163 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.1634126752614975, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9859, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8171, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 10, Time: 0:05:55
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 1/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1401, 0.2272, 0.166, 0.1016, 0.0519, 0.0993, 0.214] **
max =  0.2272 | max_idx =  1
**pseudo_label ->  [0.1659, 0.1661, 0.1133, 0.1336, 0.06, 0.171, 0.1901] **
max =  0.1901 | max_idx =  6
**pseudo_label ->  [0.1884, 0.1459, 0.1525, 0.1138, 0.0722, 0.1207, 0.2065] **
max =  0.2065 | max_idx =  6
**pseudo_label ->  [0.1741, 0.1958, 0.1317, 0.12, 0.0508, 0.1265, 0.2011] **
max =  0.2011 | max_idx =  6
**pseudo_label ->  [0.1816, 0.1632, 0.1177, 0.1302, 0.0601, 0.1307, 0.2165] **
max =  0.2165 | max_idx =  6
**pseudo_label ->  [0.1975, 0.1571, 0.1373, 0.1276, 0.0548, 0.1249, 0.2007] **
max =  0.2007 | max_idx =  6
**pseudo_label ->  [0.1565, 0.1865, 0.1498, 0.1341, 0.0628, 0.1672, 0.143] **
max =  0.1865 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 3624]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 555]
psl_acc(PSL 평가에서의 정확도):  0.153 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1531457006931305]
loss for labeled data =>  tensor(1.9479, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0254, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 20, Time: 0:11:46
Train F1: 0.0357, Val F1: 0.0000, Test F1: 0.0038
Epoch 2/20, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.391, 0.0585, 0.1213, 0.176, 0.0425, 0.1341, 0.0766] **
max =  0.391 | max_idx =  0
**pseudo_label ->  [0.3817, 0.0521, 0.1053, 0.1644, 0.0402, 0.1636, 0.0927] **
max =  0.3817 | max_idx =  0
**pseudo_label ->  [0.3125, 0.0485, 0.1215, 0.1446, 0.0486, 0.2226, 0.1016] **
max =  0.3125 | max_idx =  0
**pseudo_label ->  [0.3035, 0.0503, 0.1373, 0.1998, 0.0447, 0.1718, 0.0925] **
max =  0.3035 | max_idx =  0
**pseudo_label ->  [0.3517, 0.0539, 0.1625, 0.1584, 0.0379, 0.1599, 0.0758] **
max =  0.3517 | max_idx =  0
**pseudo_label ->  [0.3633, 0.0456, 0.1466, 0.1809, 0.0347, 0.1552, 0.0738] **
max =  0.3633 | max_idx =  0
**pseudo_label ->  [0.3529, 0.0402, 0.1713, 0.1435, 0.049, 0.1489, 0.0941] **
max =  0.3529 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.2368, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0386, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 30, Time: 0:17:34
Train F1: 0.0357, Val F1: 0.0000, Test F1: 0.0038
Epoch 3/20, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1224, 0.2048, 0.1444, 0.0932, 0.2295, 0.147, 0.0588] **
max =  0.2295 | max_idx =  4
**pseudo_label ->  [0.1139, 0.2272, 0.1246, 0.1507, 0.1764, 0.135, 0.0722] **
max =  0.2272 | max_idx =  1
**pseudo_label ->  [0.1129, 0.1577, 0.1249, 0.1033, 0.2755, 0.1564, 0.0693] **
max =  0.2755 | max_idx =  4
**pseudo_label ->  [0.1399, 0.2012, 0.1336, 0.1208, 0.2252, 0.1203, 0.059] **
max =  0.2252 | max_idx =  4
**pseudo_label ->  [0.1155, 0.1622, 0.1367, 0.1165, 0.2606, 0.1576, 0.051] **
max =  0.2606 | max_idx =  4
**pseudo_label ->  [0.0962, 0.2681, 0.1116, 0.1207, 0.2041, 0.135, 0.0644] **
max =  0.2681 | max_idx =  1
**pseudo_label ->  [0.1148, 0.1603, 0.1236, 0.1433, 0.2593, 0.13, 0.0688] **
max =  0.2593 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0735, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0405, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 40, Time: 0:23:21
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 4/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0359, 0.1747, 0.1307, 0.429, 0.0914, 0.069, 0.0692] **
max =  0.429 | max_idx =  3
**pseudo_label ->  [0.024, 0.1067, 0.1037, 0.562, 0.0619, 0.1018, 0.0399] **
max =  0.562 | max_idx =  3
**pseudo_label ->  [0.0281, 0.1399, 0.0934, 0.5255, 0.0793, 0.0673, 0.0666] **
max =  0.5255 | max_idx =  3
**pseudo_label ->  [0.0389, 0.1598, 0.1231, 0.4124, 0.082, 0.1072, 0.0766] **
max =  0.4124 | max_idx =  3
**pseudo_label ->  [0.0322, 0.1244, 0.1699, 0.4342, 0.1144, 0.0712, 0.0535] **
max =  0.4342 | max_idx =  3
**pseudo_label ->  [0.0438, 0.1711, 0.1009, 0.4417, 0.0866, 0.0911, 0.0647] **
max =  0.4417 | max_idx =  3
**pseudo_label ->  [0.029, 0.1573, 0.1027, 0.4992, 0.0848, 0.0747, 0.0524] **
max =  0.4992 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 3698, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 527, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.143 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.14250946044921875, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.4488, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0426, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 50, Time: 0:29:49
Train F1: 0.0357, Val F1: 0.0666, Test F1: 0.0163
Epoch 5/20, Train Acc: 0.1429, Val Acc: 0.1997, Test Acc: 0.0604, Test F1(macro): 0.0163, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0847, 0.0001, 0.3031, 0.2173, 0.0843, 0.2097, 0.1007] **
max =  0.3031 | max_idx =  2
**pseudo_label ->  [0.0824, 0.0001, 0.3332, 0.2572, 0.0857, 0.1438, 0.0976] **
max =  0.3332 | max_idx =  2
**pseudo_label ->  [0.0849, 0.0001, 0.3098, 0.223, 0.0886, 0.2084, 0.0852] **
max =  0.3098 | max_idx =  2
**pseudo_label ->  [0.0598, 0.0001, 0.3317, 0.2748, 0.075, 0.1705, 0.0882] **
max =  0.3317 | max_idx =  2
**pseudo_label ->  [0.073, 0.0001, 0.3318, 0.2335, 0.0915, 0.1485, 0.1217] **
max =  0.3318 | max_idx =  2
**pseudo_label ->  [0.0811, 0.0001, 0.2651, 0.2483, 0.0818, 0.2359, 0.0877] **
max =  0.2651 | max_idx =  2
**pseudo_label ->  [0.0639, 0.0001, 0.2805, 0.2594, 0.0833, 0.2094, 0.1034] **
max =  0.2805 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3755, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 569, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.152 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.15153129398822784, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.6526, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9302, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 60, Time: 0:35:59
Train F1: 0.0357, Val F1: 0.0698, Test F1: 0.0382
Epoch 6/20, Train Acc: 0.1429, Val Acc: 0.2115, Test Acc: 0.1544, Test F1(macro): 0.0382, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.2602, 0.0, 0.0003, 0.043, 0.3087, 0.1264, 0.2614] **
max =  0.3087 | max_idx =  4
**pseudo_label ->  [0.2862, 0.0, 0.0003, 0.0305, 0.2815, 0.122, 0.2795] **
max =  0.2862 | max_idx =  0
**pseudo_label ->  [0.276, 0.0, 0.0004, 0.0432, 0.2733, 0.14, 0.267] **
max =  0.276 | max_idx =  0
**pseudo_label ->  [0.2631, 0.0, 0.0003, 0.0252, 0.375, 0.0915, 0.2448] **
max =  0.375 | max_idx =  4
**pseudo_label ->  [0.2915, 0.0, 0.0002, 0.0364, 0.2567, 0.1301, 0.2851] **
max =  0.2915 | max_idx =  0
**pseudo_label ->  [0.3353, 0.0, 0.0003, 0.0267, 0.2391, 0.1395, 0.2591] **
max =  0.3353 | max_idx =  0
**pseudo_label ->  [0.2877, 0.0, 0.0003, 0.0344, 0.3373, 0.1342, 0.2061] **
max =  0.3373 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [2853, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [462, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.162 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.16193480789661407, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(4.7051, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1630, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 70, Time: 0:41:50
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 7/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.2861, 0.0983, 0.0605, 0.117, 0.2042, 0.102, 0.132] **
max =  0.2861 | max_idx =  0
**pseudo_label ->  [0.2888, 0.0693, 0.0786, 0.0944, 0.2428, 0.1153, 0.1109] **
max =  0.2888 | max_idx =  0
**pseudo_label ->  [0.295, 0.0914, 0.0601, 0.163, 0.168, 0.0828, 0.1398] **
max =  0.295 | max_idx =  0
**pseudo_label ->  [0.2665, 0.0591, 0.0535, 0.1182, 0.2541, 0.1267, 0.122] **
max =  0.2665 | max_idx =  0
**pseudo_label ->  [0.2725, 0.1157, 0.049, 0.1497, 0.182, 0.1019, 0.1291] **
max =  0.2725 | max_idx =  0
**pseudo_label ->  [0.2833, 0.1011, 0.0571, 0.1078, 0.2148, 0.1208, 0.115] **
max =  0.2833 | max_idx =  0
**pseudo_label ->  [0.2403, 0.1198, 0.0684, 0.1128, 0.2044, 0.1194, 0.1349] **
max =  0.2403 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3651, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [594, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.163 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.16269515454769135, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0472, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1541, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 80, Time: 0:47:38
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 8/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0003, 0.237, 0.1013, 0.0937, 0.105, 0.2493, 0.2135] **
max =  0.2493 | max_idx =  5
**pseudo_label ->  [0.0004, 0.22, 0.0611, 0.1549, 0.1606, 0.1786, 0.2245] **
max =  0.2245 | max_idx =  6
**pseudo_label ->  [0.0003, 0.204, 0.0639, 0.1961, 0.1609, 0.2275, 0.1473] **
max =  0.2275 | max_idx =  5
**pseudo_label ->  [0.0003, 0.2455, 0.0913, 0.1677, 0.109, 0.1728, 0.2134] **
max =  0.2455 | max_idx =  1
**pseudo_label ->  [0.0003, 0.2578, 0.114, 0.1946, 0.1242, 0.1243, 0.1848] **
max =  0.2578 | max_idx =  1
**pseudo_label ->  [0.0004, 0.218, 0.084, 0.1407, 0.1756, 0.2601, 0.1212] **
max =  0.2601 | max_idx =  5
**pseudo_label ->  [0.0004, 0.1751, 0.11, 0.1991, 0.1374, 0.2195, 0.1584] **
max =  0.2195 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.6202, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1065, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 90, Time: 0:53:23
Train F1: 0.0357, Val F1: 0.0684, Test F1: 0.0116
Epoch 9/20, Train Acc: 0.1429, Val Acc: 0.2064, Test Acc: 0.0425, Test F1(macro): 0.0116, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0515, 0.2533, 0.2466, 0.1738, 0.0904, 0.0487, 0.1358] **
max =  0.2533 | max_idx =  1
**pseudo_label ->  [0.0501, 0.2523, 0.2187, 0.1103, 0.1167, 0.0741, 0.1778] **
max =  0.2523 | max_idx =  1
**pseudo_label ->  [0.0825, 0.2284, 0.2369, 0.1616, 0.1158, 0.0658, 0.1091] **
max =  0.2369 | max_idx =  2
**pseudo_label ->  [0.0734, 0.2756, 0.1475, 0.1996, 0.0959, 0.0912, 0.1169] **
max =  0.2756 | max_idx =  1
**pseudo_label ->  [0.0621, 0.2025, 0.2072, 0.1608, 0.1142, 0.0979, 0.1553] **
max =  0.2072 | max_idx =  2
**pseudo_label ->  [0.051, 0.2474, 0.145, 0.1875, 0.1096, 0.0965, 0.1631] **
max =  0.2474 | max_idx =  1
**pseudo_label ->  [0.0715, 0.206, 0.1559, 0.2085, 0.0986, 0.1087, 0.1509] **
max =  0.2085 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3713, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 569, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.153 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.15324535965919495, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9515, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.5934, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 100, Time: 0:59:10
Train F1: 0.0357, Val F1: 0.0698, Test F1: 0.0382
Epoch 10/20, Train Acc: 0.1429, Val Acc: 0.2115, Test Acc: 0.1544, Test F1(macro): 0.0382, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0189, 0.1772, 0.0116, 0.2186, 0.1598, 0.2083, 0.2057] **
max =  0.2186 | max_idx =  3
**pseudo_label ->  [0.0258, 0.1455, 0.0085, 0.253, 0.1891, 0.176, 0.2021] **
max =  0.253 | max_idx =  3
**pseudo_label ->  [0.0189, 0.2095, 0.0104, 0.168, 0.1701, 0.2236, 0.1995] **
max =  0.2236 | max_idx =  5
**pseudo_label ->  [0.0222, 0.2224, 0.0106, 0.2188, 0.1583, 0.1427, 0.225] **
max =  0.225 | max_idx =  6
**pseudo_label ->  [0.0298, 0.262, 0.0064, 0.1931, 0.1483, 0.175, 0.1854] **
max =  0.262 | max_idx =  1
**pseudo_label ->  [0.0202, 0.2288, 0.0155, 0.1374, 0.1099, 0.2493, 0.2388] **
max =  0.2493 | max_idx =  5
**pseudo_label ->  [0.0179, 0.2174, 0.0085, 0.1788, 0.1243, 0.2181, 0.235] **
max =  0.235 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 629, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 100, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.159 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.158982515335083, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.4116, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.3330, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 110, Time: 1:04:55
Train F1: 0.0357, Val F1: 0.0666, Test F1: 0.0163
Epoch 11/20, Train Acc: 0.1429, Val Acc: 0.1997, Test Acc: 0.0604, Test F1(macro): 0.0163, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1938, 0.0004, 0.1263, 0.1333, 0.2887, 0.1525, 0.1051] **
max =  0.2887 | max_idx =  4
**pseudo_label ->  [0.2121, 0.0004, 0.1363, 0.1568, 0.1693, 0.1545, 0.1705] **
max =  0.2121 | max_idx =  0
**pseudo_label ->  [0.2947, 0.0003, 0.1367, 0.0824, 0.214, 0.1432, 0.1287] **
max =  0.2947 | max_idx =  0
**pseudo_label ->  [0.2636, 0.0002, 0.1753, 0.1277, 0.1734, 0.1445, 0.1153] **
max =  0.2636 | max_idx =  0
**pseudo_label ->  [0.16, 0.0002, 0.2566, 0.1776, 0.125, 0.1412, 0.1393] **
max =  0.2566 | max_idx =  2
**pseudo_label ->  [0.3018, 0.0002, 0.108, 0.1395, 0.1953, 0.1274, 0.1277] **
max =  0.3018 | max_idx =  0
**pseudo_label ->  [0.3058, 0.0002, 0.099, 0.1604, 0.1494, 0.1142, 0.1709] **
max =  0.3058 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3557, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [588, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.165 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.16530784964561462, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7586, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.0493, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 120, Time: 1:10:42
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 12/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0009, 0.0001, 0.1632, 0.2011, 0.1745, 0.2072, 0.2531] **
max =  0.2531 | max_idx =  6
**pseudo_label ->  [0.0005, 0.0, 0.1646, 0.1421, 0.2006, 0.3126, 0.1797] **
max =  0.3126 | max_idx =  5
**pseudo_label ->  [0.0006, 0.0001, 0.2029, 0.151, 0.2662, 0.2226, 0.1567] **
max =  0.2662 | max_idx =  4
**pseudo_label ->  [0.0004, 0.0001, 0.1345, 0.2225, 0.1513, 0.2818, 0.2095] **
max =  0.2818 | max_idx =  5
**pseudo_label ->  [0.0006, 0.0001, 0.2206, 0.22, 0.1757, 0.1945, 0.1886] **
max =  0.2206 | max_idx =  2
**pseudo_label ->  [0.0007, 0.0001, 0.1697, 0.1714, 0.2396, 0.2489, 0.1697] **
max =  0.2489 | max_idx =  5
**pseudo_label ->  [0.0006, 0.0001, 0.1807, 0.181, 0.1559, 0.2982, 0.1836] **
max =  0.2982 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3739, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 570, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.152 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.1524471789598465, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.7032, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.7749, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 130, Time: 1:16:29
Train F1: 0.0357, Val F1: 0.0698, Test F1: 0.0382
Epoch 13/20, Train Acc: 0.1429, Val Acc: 0.2115, Test Acc: 0.1544, Test F1(macro): 0.0382, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0004, 0.3832, 0.0002, 0.1486, 0.1109, 0.1828, 0.1739] **
max =  0.3832 | max_idx =  1
**pseudo_label ->  [0.0003, 0.3383, 0.0003, 0.1876, 0.1375, 0.1312, 0.2048] **
max =  0.3383 | max_idx =  1
**pseudo_label ->  [0.0003, 0.2913, 0.0004, 0.1906, 0.1157, 0.2737, 0.128] **
max =  0.2913 | max_idx =  1
**pseudo_label ->  [0.0003, 0.2703, 0.0003, 0.1927, 0.1467, 0.2175, 0.1723] **
max =  0.2703 | max_idx =  1
**pseudo_label ->  [0.0003, 0.3952, 0.0003, 0.1541, 0.1466, 0.1538, 0.1499] **
max =  0.3952 | max_idx =  1
**pseudo_label ->  [0.0003, 0.3036, 0.0001, 0.2042, 0.1167, 0.1504, 0.2247] **
max =  0.3036 | max_idx =  1
**pseudo_label ->  [0.0003, 0.367, 0.0005, 0.1548, 0.0878, 0.2255, 0.1642] **
max =  0.367 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 3751, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 540, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.144 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1439616084098816, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.5906, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.1253, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 140, Time: 1:22:17
Train F1: 0.0357, Val F1: 0.0666, Test F1: 0.0163
Epoch 14/20, Train Acc: 0.1429, Val Acc: 0.1997, Test Acc: 0.0604, Test F1(macro): 0.0163, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.2144, 0.0003, 0.0, 0.0915, 0.0564, 0.5248, 0.1125] **
max =  0.5248 | max_idx =  5
**pseudo_label ->  [0.1841, 0.0003, 0.0, 0.1203, 0.1119, 0.4597, 0.1237] **
max =  0.4597 | max_idx =  5
**pseudo_label ->  [0.2508, 0.0004, 0.0, 0.1071, 0.102, 0.386, 0.1537] **
max =  0.386 | max_idx =  5
**pseudo_label ->  [0.1867, 0.0003, 0.0, 0.0667, 0.1719, 0.4444, 0.13] **
max =  0.4444 | max_idx =  5
**pseudo_label ->  [0.193, 0.0003, 0.0, 0.0969, 0.1117, 0.476, 0.122] **
max =  0.476 | max_idx =  5
**pseudo_label ->  [0.1991, 0.0003, 0.0, 0.0914, 0.0983, 0.4786, 0.1322] **
max =  0.4786 | max_idx =  5
**pseudo_label ->  [0.2224, 0.0002, 0.0, 0.1033, 0.0855, 0.4363, 0.1523] **
max =  0.4363 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3728, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 566, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.152 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.15182402729988098, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.7615, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.6183, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 150, Time: 1:28:04
Train F1: 0.0357, Val F1: 0.0698, Test F1: 0.0382
Epoch 15/20, Train Acc: 0.1429, Val Acc: 0.2115, Test Acc: 0.1544, Test F1(macro): 0.0382, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0091, 0.0, 0.0071, 0.3714, 0.2942, 0.0034, 0.3147] **
max =  0.3714 | max_idx =  3
**pseudo_label ->  [0.0091, 0.0, 0.0169, 0.2915, 0.3063, 0.0045, 0.3716] **
max =  0.3716 | max_idx =  6
**pseudo_label ->  [0.0136, 0.0001, 0.0153, 0.3057, 0.3035, 0.0042, 0.3577] **
max =  0.3577 | max_idx =  6
**pseudo_label ->  [0.0125, 0.0001, 0.0175, 0.3501, 0.3934, 0.0039, 0.2226] **
max =  0.3934 | max_idx =  4
**pseudo_label ->  [0.0081, 0.0001, 0.0108, 0.418, 0.2784, 0.0044, 0.2803] **
max =  0.418 | max_idx =  3
**pseudo_label ->  [0.0123, 0.0001, 0.0161, 0.3979, 0.2926, 0.0029, 0.2782] **
max =  0.3979 | max_idx =  3
**pseudo_label ->  [0.0085, 0.0, 0.0059, 0.3918, 0.3192, 0.004, 0.2707] **
max =  0.3918 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 3661]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 567]
psl_acc(PSL 평가에서의 정확도):  0.155 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.154875710606575]
loss for labeled data =>  tensor(3.9238, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1172, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 160, Time: 1:33:52
Train F1: 0.0357, Val F1: 0.0000, Test F1: 0.0038
Epoch 16/20, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.0134, Test F1(macro): 0.0038, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0432, 0.1753, 0.1634, 0.2384, 0.2102, 0.1615, 0.008] **
max =  0.2384 | max_idx =  3
**pseudo_label ->  [0.0621, 0.1552, 0.2089, 0.1488, 0.2042, 0.213, 0.008] **
max =  0.213 | max_idx =  5
**pseudo_label ->  [0.0484, 0.1571, 0.125, 0.1617, 0.2594, 0.2431, 0.0053] **
max =  0.2594 | max_idx =  4
**pseudo_label ->  [0.0391, 0.177, 0.1136, 0.1283, 0.2873, 0.2474, 0.0073] **
max =  0.2873 | max_idx =  4
**pseudo_label ->  [0.0656, 0.1735, 0.1941, 0.1779, 0.2066, 0.1758, 0.0064] **
max =  0.2066 | max_idx =  4
**pseudo_label ->  [0.052, 0.1334, 0.1712, 0.1598, 0.3072, 0.1694, 0.007] **
max =  0.3072 | max_idx =  4
**pseudo_label ->  [0.0342, 0.1436, 0.2249, 0.1492, 0.2714, 0.17, 0.0068] **
max =  0.2714 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3615, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 460, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.127 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.12724758684635162, nan, nan]
loss for labeled data =>  tensor(2.3574, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.2942, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 170, Time: 1:39:59
Train F1: 0.0357, Val F1: 0.0885, Test F1: 0.0531
Epoch 17/20, Train Acc: 0.1429, Val Acc: 0.2843, Test Acc: 0.2282, Test F1(macro): 0.0531, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.3356, 0.2315, 0.0687, 0.2035, 0.0006, 0.1575, 0.0028] **
max =  0.3356 | max_idx =  0
**pseudo_label ->  [0.2791, 0.2979, 0.1783, 0.0929, 0.0003, 0.1478, 0.0037] **
max =  0.2979 | max_idx =  1
**pseudo_label ->  [0.3418, 0.2408, 0.148, 0.1369, 0.0003, 0.1284, 0.0037] **
max =  0.3418 | max_idx =  0
**pseudo_label ->  [0.4558, 0.2172, 0.0611, 0.1475, 0.0005, 0.1136, 0.0042] **
max =  0.4558 | max_idx =  0
**pseudo_label ->  [0.4308, 0.1923, 0.0786, 0.1502, 0.0004, 0.1455, 0.0023] **
max =  0.4308 | max_idx =  0
**pseudo_label ->  [0.4459, 0.1869, 0.0643, 0.1263, 0.0004, 0.1732, 0.003] **
max =  0.4459 | max_idx =  0
**pseudo_label ->  [0.3091, 0.299, 0.1301, 0.1218, 0.0002, 0.137, 0.0026] **
max =  0.3091 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 3621, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 532, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.147 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.14692074060440063, nan, nan, nan]
loss for labeled data =>  tensor(3.2654, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.6130, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 180, Time: 1:45:48
Train F1: 0.0357, Val F1: 0.0684, Test F1: 0.0116
Epoch 18/20, Train Acc: 0.1429, Val Acc: 0.2064, Test Acc: 0.0425, Test F1(macro): 0.0116, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0334, 0.377, 0.1389, 0.006, 0.2134, 0.0504, 0.1809] **
max =  0.377 | max_idx =  1
**pseudo_label ->  [0.0548, 0.3313, 0.1036, 0.0143, 0.1477, 0.0574, 0.2908] **
max =  0.3313 | max_idx =  1
**pseudo_label ->  [0.0398, 0.3713, 0.1055, 0.0093, 0.1748, 0.0852, 0.2142] **
max =  0.3713 | max_idx =  1
**pseudo_label ->  [0.046, 0.3876, 0.0798, 0.0076, 0.1936, 0.084, 0.2014] **
max =  0.3876 | max_idx =  1
**pseudo_label ->  [0.0348, 0.3347, 0.1377, 0.0099, 0.1768, 0.0742, 0.232] **
max =  0.3347 | max_idx =  1
**pseudo_label ->  [0.0413, 0.4089, 0.1687, 0.0076, 0.0946, 0.044, 0.2349] **
max =  0.4089 | max_idx =  1
**pseudo_label ->  [0.0296, 0.4159, 0.2441, 0.0071, 0.0821, 0.027, 0.1942] **
max =  0.4159 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3722, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [614, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.165 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.16496507823467255, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.5451, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.2990, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 190, Time: 1:51:35
Train F1: 0.0357, Val F1: 0.0357, Test F1: 0.0338
Epoch 19/20, Train Acc: 0.1429, Val Acc: 0.0981, Test Acc: 0.1342, Test F1(macro): 0.0338, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0008, 0.0778, 0.203, 0.0045, 0.1376, 0.4504, 0.1258] **
max =  0.4504 | max_idx =  5
**pseudo_label ->  [0.0011, 0.0965, 0.2646, 0.0059, 0.0974, 0.3734, 0.1612] **
max =  0.3734 | max_idx =  5
**pseudo_label ->  [0.0006, 0.0745, 0.3402, 0.0048, 0.0777, 0.3242, 0.1779] **
max =  0.3402 | max_idx =  2
**pseudo_label ->  [0.0011, 0.066, 0.2361, 0.0053, 0.0948, 0.4714, 0.1253] **
max =  0.4714 | max_idx =  5
**pseudo_label ->  [0.0008, 0.0941, 0.3921, 0.0032, 0.0602, 0.3191, 0.1304] **
max =  0.3921 | max_idx =  2
**pseudo_label ->  [0.001, 0.0783, 0.4832, 0.0076, 0.0902, 0.2639, 0.0758] **
max =  0.4832 | max_idx =  2
**pseudo_label ->  [0.0009, 0.0683, 0.3707, 0.0029, 0.0631, 0.3696, 0.1246] **
max =  0.3707 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 3745, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 419, 0]
psl_acc(PSL 평가에서의 정확도):  0.112 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, 0.11188250780105591, nan]
loss for labeled data =>  tensor(3.0527, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.0733, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 200, Time: 1:57:23
Train F1: 0.0357, Val F1: 0.0000, Test F1: 0.0767
Epoch 20/20, Train Acc: 0.1429, Val Acc: 0.0000, Test Acc: 0.3669, Test F1(macro): 0.0767, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0, Train Data Number: 70


Training complete!
Total training took 1:57:23 (h:mm:ss)
Load model from ./experiment/jointmatch/output/10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'java'}_net0.pth
Load model from ./experiment/jointmatch/output/10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'java'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/unixcoder/joint_match//10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'java'}/training_statistics.csv


Best_step:  170 
Best_val_epoch:  17 
best_val_acc:  0.28426395939086296 
best_val_test_acc:  0.22818791946308725 
best_val_test_f1:  0.05308352849336456
Save best record in:  ./experiment/jointmatch/log/unixcoder/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
