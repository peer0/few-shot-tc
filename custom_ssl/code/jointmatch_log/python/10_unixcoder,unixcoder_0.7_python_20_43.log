current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code

bs =>  7
Data set -> jointmatch
save_name: 10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[43]_{'python'}

data_path:  ../data/jointmatch/python

There are 1 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base']
**tokenizer type =  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base'] 

n_labeled_per_class:  10
train_df samples: 3974
train_labeled_df samples: 70
train_unlabeled_df samples: 3904
Check n_smaples_per_class in the original training set:  OrderedDict([(1, 704), (2, 514), (3, 707), (4, 585), (5, 580), (6, 426), (7, 458)])
Check n_smaples_per_class in the labeled training set:  OrderedDict([(1, 10), (2, 10), (3, 10), (4, 10), (5, 10), (6, 10), (7, 10)])
Check n_smaples_per_class in the unlabeled training set:  OrderedDict([(1, 694), (2, 504), (3, 697), (4, 575), (5, 570), (6, 416), (7, 448)])
n_classes:  7

net_arch:  microsoft/unixcoder-base 
lr:  0.0004 
lr_linear:  0.001 


net_arch:  microsoft/unixcoder-base 
lr:  0.0002 
lr_linear:  0.001 

**pseudo_label ->  [0.1792, 0.1305, 0.1591, 0.1298, 0.1025, 0.1955, 0.1033] **
max =  0.1955 | max_idx =  5
**pseudo_label ->  [0.191, 0.099, 0.2076, 0.0952, 0.1457, 0.1482, 0.1133] **
max =  0.2076 | max_idx =  2
**pseudo_label ->  [0.1585, 0.1962, 0.1191, 0.1357, 0.0998, 0.1433, 0.1474] **
max =  0.1962 | max_idx =  1
**pseudo_label ->  [0.2223, 0.1352, 0.1471, 0.1112, 0.1343, 0.1388, 0.1111] **
max =  0.2223 | max_idx =  0
**pseudo_label ->  [0.1729, 0.1665, 0.1494, 0.1209, 0.1542, 0.1042, 0.1318] **
max =  0.1729 | max_idx =  0
**pseudo_label ->  [0.2262, 0.151, 0.1442, 0.0895, 0.139, 0.145, 0.1051] **
max =  0.2262 | max_idx =  0
**pseudo_label ->  [0.2564, 0.1984, 0.1012, 0.1101, 0.1209, 0.1145, 0.0985] **
max =  0.2564 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9006, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9878, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 10, Time: 0:08:24
Train F1: 0.0357, Val F1: 0.0239, Test F1: 0.0206
Epoch 1/20, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1737, 0.1001, 0.1663, 0.0927, 0.1501, 0.0801, 0.237] **
max =  0.237 | max_idx =  6
**pseudo_label ->  [0.303, 0.1805, 0.1468, 0.1455, 0.0628, 0.0561, 0.1054] **
max =  0.303 | max_idx =  0
**pseudo_label ->  [0.4022, 0.1565, 0.1189, 0.1403, 0.0689, 0.0393, 0.0739] **
max =  0.4022 | max_idx =  0
**pseudo_label ->  [0.3859, 0.1669, 0.1284, 0.134, 0.0623, 0.0494, 0.0732] **
max =  0.3859 | max_idx =  0
**pseudo_label ->  [0.2148, 0.1956, 0.2165, 0.1157, 0.0742, 0.0416, 0.1416] **
max =  0.2165 | max_idx =  2
**pseudo_label ->  [0.2972, 0.1512, 0.209, 0.1112, 0.0726, 0.0519, 0.1068] **
max =  0.2972 | max_idx =  0
**pseudo_label ->  [0.2495, 0.1861, 0.1469, 0.1371, 0.0997, 0.0597, 0.1209] **
max =  0.2495 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3875, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [690, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.178 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.1780645102262497, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.8870, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8365, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 20, Time: 0:16:56
Train F1: 0.0357, Val F1: 0.0239, Test F1: 0.0206
Epoch 2/20, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.3128, 0.074, 0.0739, 0.1535, 0.1665, 0.0663, 0.153] **
max =  0.3128 | max_idx =  0
**pseudo_label ->  [0.2375, 0.0585, 0.0741, 0.1527, 0.2104, 0.0465, 0.2203] **
max =  0.2375 | max_idx =  0
**pseudo_label ->  [0.2715, 0.0665, 0.0685, 0.1434, 0.2084, 0.0641, 0.1776] **
max =  0.2715 | max_idx =  0
**pseudo_label ->  [0.3345, 0.0693, 0.0723, 0.1474, 0.1527, 0.0509, 0.1729] **
max =  0.3345 | max_idx =  0
**pseudo_label ->  [0.2922, 0.0704, 0.0633, 0.1721, 0.1505, 0.0421, 0.2093] **
max =  0.2922 | max_idx =  0
**pseudo_label ->  [0.3087, 0.0722, 0.0701, 0.1272, 0.1498, 0.0388, 0.2332] **
max =  0.3087 | max_idx =  0
**pseudo_label ->  [0.2642, 0.057, 0.1005, 0.1494, 0.1268, 0.0446, 0.2575] **
max =  0.2642 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3846, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 566, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.147 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.14716587960720062, nan, nan]
loss for labeled data =>  tensor(2.0683, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1320, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 30, Time: 0:25:49
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 3/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0569, 0.2547, 0.1233, 0.1413, 0.0001, 0.182, 0.2416] **
max =  0.2547 | max_idx =  1
**pseudo_label ->  [0.0562, 0.2162, 0.1099, 0.1442, 0.0002, 0.1769, 0.2964] **
max =  0.2964 | max_idx =  6
**pseudo_label ->  [0.0682, 0.2457, 0.1385, 0.1726, 0.0002, 0.1668, 0.2081] **
max =  0.2457 | max_idx =  1
**pseudo_label ->  [0.0681, 0.2134, 0.1731, 0.1291, 0.0001, 0.1851, 0.231] **
max =  0.231 | max_idx =  6
**pseudo_label ->  [0.0797, 0.2298, 0.1225, 0.1787, 0.0002, 0.1272, 0.2619] **
max =  0.2619 | max_idx =  6
**pseudo_label ->  [0.0463, 0.2534, 0.1538, 0.1843, 0.0002, 0.1439, 0.2181] **
max =  0.2534 | max_idx =  1
**pseudo_label ->  [0.0445, 0.2469, 0.1493, 0.1375, 0.0001, 0.1453, 0.2764] **
max =  0.2764 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3779, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [675, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.179 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.1786186844110489, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7029, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.4083, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 40, Time: 0:34:15
Train F1: 0.0357, Val F1: 0.0239, Test F1: 0.0206
Epoch 4/20, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0006, 0.1698, 0.2021, 0.2275, 0.0, 0.1448, 0.2551] **
max =  0.2551 | max_idx =  6
**pseudo_label ->  [0.0007, 0.1682, 0.3159, 0.1494, 0.0, 0.1464, 0.2193] **
max =  0.3159 | max_idx =  2
**pseudo_label ->  [0.001, 0.1683, 0.2321, 0.168, 0.0, 0.1501, 0.2806] **
max =  0.2806 | max_idx =  6
**pseudo_label ->  [0.0006, 0.1956, 0.2768, 0.1285, 0.0, 0.1218, 0.2766] **
max =  0.2768 | max_idx =  2
**pseudo_label ->  [0.0008, 0.1755, 0.2168, 0.2276, 0.0, 0.0907, 0.2885] **
max =  0.2885 | max_idx =  6
**pseudo_label ->  [0.0007, 0.1605, 0.3394, 0.1587, 0.0, 0.1338, 0.2069] **
max =  0.3394 | max_idx =  2
**pseudo_label ->  [0.0007, 0.1979, 0.2266, 0.2166, 0.0, 0.1638, 0.1945] **
max =  0.2266 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 3827, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 407, 0]
psl_acc(PSL 평가에서의 정확도):  0.106 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, 0.10634962469339371, nan]
loss for labeled data =>  tensor(4.2408, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1162, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 50, Time: 0:42:34
Train F1: 0.0357, Val F1: 0.0073, Test F1: 0.0654
Epoch 5/20, Train Acc: 0.1429, Val Acc: 0.0261, Test Acc: 0.2971, Test F1(macro): 0.0654, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1472, 0.1956, 0.1757, 0.0979, 0.0847, 0.1001, 0.1989] **
max =  0.1989 | max_idx =  6
**pseudo_label ->  [0.0924, 0.1284, 0.2313, 0.1255, 0.0908, 0.0942, 0.2375] **
max =  0.2375 | max_idx =  6
**pseudo_label ->  [0.0955, 0.1683, 0.199, 0.1063, 0.1299, 0.0747, 0.2264] **
max =  0.2264 | max_idx =  6
**pseudo_label ->  [0.0911, 0.1487, 0.1792, 0.1336, 0.0965, 0.0702, 0.2806] **
max =  0.2806 | max_idx =  6
**pseudo_label ->  [0.118, 0.1341, 0.1431, 0.1285, 0.1228, 0.0919, 0.2615] **
max =  0.2615 | max_idx =  6
**pseudo_label ->  [0.1409, 0.113, 0.1519, 0.1319, 0.1217, 0.0591, 0.2816] **
max =  0.2816 | max_idx =  6
**pseudo_label ->  [0.1056, 0.1194, 0.1689, 0.1728, 0.0621, 0.097, 0.2743] **
max =  0.2743 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3839, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [681, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.177 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.1773899495601654, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0321, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.5841, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 60, Time: 0:51:01
Train F1: 0.0357, Val F1: 0.0239, Test F1: 0.0206
Epoch 6/20, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0003, 0.2267, 0.1835, 0.1341, 0.1704, 0.1438, 0.1411] **
max =  0.2267 | max_idx =  1
**pseudo_label ->  [0.0004, 0.1452, 0.2078, 0.1409, 0.242, 0.1349, 0.1287] **
max =  0.242 | max_idx =  4
**pseudo_label ->  [0.0003, 0.1711, 0.2152, 0.1914, 0.1607, 0.0916, 0.1697] **
max =  0.2152 | max_idx =  2
**pseudo_label ->  [0.0004, 0.2613, 0.1508, 0.1692, 0.1636, 0.1366, 0.1181] **
max =  0.2613 | max_idx =  1
**pseudo_label ->  [0.0004, 0.1844, 0.1743, 0.1658, 0.1959, 0.1516, 0.1275] **
max =  0.1959 | max_idx =  4
**pseudo_label ->  [0.0003, 0.2072, 0.1817, 0.1606, 0.2459, 0.101, 0.1032] **
max =  0.2459 | max_idx =  4
**pseudo_label ->  [0.0007, 0.1976, 0.1561, 0.1431, 0.288, 0.0939, 0.1206] **
max =  0.288 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3760, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 550, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.146 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.146276593208313, nan, nan]
loss for labeled data =>  tensor(2.6369, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0386, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 70, Time: 0:59:12
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 7/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 70

**pseudo_label ->  [0.0001, 0.1916, 0.2004, 0.2029, 0.0009, 0.213, 0.191] **
max =  0.213 | max_idx =  5
**pseudo_label ->  [0.0001, 0.1888, 0.1287, 0.2602, 0.0008, 0.1811, 0.2402] **
max =  0.2602 | max_idx =  3
**pseudo_label ->  [0.0, 0.1294, 0.1867, 0.3198, 0.0009, 0.2062, 0.1571] **
max =  0.3198 | max_idx =  3
**pseudo_label ->  [0.0001, 0.1721, 0.1536, 0.2765, 0.0016, 0.2225, 0.1736] **
max =  0.2765 | max_idx =  3
**pseudo_label ->  [0.0001, 0.2092, 0.1871, 0.2368, 0.0014, 0.1953, 0.1702] **
max =  0.2368 | max_idx =  3
**pseudo_label ->  [0.0001, 0.1603, 0.2343, 0.2039, 0.0012, 0.21, 0.1903] **
max =  0.2343 | max_idx =  2
**pseudo_label ->  [0.0, 0.2284, 0.1625, 0.2466, 0.001, 0.1953, 0.1661] **
max =  0.2466 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 3869, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 410, 0]
psl_acc(PSL 평가에서의 정확도):  0.106 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, 0.10597053170204163, nan]
loss for labeled data =>  tensor(3.6375, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9792, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 80, Time: 1:07:40
Train F1: 0.0357, Val F1: 0.0073, Test F1: 0.0654
Epoch 8/20, Train Acc: 0.1429, Val Acc: 0.0261, Test Acc: 0.2971, Test F1(macro): 0.0654, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 70

**pseudo_label ->  [0.2535, 0.2161, 0.1607, 0.1709, 0.001, 0.0007, 0.1971] **
max =  0.2535 | max_idx =  0
**pseudo_label ->  [0.2112, 0.2287, 0.2223, 0.1701, 0.0015, 0.0007, 0.1656] **
max =  0.2287 | max_idx =  1
**pseudo_label ->  [0.2203, 0.2561, 0.1765, 0.1408, 0.001, 0.0005, 0.2048] **
max =  0.2561 | max_idx =  1
**pseudo_label ->  [0.1755, 0.2032, 0.2127, 0.1728, 0.0008, 0.0004, 0.2348] **
max =  0.2348 | max_idx =  6
**pseudo_label ->  [0.232, 0.2205, 0.198, 0.1753, 0.0014, 0.0005, 0.1722] **
max =  0.232 | max_idx =  0
**pseudo_label ->  [0.2113, 0.2032, 0.2293, 0.155, 0.0013, 0.0005, 0.1994] **
max =  0.2293 | max_idx =  2
**pseudo_label ->  [0.2338, 0.2058, 0.1946, 0.1433, 0.0012, 0.0006, 0.2206] **
max =  0.2338 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3869, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [691, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.179 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.17859911918640137, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.0414, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1800, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 90, Time: 1:15:56
Train F1: 0.0357, Val F1: 0.0239, Test F1: 0.0206
Epoch 9/20, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 70

**pseudo_label ->  [0.0004, 0.3218, 0.092, 0.2197, 0.2127, 0.0001, 0.1534] **
max =  0.3218 | max_idx =  1
**pseudo_label ->  [0.0002, 0.3135, 0.1025, 0.1877, 0.2177, 0.0001, 0.1783] **
max =  0.3135 | max_idx =  1
**pseudo_label ->  [0.0004, 0.2612, 0.1224, 0.1953, 0.1887, 0.0001, 0.232] **
max =  0.2612 | max_idx =  1
**pseudo_label ->  [0.0003, 0.2109, 0.1219, 0.2334, 0.2201, 0.0001, 0.2133] **
max =  0.2334 | max_idx =  3
**pseudo_label ->  [0.0004, 0.3427, 0.1183, 0.1786, 0.1941, 0.0001, 0.1658] **
max =  0.3427 | max_idx =  1
**pseudo_label ->  [0.0002, 0.2174, 0.0976, 0.207, 0.1981, 0.0, 0.2797] **
max =  0.2797 | max_idx =  6
**pseudo_label ->  [0.0003, 0.426, 0.1142, 0.1679, 0.1286, 0.0, 0.1629] **
max =  0.426 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3755, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 549, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.146 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.14620505273342133, nan, nan]
loss for labeled data =>  tensor(3.8495, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1402, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 100, Time: 1:24:27
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 10/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 70

**pseudo_label ->  [0.0, 0.2296, 0.2505, 0.1626, 0.0004, 0.1405, 0.2164] **
max =  0.2505 | max_idx =  2
**pseudo_label ->  [0.0, 0.1776, 0.2223, 0.2251, 0.0004, 0.1882, 0.1864] **
max =  0.2251 | max_idx =  3
**pseudo_label ->  [0.0, 0.1808, 0.1741, 0.2314, 0.0005, 0.1885, 0.2246] **
max =  0.2314 | max_idx =  3
**pseudo_label ->  [0.0, 0.184, 0.2503, 0.2114, 0.0003, 0.1468, 0.2072] **
max =  0.2503 | max_idx =  2
**pseudo_label ->  [0.0, 0.1704, 0.1469, 0.2139, 0.0004, 0.2279, 0.2405] **
max =  0.2405 | max_idx =  6
**pseudo_label ->  [0.0, 0.163, 0.1364, 0.3098, 0.0006, 0.2439, 0.1462] **
max =  0.3098 | max_idx =  3
**pseudo_label ->  [0.0, 0.219, 0.2086, 0.1692, 0.0005, 0.1553, 0.2475] **
max =  0.2475 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 3876, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 416, 0]
psl_acc(PSL 평가에서의 정확도):  0.107 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, 0.10732714086771011, nan]
loss for labeled data =>  tensor(3.9624, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.3693, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 110, Time: 1:32:55
Train F1: 0.0357, Val F1: 0.0073, Test F1: 0.0654
Epoch 11/20, Train Acc: 0.1429, Val Acc: 0.0261, Test Acc: 0.2971, Test F1(macro): 0.0654, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 70

**pseudo_label ->  [0.363, 0.1533, 0.1204, 0.1773, 0.0004, 0.0015, 0.1841] **
max =  0.363 | max_idx =  0
**pseudo_label ->  [0.351, 0.2101, 0.1136, 0.1636, 0.0006, 0.0008, 0.1604] **
max =  0.351 | max_idx =  0
**pseudo_label ->  [0.4073, 0.1757, 0.1062, 0.1482, 0.0007, 0.0008, 0.1611] **
max =  0.4073 | max_idx =  0
**pseudo_label ->  [0.5386, 0.1271, 0.0861, 0.1384, 0.0004, 0.0008, 0.1085] **
max =  0.5386 | max_idx =  0
**pseudo_label ->  [0.401, 0.1367, 0.1123, 0.2091, 0.0006, 0.001, 0.1393] **
max =  0.401 | max_idx =  0
**pseudo_label ->  [0.3725, 0.1512, 0.1211, 0.1853, 0.0006, 0.0019, 0.1673] **
max =  0.3725 | max_idx =  0
**pseudo_label ->  [0.3955, 0.1601, 0.1358, 0.169, 0.0004, 0.0008, 0.1383] **
max =  0.3955 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3889, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [693, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.178 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.17819491028785706, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.5457, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7329, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 120, Time: 1:41:23
Train F1: 0.0357, Val F1: 0.0239, Test F1: 0.0206
Epoch 12/20, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 70

**pseudo_label ->  [0.0127, 0.1908, 0.1014, 0.1383, 0.3418, 0.0388, 0.1762] **
max =  0.3418 | max_idx =  4
**pseudo_label ->  [0.0117, 0.2006, 0.062, 0.101, 0.4208, 0.0789, 0.1249] **
max =  0.4208 | max_idx =  4
**pseudo_label ->  [0.0115, 0.1764, 0.0967, 0.1524, 0.3256, 0.0811, 0.1563] **
max =  0.3256 | max_idx =  4
**pseudo_label ->  [0.0085, 0.1849, 0.1048, 0.1268, 0.3218, 0.0631, 0.1901] **
max =  0.3218 | max_idx =  4
**pseudo_label ->  [0.0132, 0.2078, 0.0968, 0.1229, 0.3071, 0.0398, 0.2124] **
max =  0.3071 | max_idx =  4
**pseudo_label ->  [0.0111, 0.2018, 0.0939, 0.1513, 0.2808, 0.0448, 0.2163] **
max =  0.2808 | max_idx =  4
**pseudo_label ->  [0.0131, 0.2034, 0.0748, 0.0813, 0.3769, 0.0445, 0.206] **
max =  0.3769 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3870, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 564, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.146 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.1457364410161972, nan, nan]
loss for labeled data =>  tensor(2.1777, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0375, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 130, Time: 1:49:52
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 13/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 70

**pseudo_label ->  [0.0703, 0.1988, 0.1557, 0.1582, 0.0005, 0.2021, 0.2145] **
max =  0.2145 | max_idx =  6
**pseudo_label ->  [0.0692, 0.1744, 0.1589, 0.1423, 0.0003, 0.1791, 0.2758] **
max =  0.2758 | max_idx =  6
**pseudo_label ->  [0.0451, 0.2168, 0.1962, 0.1351, 0.0003, 0.1922, 0.2143] **
max =  0.2168 | max_idx =  1
**pseudo_label ->  [0.0561, 0.1654, 0.2194, 0.1205, 0.0002, 0.1723, 0.2661] **
max =  0.2661 | max_idx =  6
**pseudo_label ->  [0.061, 0.1445, 0.235, 0.1296, 0.0004, 0.2241, 0.2054] **
max =  0.235 | max_idx =  2
**pseudo_label ->  [0.078, 0.2004, 0.1251, 0.1318, 0.0004, 0.1564, 0.3078] **
max =  0.3078 | max_idx =  6
**pseudo_label ->  [0.0847, 0.1449, 0.2319, 0.1229, 0.0004, 0.2479, 0.1672] **
max =  0.2479 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3662, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [646, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.176 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.17640633881092072, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8070, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.4455, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 140, Time: 1:58:21
Train F1: 0.0357, Val F1: 0.0239, Test F1: 0.0206
Epoch 14/20, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0003, 0.2315, 0.1836, 0.1822, 0.0, 0.1605, 0.2419] **
max =  0.2419 | max_idx =  6
**pseudo_label ->  [0.0003, 0.2597, 0.1646, 0.203, 0.0, 0.2071, 0.1654] **
max =  0.2597 | max_idx =  1
**pseudo_label ->  [0.0002, 0.2715, 0.1985, 0.1858, 0.0, 0.1345, 0.2096] **
max =  0.2715 | max_idx =  1
**pseudo_label ->  [0.0002, 0.1848, 0.1821, 0.1772, 0.0, 0.2588, 0.1969] **
max =  0.2588 | max_idx =  5
**pseudo_label ->  [0.0002, 0.1915, 0.1863, 0.1755, 0.0, 0.1817, 0.2648] **
max =  0.2648 | max_idx =  6
**pseudo_label ->  [0.0001, 0.2371, 0.1936, 0.1668, 0.0, 0.1218, 0.2806] **
max =  0.2806 | max_idx =  6
**pseudo_label ->  [0.0003, 0.1966, 0.2959, 0.1374, 0.0, 0.1747, 0.1951] **
max =  0.2959 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 3797, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 410, 0]
psl_acc(PSL 평가에서의 정확도):  0.108 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, 0.10797998309135437, nan]
loss for labeled data =>  tensor(4.3336, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7663, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 150, Time: 2:06:49
Train F1: 0.0357, Val F1: 0.0073, Test F1: 0.0654
Epoch 15/20, Train Acc: 0.1429, Val Acc: 0.0261, Test Acc: 0.2971, Test F1(macro): 0.0654, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0, 0.238, 0.2748, 0.2664, 0.0064, 0.0004, 0.214] **
max =  0.2748 | max_idx =  2
**pseudo_label ->  [0.0, 0.2462, 0.1964, 0.2527, 0.0051, 0.0003, 0.2993] **
max =  0.2993 | max_idx =  6
**pseudo_label ->  [0.0, 0.2703, 0.2222, 0.2263, 0.003, 0.0007, 0.2776] **
max =  0.2776 | max_idx =  6
**pseudo_label ->  [0.0, 0.2378, 0.2753, 0.239, 0.0022, 0.0003, 0.2453] **
max =  0.2753 | max_idx =  2
**pseudo_label ->  [0.0, 0.272, 0.2065, 0.2509, 0.0047, 0.0005, 0.2653] **
max =  0.272 | max_idx =  1
**pseudo_label ->  [0.0, 0.1742, 0.2161, 0.3259, 0.0042, 0.0005, 0.279] **
max =  0.3259 | max_idx =  3
**pseudo_label ->  [0.0, 0.1955, 0.2863, 0.266, 0.0029, 0.0004, 0.249] **
max =  0.2863 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3822, 0, 0]
