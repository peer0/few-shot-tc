current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code
Data set -> jointmatch
save_name: 5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[45]_{'jointmatch'}

data_path:  ../data/jointmatch/python

There are 2 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base']
**tokenizer type =  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base'] 

n_labeled_per_class:  5
train_df samples: 3974
train_labeled_df samples: 35
train_unlabeled_df samples: 3939
Check n_smaples_per_class in the original training set:  {3: 707, 1: 704, 4: 585, 5: 580, 2: 514, 7: 458, 6: 426}
Check n_smaples_per_class in the labeled training set:  {6: 5, 1: 5, 4: 5, 2: 5, 3: 5, 5: 5, 7: 5}
Check n_smaples_per_class in the unlabeled training set:  {3: 702, 1: 699, 4: 580, 5: 575, 2: 509, 7: 453, 6: 421}
n_classes:  7

net_arch:  microsoft/unixcoder-base 
lr:  0.0004 
lr_linear:  0.001 


net_arch:  microsoft/unixcoder-base 
lr:  0.0002 
lr_linear:  0.001 


acc_train_cw(현재 train의 class별 acc) [0.0, 0.2, 0.2, 0.6, 0.0, 0.4, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(1.9748, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8939, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 1/37, Train Acc: 0.2000, Val Acc: 0.2248, Test Acc: 0.1148, Test F1(macro): 0.0722, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.2556, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0226, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 2/37, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9157, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1989, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 3/37, Train Acc: 0.1143, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 1, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.2, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [4, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [1, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.25 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.25, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.0190, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0809, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 4/37, Train Acc: 0.1714, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [2, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.0 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.0, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.9161, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.5798, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 5/37, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3, 0, 42, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 10, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.222 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.0, nan, 0.2380952388048172, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(5.7054, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(5.2257, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 6/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 52, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 7, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.135 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.13461539149284363, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.2881, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.3099, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 7/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 48, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 7, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.146 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.1458333283662796, nan, nan, nan, nan]
loss for labeled data =>  tensor(4.3456, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8424, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 8/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 70, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 10, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.143 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.1428571492433548, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8950, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.2413, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 9/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 46, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 7, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.152 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.15217390656471252, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.4081, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7709, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 10/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 69, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 9, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.13 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.1304347813129425, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8515, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.1156, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 11/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 3

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 42, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 8, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.19 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.190476194024086, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.4542, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7935, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 12/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 70, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 15, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.214 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.2142857164144516, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7567, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.1533, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 13/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 45, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 7, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.156 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.15555556118488312, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.3137, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7392, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 14/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 64, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 11, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.172 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.171875, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7167, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.1954, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 15/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 3

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 54, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 10, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.185 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.18518517911434174, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.1132, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7791, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 16/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 49, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 6, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.122 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.12244898080825806, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8600, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8115, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 17/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 55, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 7, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.127 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.12727272510528564, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9093, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.2476, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 18/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 51, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 10, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.196 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.19607843458652496, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.1328, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.5800, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 19/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 61, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 16, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.262 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.26229506731033325, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7407, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.1385, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 20/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 52, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 10, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.192 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.19230769574642181, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8819, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7620, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 21/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 4

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 58, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 15, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.259 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.2586206793785095, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7528, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8826, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 22/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 51, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 9, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.176 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.1764705926179886, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.5999, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9031, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 23/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 53, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 4, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.075 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.07547169923782349, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8608, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.9906, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 24/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 54, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 7, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.13 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.12962962687015533, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7059, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7439, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 25/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 2

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 52, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 16, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.308 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.3076923191547394, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.9163, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8269, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 26/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 6, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 46, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 11, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.239 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.239130437374115, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8222, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.7708, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 27/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 52, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 9, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.173 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.17307692766189575, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.0979, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8283, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 28/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 7, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 53, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 11, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.208 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.2075471729040146, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.7980, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.8429, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 29/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 4, Correct Pseudo-Labels: 1

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 23, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 4, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.174 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.17391304671764374, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.6808, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.5632, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 30/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0389, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.2561, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 31/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0588, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0380, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 32/37, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9439, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0237, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 33/37, Train Acc: 0.1429, Val Acc: 0.0261, Test Acc: 0.2971, Test F1(macro): 0.0654, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
Save model to ./experiment/jointmatch/output/
loss for labeled data =>  tensor(1.9956, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9354, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 34/37, Train Acc: 0.1429, Val Acc: 0.3876, Test Acc: 0.1619, Test F1(macro): 0.0398, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0123, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8763, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 35/37, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9965, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0467, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 36/37, Train Acc: 0.1429, Val Acc: 0.3876, Test Acc: 0.1619, Test F1(macro): 0.0398, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0110, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9840, device='cuda:0', grad_fn=<NllLossBackward0>)
Epoch 37/37, Train Acc: 0.1429, Val Acc: 0.0261, Test Acc: 0.2971, Test F1(macro): 0.0654, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0

Training complete!
Total training took 0:42:55 (h:mm:ss)
Load model from ./experiment/jointmatch/output/5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[45]_{'jointmatch'}_net0.pth
Load model from ./experiment/jointmatch/output/5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[45]_{'jointmatch'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/unixcoder/joint_match//5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_37_[45]_{'jointmatch'}/training_statistics.csv


Best_step:  33 
Best_val_epoch:  34 
best_val_acc:  0.38762214983713356 
best_val_test_acc:  0.16188524590163936 
best_val_test_f1:  0.0398085159989922
Save best record in:  ./experiment/jointmatch/log/unixcoder/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
