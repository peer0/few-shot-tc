current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code

bs =>  7
Data set -> jointmatch
save_name: 5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[45]_{'python'}

data_path:  ../data/jointmatch/python

There are 1 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base']
**tokenizer type =  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base'] 

n_labeled_per_class:  5
train_df samples: 3974
train_labeled_df samples: 35
train_unlabeled_df samples: 3939
Check n_smaples_per_class in the original training set:  OrderedDict([(1, 704), (2, 514), (3, 707), (4, 585), (5, 580), (6, 426), (7, 458)])
Check n_smaples_per_class in the labeled training set:  OrderedDict([(1, 5), (2, 5), (3, 5), (4, 5), (5, 5), (6, 5), (7, 5)])
Check n_smaples_per_class in the unlabeled training set:  OrderedDict([(1, 699), (2, 509), (3, 702), (4, 580), (5, 575), (6, 421), (7, 453)])
n_classes:  7

net_arch:  microsoft/unixcoder-base 
lr:  0.0004 
lr_linear:  0.001 


net_arch:  microsoft/unixcoder-base 
lr:  0.0002 
lr_linear:  0.001 

**pseudo_label ->  [0.2915, 0.1564, 0.0923, 0.1313, 0.1181, 0.0947, 0.1157] **
max =  0.2915 | max_idx =  0
**pseudo_label ->  [0.2298, 0.1912, 0.1043, 0.1074, 0.1718, 0.0967, 0.0987] **
max =  0.2298 | max_idx =  0
**pseudo_label ->  [0.2359, 0.2307, 0.112, 0.0916, 0.1426, 0.089, 0.0982] **
max =  0.2359 | max_idx =  0
**pseudo_label ->  [0.285, 0.1451, 0.09, 0.1082, 0.1349, 0.104, 0.1329] **
max =  0.285 | max_idx =  0
**pseudo_label ->  [0.2002, 0.1258, 0.1224, 0.122, 0.1649, 0.1365, 0.1283] **
max =  0.2002 | max_idx =  0
**pseudo_label ->  [0.2156, 0.1489, 0.1337, 0.0945, 0.1759, 0.132, 0.0993] **
max =  0.2156 | max_idx =  0
**pseudo_label ->  [0.1906, 0.2191, 0.1301, 0.1095, 0.1303, 0.1009, 0.1195] **
max =  0.2191 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 2773, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 289, 0]
psl_acc(PSL 평가에서의 정확도):  0.104 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, 0.10421925783157349, nan]
loss for labeled data =>  tensor(2.0337, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9151, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 5, Time: 0:08:00
Train F1: 0.0357, Val F1: 0.0073, Test F1: 0.0654
Epoch 1/20, Train Acc: 0.1429, Val Acc: 0.0261, Test Acc: 0.2971, Test F1(macro): 0.0654, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 35

**pseudo_label ->  [0.5562, 0.1401, 0.047, 0.0215, 0.1022, 0.0062, 0.1267] **
max =  0.5562 | max_idx =  0
**pseudo_label ->  [0.4052, 0.2042, 0.0775, 0.0324, 0.104, 0.0105, 0.1663] **
max =  0.4052 | max_idx =  0
**pseudo_label ->  [0.4707, 0.1883, 0.0537, 0.0303, 0.1449, 0.0064, 0.1057] **
max =  0.4707 | max_idx =  0
**pseudo_label ->  [0.4669, 0.1857, 0.0671, 0.0371, 0.121, 0.0084, 0.1139] **
max =  0.4669 | max_idx =  0
**pseudo_label ->  [0.6996, 0.0736, 0.0244, 0.0218, 0.0526, 0.0044, 0.1234] **
max =  0.6996 | max_idx =  0
**pseudo_label ->  [0.7042, 0.0577, 0.0213, 0.0265, 0.0717, 0.0059, 0.1128] **
max =  0.7042 | max_idx =  0
**pseudo_label ->  [0.708, 0.0528, 0.0179, 0.0261, 0.0475, 0.0058, 0.1419] **
max =  0.708 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3934, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [699, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.178 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.17768174409866333, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.0069, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0716, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 10, Time: 0:16:10
Train F1: 0.0357, Val F1: 0.0239, Test F1: 0.0206
Epoch 2/20, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 35

**pseudo_label ->  [0.0024, 0.217, 0.0879, 0.1477, 0.2212, 0.0824, 0.2414] **
max =  0.2414 | max_idx =  6
**pseudo_label ->  [0.0028, 0.2515, 0.0591, 0.1545, 0.2716, 0.0881, 0.1724] **
max =  0.2716 | max_idx =  4
**pseudo_label ->  [0.0032, 0.2617, 0.0429, 0.1366, 0.2097, 0.0877, 0.2582] **
max =  0.2617 | max_idx =  1
**pseudo_label ->  [0.0024, 0.2541, 0.0525, 0.1233, 0.2573, 0.0953, 0.215] **
max =  0.2573 | max_idx =  4
**pseudo_label ->  [0.0032, 0.2834, 0.0521, 0.1502, 0.1874, 0.1177, 0.2061] **
max =  0.2834 | max_idx =  1
**pseudo_label ->  [0.0027, 0.2034, 0.0532, 0.1613, 0.2407, 0.1016, 0.2371] **
max =  0.2407 | max_idx =  4
**pseudo_label ->  [0.0026, 0.2449, 0.0445, 0.1829, 0.2189, 0.0975, 0.2087] **
max =  0.2449 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 3905]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 448]
psl_acc(PSL 평가에서의 정확도):  0.115 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.11472471058368683]
loss for labeled data =>  tensor(2.8784, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.6032, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 15, Time: 0:23:48
Train F1: 0.0357, Val F1: 0.0300, Test F1: 0.0052
Epoch 3/20, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 35

**pseudo_label ->  [0.8992, 0.0037, 0.0567, 0.0013, 0.0048, 0.0226, 0.0117] **
max =  0.8992 | max_idx =  0
**pseudo_label ->  [0.8867, 0.0043, 0.06, 0.0017, 0.0087, 0.0234, 0.0153] **
max =  0.8867 | max_idx =  0
**pseudo_label ->  [0.8381, 0.0054, 0.0907, 0.0014, 0.0092, 0.0296, 0.0256] **
max =  0.8381 | max_idx =  0
**pseudo_label ->  [0.8993, 0.003, 0.0588, 0.001, 0.004, 0.02, 0.0138] **
max =  0.8993 | max_idx =  0
**pseudo_label ->  [0.8831, 0.0024, 0.0622, 0.002, 0.0069, 0.0283, 0.015] **
max =  0.8831 | max_idx =  0
**pseudo_label ->  [0.8632, 0.0038, 0.0764, 0.0023, 0.0048, 0.0315, 0.0181] **
max =  0.8632 | max_idx =  0
**pseudo_label ->  [0.8924, 0.0035, 0.0552, 0.0015, 0.0071, 0.0237, 0.0167] **
max =  0.8924 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3932, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [699, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.178 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.17777211964130402, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.1128, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.7897, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 20, Time: 0:31:29
Train F1: 0.0357, Val F1: 0.0239, Test F1: 0.0206
Epoch 4/20, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 35

**pseudo_label ->  [0.0397, 0.2216, 0.1512, 0.2278, 0.2456, 0.1123, 0.0019] **
max =  0.2456 | max_idx =  4
**pseudo_label ->  [0.0262, 0.2344, 0.1346, 0.2038, 0.3262, 0.0733, 0.0015] **
max =  0.3262 | max_idx =  4
**pseudo_label ->  [0.0466, 0.2363, 0.1053, 0.2522, 0.2711, 0.0858, 0.0027] **
max =  0.2711 | max_idx =  4
**pseudo_label ->  [0.0552, 0.2365, 0.1855, 0.1549, 0.2674, 0.098, 0.0026] **
max =  0.2674 | max_idx =  4
**pseudo_label ->  [0.0513, 0.2063, 0.1642, 0.2002, 0.2233, 0.1525, 0.0024] **
max =  0.2233 | max_idx =  4
**pseudo_label ->  [0.026, 0.3577, 0.1392, 0.1099, 0.2914, 0.0735, 0.0024] **
max =  0.3577 | max_idx =  1
**pseudo_label ->  [0.0413, 0.2153, 0.1684, 0.2532, 0.2226, 0.0969, 0.0024] **
max =  0.2532 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3743, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 672, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.18 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.1795351356267929, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.5221, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.6923, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 25, Time: 0:39:19
Train F1: 0.0357, Val F1: 0.0531, Test F1: 0.0313
Epoch 5/20, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 35

**pseudo_label ->  [0.0, 0.2932, 0.049, 0.1945, 0.2636, 0.1949, 0.0046] **
max =  0.2932 | max_idx =  1
**pseudo_label ->  [0.0, 0.3559, 0.0403, 0.1372, 0.2177, 0.2446, 0.0042] **
max =  0.3559 | max_idx =  1
**pseudo_label ->  [0.0, 0.2794, 0.055, 0.1825, 0.2233, 0.255, 0.0048] **
max =  0.2794 | max_idx =  1
**pseudo_label ->  [0.0, 0.2909, 0.0517, 0.1301, 0.3244, 0.199, 0.0039] **
max =  0.3244 | max_idx =  4
**pseudo_label ->  [0.0, 0.3674, 0.0513, 0.1921, 0.1917, 0.1941, 0.0034] **
max =  0.3674 | max_idx =  1
**pseudo_label ->  [0.0, 0.3173, 0.0514, 0.2219, 0.2223, 0.1818, 0.0054] **
max =  0.3173 | max_idx =  1
**pseudo_label ->  [0.0, 0.2139, 0.0904, 0.1334, 0.2206, 0.3383, 0.0034] **
max =  0.3383 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 3478, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 513, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.147 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.14749856293201447, nan, nan, nan]
loss for labeled data =>  tensor(4.0925, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.0821, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 30, Time: 0:47:32
Train F1: 0.0357, Val F1: 0.0798, Test F1: 0.0398
Epoch 6/20, Train Acc: 0.1429, Val Acc: 0.3876, Test Acc: 0.1619, Test F1(macro): 0.0398, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 35

**pseudo_label ->  [0.0, 0.2159, 0.0, 0.0397, 0.0233, 0.6884, 0.0327] **
max =  0.6884 | max_idx =  5
**pseudo_label ->  [0.0, 0.3235, 0.0, 0.0737, 0.0435, 0.5363, 0.0231] **
max =  0.5363 | max_idx =  5
**pseudo_label ->  [0.0, 0.3065, 0.0, 0.0672, 0.0482, 0.5314, 0.0467] **
max =  0.5314 | max_idx =  5
**pseudo_label ->  [0.0, 0.2214, 0.0, 0.0747, 0.0292, 0.6501, 0.0246] **
max =  0.6501 | max_idx =  5
**pseudo_label ->  [0.0, 0.3089, 0.0, 0.0593, 0.0341, 0.5411, 0.0566] **
max =  0.5411 | max_idx =  5
**pseudo_label ->  [0.0, 0.2416, 0.0, 0.0653, 0.0434, 0.592, 0.0577] **
max =  0.592 | max_idx =  5
**pseudo_label ->  [0.0, 0.2637, 0.0, 0.07, 0.0386, 0.5895, 0.0383] **
max =  0.5895 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 3894]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 446]
psl_acc(PSL 평가에서의 정확도):  0.115 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.11453518271446228]
loss for labeled data =>  tensor(6.9119, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.2092, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 35, Time: 0:55:04
Train F1: 0.0357, Val F1: 0.0300, Test F1: 0.0052
Epoch 7/20, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 35

**pseudo_label ->  [0.1281, 0.297, 0.0041, 0.0005, 0.22, 0.2668, 0.0835] **
max =  0.297 | max_idx =  1
**pseudo_label ->  [0.1152, 0.2729, 0.0032, 0.0004, 0.3225, 0.252, 0.0338] **
max =  0.3225 | max_idx =  4
**pseudo_label ->  [0.214, 0.2226, 0.0049, 0.0003, 0.2342, 0.2676, 0.0565] **
max =  0.2676 | max_idx =  5
**pseudo_label ->  [0.1417, 0.2875, 0.0041, 0.0004, 0.1884, 0.3196, 0.0584] **
max =  0.3196 | max_idx =  5
**pseudo_label ->  [0.1981, 0.2196, 0.0048, 0.0004, 0.2138, 0.2944, 0.0689] **
max =  0.2944 | max_idx =  5
**pseudo_label ->  [0.1232, 0.3508, 0.007, 0.0008, 0.2066, 0.2797, 0.032] **
max =  0.3508 | max_idx =  1
**pseudo_label ->  [0.2594, 0.1769, 0.0099, 0.0011, 0.2159, 0.2726, 0.0641] **
max =  0.2726 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [3855, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [683, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.177 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [0.1771724969148636, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.6623, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.1925, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 40, Time: 1:02:58
Train F1: 0.0357, Val F1: 0.0239, Test F1: 0.0206
Epoch 8/20, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 35

**pseudo_label ->  [0.1631, 0.1163, 0.1801, 0.0704, 0.4654, 0.0014, 0.0033] **
max =  0.4654 | max_idx =  4
**pseudo_label ->  [0.1114, 0.1111, 0.1278, 0.0741, 0.5708, 0.0015, 0.0033] **
max =  0.5708 | max_idx =  4
**pseudo_label ->  [0.1425, 0.1225, 0.1729, 0.0842, 0.4742, 0.0017, 0.002] **
max =  0.4742 | max_idx =  4
**pseudo_label ->  [0.1254, 0.112, 0.1606, 0.066, 0.5324, 0.0015, 0.0021] **
max =  0.5324 | max_idx =  4
**pseudo_label ->  [0.1344, 0.0885, 0.1208, 0.0542, 0.5969, 0.0015, 0.0036] **
max =  0.5969 | max_idx =  4
**pseudo_label ->  [0.1551, 0.1197, 0.1814, 0.1116, 0.4293, 0.0016, 0.0013] **
max =  0.4293 | max_idx =  4
**pseudo_label ->  [0.1693, 0.1275, 0.2192, 0.0914, 0.3892, 0.0015, 0.0019] **
max =  0.3892 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 3885, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 502, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.129 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.12921492755413055, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.6764, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.5714, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 45, Time: 1:10:51
Train F1: 0.0357, Val F1: 0.0018, Test F1: 0.0623
Epoch 9/20, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 2, Train Data Number: 35

**pseudo_label ->  [0.0, 0.0839, 0.1532, 0.2193, 0.0028, 0.535, 0.0057] **
max =  0.535 | max_idx =  5
**pseudo_label ->  [0.0, 0.0937, 0.2008, 0.1323, 0.0025, 0.5643, 0.0063] **
max =  0.5643 | max_idx =  5
**pseudo_label ->  [0.0, 0.129, 0.1664, 0.1258, 0.0029, 0.5704, 0.0055] **
max =  0.5704 | max_idx =  5
**pseudo_label ->  [0.0, 0.1362, 0.1383, 0.1393, 0.0033, 0.5752, 0.0078] **
max =  0.5752 | max_idx =  5
**pseudo_label ->  [0.0, 0.1164, 0.1967, 0.1997, 0.0033, 0.4753, 0.0086] **
max =  0.4753 | max_idx =  5
**pseudo_label ->  [0.0, 0.1951, 0.1361, 0.1591, 0.0036, 0.4981, 0.008] **
max =  0.4981 | max_idx =  5
**pseudo_label ->  [0.0, 0.1129, 0.1971, 0.1964, 0.0032, 0.4857, 0.0047] **
max =  0.4857 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 3899]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 447]
psl_acc(PSL 평가에서의 정확도):  0.115 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.11464478075504303]
loss for labeled data =>  tensor(4.9743, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1812, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 50, Time: 1:18:45
Train F1: 0.0357, Val F1: 0.0300, Test F1: 0.0052
Epoch 10/20, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 35

**pseudo_label ->  [0.0, 0.0, 0.0, 0.0, 0.0111, 0.0, 0.9889] **
max =  0.9889 | max_idx =  6
**pseudo_label ->  [0.0, 0.0, 0.0, 0.0001, 0.008, 0.0, 0.9919] **
max =  0.9919 | max_idx =  6
**pseudo_label ->  [0.0, 0.0, 0.0, 0.0, 0.0088, 0.0, 0.9912] **
max =  0.9912 | max_idx =  6
**pseudo_label ->  [0.0, 0.0, 0.0, 0.0001, 0.0116, 0.0, 0.9883] **
max =  0.9883 | max_idx =  6
**pseudo_label ->  [0.0, 0.0, 0.0, 0.0, 0.0087, 0.0, 0.9912] **
max =  0.9912 | max_idx =  6
**pseudo_label ->  [0.0, 0.0, 0.0, 0.0001, 0.0059, 0.0, 0.994] **
max =  0.994 | max_idx =  6
**pseudo_label ->  [0.0, 0.0, 0.0, 0.0001, 0.0079, 0.0, 0.992] **
max =  0.992 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 3904, 0, 0, 20]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 573, 0, 0, 1]
psl_acc(PSL 평가에서의 정확도):  0.146 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.14677253365516663, nan, nan, 0.05000000074505806]
loss for labeled data =>  tensor(14.1648, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.0948, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 55, Time: 1:26:31
Train F1: 0.0357, Val F1: 0.0798, Test F1: 0.0398
Epoch 11/20, Train Acc: 0.1429, Val Acc: 0.3876, Test Acc: 0.1619, Test F1(macro): 0.0398, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 35

**pseudo_label ->  [0.3785, 0.0961, 0.0397, 0.0581, 0.1676, 0.0931, 0.1669] **
max =  0.3785 | max_idx =  0
**pseudo_label ->  [0.1935, 0.1224, 0.0334, 0.0519, 0.3959, 0.0986, 0.1043] **
max =  0.3959 | max_idx =  4
**pseudo_label ->  [0.3104, 0.0741, 0.1068, 0.0765, 0.2641, 0.0773, 0.0908] **
max =  0.3104 | max_idx =  0
**pseudo_label ->  [0.4824, 0.1026, 0.0498, 0.044, 0.1065, 0.0991, 0.1157] **
max =  0.4824 | max_idx =  0
**pseudo_label ->  [0.3118, 0.1077, 0.047, 0.0508, 0.2372, 0.1105, 0.135] **
max =  0.3118 | max_idx =  0
**pseudo_label ->  [0.4233, 0.1614, 0.0356, 0.0387, 0.1387, 0.0769, 0.1254] **
max =  0.4233 | max_idx =  0
**pseudo_label ->  [0.4244, 0.055, 0.057, 0.0446, 0.1973, 0.0991, 0.1226] **
max =  0.4244 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 3913, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 574, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.147 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.1466905176639557, nan, nan, nan]
loss for labeled data =>  tensor(2.5637, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(6.7132, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 60, Time: 1:34:14
Train F1: 0.0357, Val F1: 0.0798, Test F1: 0.0398
Epoch 12/20, Train Acc: 0.1429, Val Acc: 0.3876, Test Acc: 0.1619, Test F1(macro): 0.0398, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 35

**pseudo_label ->  [0.0011, 0.0001, 0.0414, 0.8195, 0.0064, 0.1104, 0.0211] **
max =  0.8195 | max_idx =  3
**pseudo_label ->  [0.0014, 0.0001, 0.045, 0.7931, 0.0045, 0.1301, 0.0259] **
max =  0.7931 | max_idx =  3
**pseudo_label ->  [0.0013, 0.0, 0.0621, 0.8377, 0.0036, 0.0775, 0.0178] **
max =  0.8377 | max_idx =  3
**pseudo_label ->  [0.0014, 0.0001, 0.0391, 0.8159, 0.0047, 0.1128, 0.026] **
max =  0.8159 | max_idx =  3
**pseudo_label ->  [0.0016, 0.0001, 0.0344, 0.7902, 0.0076, 0.1434, 0.0227] **
max =  0.7902 | max_idx =  3
**pseudo_label ->  [0.0005, 0.0001, 0.0419, 0.8336, 0.0062, 0.1002, 0.0175] **
max =  0.8336 | max_idx =  3
**pseudo_label ->  [0.0016, 0.0001, 0.061, 0.7503, 0.0082, 0.1556, 0.0233] **
max =  0.7503 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 7, 3818, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 1, 564, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.148 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.1428571492433548, 0.1477213203907013, nan, nan]
loss for labeled data =>  tensor(6.3217, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.6619, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 65, Time: 1:41:42
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 13/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 2, Train Data Number: 35

**pseudo_label ->  [0.1644, 0.0038, 0.3908, 0.0001, 0.129, 0.2488, 0.0631] **
max =  0.3908 | max_idx =  2
**pseudo_label ->  [0.1809, 0.002, 0.4904, 0.0, 0.0911, 0.1787, 0.0568] **
max =  0.4904 | max_idx =  2
**pseudo_label ->  [0.15, 0.0012, 0.3697, 0.0, 0.1392, 0.2631, 0.0767] **
max =  0.3697 | max_idx =  2
**pseudo_label ->  [0.1384, 0.0034, 0.4558, 0.0001, 0.1321, 0.2252, 0.0449] **
max =  0.4558 | max_idx =  2
**pseudo_label ->  [0.2038, 0.0036, 0.3765, 0.0, 0.089, 0.2473, 0.0798] **
max =  0.3765 | max_idx =  2
**pseudo_label ->  [0.1739, 0.0016, 0.4143, 0.0, 0.0827, 0.2447, 0.0828] **
max =  0.4143 | max_idx =  2
**pseudo_label ->  [0.1416, 0.0019, 0.5763, 0.0, 0.0665, 0.1571, 0.0566] **
max =  0.5763 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3904, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 564, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.144 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.14446721971035004, nan, nan]
loss for labeled data =>  tensor(3.9454, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(6.3641, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 70, Time: 1:49:38
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 14/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 35

**pseudo_label ->  [0.0049, 0.0024, 0.3469, 0.461, 0.1711, 0.0122, 0.0015] **
max =  0.461 | max_idx =  3
**pseudo_label ->  [0.0041, 0.003, 0.3424, 0.4618, 0.1767, 0.0107, 0.0013] **
max =  0.4618 | max_idx =  3
**pseudo_label ->  [0.0039, 0.0029, 0.3522, 0.4937, 0.1335, 0.0123, 0.0015] **
max =  0.4937 | max_idx =  3
**pseudo_label ->  [0.0057, 0.0036, 0.3931, 0.4711, 0.1116, 0.0134, 0.0016] **
max =  0.4711 | max_idx =  3
**pseudo_label ->  [0.005, 0.0028, 0.4677, 0.3255, 0.183, 0.0146, 0.0014] **
max =  0.4677 | max_idx =  2
**pseudo_label ->  [0.0037, 0.0025, 0.3144, 0.5218, 0.1415, 0.0143, 0.0018] **
max =  0.5218 | max_idx =  3
**pseudo_label ->  [0.0073, 0.0042, 0.4162, 0.3797, 0.1744, 0.0161, 0.0021] **
max =  0.4162 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(4.2235, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(5.6859, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 75, Time: 1:57:24
Train F1: 0.0357, Val F1: 0.0018, Test F1: 0.0623
Epoch 15/20, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 35

**pseudo_label ->  [0.1956, 0.0948, 0.0036, 0.0283, 0.2408, 0.2022, 0.2348] **
max =  0.2408 | max_idx =  4
**pseudo_label ->  [0.1732, 0.249, 0.0047, 0.0301, 0.159, 0.1492, 0.2348] **
max =  0.249 | max_idx =  1
**pseudo_label ->  [0.188, 0.135, 0.0027, 0.0309, 0.2157, 0.1665, 0.2613] **
max =  0.2613 | max_idx =  6
**pseudo_label ->  [0.2508, 0.1799, 0.0047, 0.0234, 0.1633, 0.1917, 0.1862] **
max =  0.2508 | max_idx =  0
**pseudo_label ->  [0.1691, 0.1424, 0.0035, 0.0316, 0.2422, 0.2227, 0.1885] **
max =  0.2422 | max_idx =  4
**pseudo_label ->  [0.1413, 0.1508, 0.0024, 0.0146, 0.2647, 0.1896, 0.2366] **
max =  0.2647 | max_idx =  4
**pseudo_label ->  [0.3267, 0.1254, 0.0051, 0.0303, 0.093, 0.175, 0.2445] **
max =  0.3267 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3846, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 683, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.178 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.1775871068239212, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8051, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.4790, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 80, Time: 2:04:56
Train F1: 0.0357, Val F1: 0.0531, Test F1: 0.0313
Epoch 16/20, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 35

**pseudo_label ->  [0.2716, 0.2081, 0.0153, 0.0365, 0.2428, 0.0889, 0.1369] **
max =  0.2716 | max_idx =  0
**pseudo_label ->  [0.2141, 0.2963, 0.0101, 0.0198, 0.2302, 0.0713, 0.1582] **
max =  0.2963 | max_idx =  1
**pseudo_label ->  [0.2418, 0.2272, 0.0168, 0.0333, 0.2052, 0.1232, 0.1525] **
max =  0.2418 | max_idx =  0
**pseudo_label ->  [0.2361, 0.1778, 0.0137, 0.0314, 0.2285, 0.09, 0.2225] **
max =  0.2361 | max_idx =  0
**pseudo_label ->  [0.2678, 0.1543, 0.01, 0.0283, 0.3073, 0.0737, 0.1585] **
max =  0.3073 | max_idx =  4
**pseudo_label ->  [0.2483, 0.1621, 0.0136, 0.0299, 0.3693, 0.0914, 0.0854] **
max =  0.3693 | max_idx =  4
**pseudo_label ->  [0.235, 0.2266, 0.0105, 0.0213, 0.31, 0.0786, 0.118] **
max =  0.31 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 3814, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 408, 0]
psl_acc(PSL 평가에서의 정확도):  0.107 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, 0.10697430372238159, nan]
loss for labeled data =>  tensor(2.5777, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.3545, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 85, Time: 2:12:52
Train F1: 0.0357, Val F1: 0.0073, Test F1: 0.0654
Epoch 17/20, Train Acc: 0.1429, Val Acc: 0.0261, Test Acc: 0.2971, Test F1(macro): 0.0654, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 35

**pseudo_label ->  [0.2801, 0.002, 0.0016, 0.1953, 0.0032, 0.1542, 0.3637] **
max =  0.3637 | max_idx =  6
**pseudo_label ->  [0.3475, 0.0013, 0.0016, 0.1772, 0.0021, 0.1274, 0.3428] **
max =  0.3475 | max_idx =  0
**pseudo_label ->  [0.2894, 0.002, 0.0014, 0.2247, 0.002, 0.1307, 0.3498] **
max =  0.3498 | max_idx =  6
**pseudo_label ->  [0.4446, 0.0017, 0.0023, 0.2114, 0.0009, 0.1141, 0.225] **
max =  0.4446 | max_idx =  0
**pseudo_label ->  [0.423, 0.0024, 0.0011, 0.1592, 0.0012, 0.124, 0.2892] **
max =  0.423 | max_idx =  0
**pseudo_label ->  [0.3078, 0.002, 0.0016, 0.2156, 0.0018, 0.1226, 0.3485] **
max =  0.3485 | max_idx =  6
**pseudo_label ->  [0.2819, 0.0015, 0.002, 0.3183, 0.0018, 0.0783, 0.3162] **
max =  0.3183 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 3844, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 503, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.131 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.13085328042507172, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.8343, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(5.4857, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 90, Time: 2:20:31
Train F1: 0.0357, Val F1: 0.0018, Test F1: 0.0623
Epoch 18/20, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 35

**pseudo_label ->  [0.142, 0.1545, 0.0633, 0.338, 0.1078, 0.0002, 0.1942] **
max =  0.338 | max_idx =  3
**pseudo_label ->  [0.1734, 0.1426, 0.0982, 0.3047, 0.1097, 0.0002, 0.1712] **
max =  0.3047 | max_idx =  3
**pseudo_label ->  [0.2446, 0.1577, 0.0771, 0.2225, 0.1135, 0.0003, 0.1843] **
max =  0.2446 | max_idx =  0
**pseudo_label ->  [0.1522, 0.1389, 0.0792, 0.3962, 0.09, 0.0002, 0.1435] **
max =  0.3962 | max_idx =  3
**pseudo_label ->  [0.2037, 0.159, 0.1226, 0.3258, 0.0892, 0.0002, 0.0995] **
max =  0.3258 | max_idx =  3
**pseudo_label ->  [0.2468, 0.1333, 0.0822, 0.3312, 0.0873, 0.0002, 0.119] **
max =  0.3312 | max_idx =  3
**pseudo_label ->  [0.1686, 0.1193, 0.0738, 0.1905, 0.1783, 0.0003, 0.2692] **
max =  0.2692 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3783, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 556, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.147 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.14697329699993134, nan, nan]
loss for labeled data =>  tensor(3.2681, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(7.6247, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 95, Time: 2:28:25
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 19/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 35

**pseudo_label ->  [0.0547, 0.0, 0.1217, 0.113, 0.6541, 0.0015, 0.0549] **
max =  0.6541 | max_idx =  4
**pseudo_label ->  [0.047, 0.0, 0.1215, 0.1212, 0.6508, 0.0015, 0.058] **
max =  0.6508 | max_idx =  4
**pseudo_label ->  [0.0435, 0.0, 0.1599, 0.165, 0.5667, 0.0016, 0.0634] **
max =  0.5667 | max_idx =  4
**pseudo_label ->  [0.0474, 0.0, 0.1363, 0.1215, 0.6436, 0.0017, 0.0495] **
max =  0.6436 | max_idx =  4
**pseudo_label ->  [0.041, 0.0, 0.123, 0.0849, 0.6985, 0.0013, 0.0513] **
max =  0.6985 | max_idx =  4
**pseudo_label ->  [0.0348, 0.0, 0.1238, 0.1045, 0.6857, 0.0014, 0.0499] **
max =  0.6857 | max_idx =  4
**pseudo_label ->  [0.0325, 0.0, 0.0896, 0.094, 0.7251, 0.0018, 0.057] **
max =  0.7251 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 1, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.0 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.0, nan, nan]
loss for labeled data =>  tensor(5.5141, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.4833, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 100, Time: 2:35:50
Train F1: 0.0357, Val F1: 0.0300, Test F1: 0.0052
Epoch 20/20, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 35


Training complete!
Total training took 2:35:50 (h:mm:ss)
Load model from ./experiment/jointmatch/output/5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[45]_{'python'}_net0.pth
Load model from ./experiment/jointmatch/output/5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[45]_{'python'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/unixcoder/joint_match//5_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[45]_{'python'}/training_statistics.csv


Best_step:  30 
Best_val_epoch:  6 
best_val_acc:  0.38762214983713356 
best_val_test_acc:  0.16188524590163936 
best_val_test_f1:  0.0398085159989922
Save best record in:  ./experiment/jointmatch/log/unixcoder/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
