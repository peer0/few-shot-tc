current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code

bs =>  7
Data set -> jointmatch
save_name: 10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_20_[43]_{'python'}

data_path:  ../data/jointmatch/python

There are 1 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding']
**tokenizer type =  ['Salesforce/codet5p-110m-embedding', 'Salesforce/codet5p-110m-embedding'] 

n_labeled_per_class:  10
train_df samples: 3974
train_labeled_df samples: 70
train_unlabeled_df samples: 3904
Check n_smaples_per_class in the original training set:  OrderedDict([(1, 704), (2, 514), (3, 707), (4, 585), (5, 580), (6, 426), (7, 458)])
Check n_smaples_per_class in the labeled training set:  OrderedDict([(1, 10), (2, 10), (3, 10), (4, 10), (5, 10), (6, 10), (7, 10)])
Check n_smaples_per_class in the unlabeled training set:  OrderedDict([(1, 694), (2, 504), (3, 697), (4, 575), (5, 570), (6, 416), (7, 448)])
n_classes:  7

net_arch:  Salesforce/codet5p-110m-embedding 
lr:  0.0003 
lr_linear:  0.001 


net_arch:  Salesforce/codet5p-110m-embedding 
lr:  0.00025 
lr_linear:  0.001 

**pseudo_label ->  [0.1513, 0.1414, 0.1357, 0.1889, 0.1327, 0.1274, 0.1227] **
max =  0.1889 | max_idx =  3
**pseudo_label ->  [0.1809, 0.1593, 0.1344, 0.149, 0.1304, 0.1222, 0.1238] **
max =  0.1809 | max_idx =  0
**pseudo_label ->  [0.1863, 0.171, 0.1454, 0.1308, 0.1254, 0.1245, 0.1166] **
max =  0.1863 | max_idx =  0
**pseudo_label ->  [0.1245, 0.1666, 0.1504, 0.1219, 0.1354, 0.1585, 0.1427] **
max =  0.1666 | max_idx =  1
**pseudo_label ->  [0.1419, 0.1729, 0.153, 0.1225, 0.139, 0.133, 0.1378] **
max =  0.1729 | max_idx =  1
**pseudo_label ->  [0.1352, 0.1819, 0.1502, 0.1232, 0.1351, 0.1408, 0.1336] **
max =  0.1819 | max_idx =  1
**pseudo_label ->  [0.1609, 0.151, 0.1433, 0.1589, 0.1349, 0.1314, 0.1196] **
max =  0.1609 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9070, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9201, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 10, Time: 0:07:34
Train F1: 0.0357, Val F1: 0.0239, Test F1: 0.0207
Epoch 1/20, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0207, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.099, 0.1471, 0.1426, 0.1229, 0.166, 0.1331, 0.1894] **
max =  0.1894 | max_idx =  6
**pseudo_label ->  [0.1035, 0.1591, 0.1466, 0.1149, 0.1647, 0.1391, 0.1721] **
max =  0.1721 | max_idx =  6
**pseudo_label ->  [0.1063, 0.1414, 0.1424, 0.1213, 0.1659, 0.1347, 0.1879] **
max =  0.1879 | max_idx =  6
**pseudo_label ->  [0.0996, 0.1478, 0.147, 0.1195, 0.1708, 0.1366, 0.1787] **
max =  0.1787 | max_idx =  6
**pseudo_label ->  [0.0979, 0.1613, 0.1373, 0.1231, 0.1626, 0.135, 0.1828] **
max =  0.1828 | max_idx =  6
**pseudo_label ->  [0.1096, 0.1991, 0.1281, 0.1164, 0.1369, 0.1398, 0.1701] **
max =  0.1991 | max_idx =  1
**pseudo_label ->  [0.1, 0.185, 0.1307, 0.1238, 0.1392, 0.1339, 0.1874] **
max =  0.1874 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9065, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8523, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 20, Time: 0:15:13
Train F1: 0.1100, Val F1: 0.0709, Test F1: 0.0657
Epoch 2/20, Train Acc: 0.2000, Val Acc: 0.0326, Test Acc: 0.2971, Test F1(macro): 0.0657, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1101, 0.2338, 0.125, 0.1401, 0.1052, 0.1172, 0.1685] **
max =  0.2338 | max_idx =  1
**pseudo_label ->  [0.1469, 0.0852, 0.1603, 0.1468, 0.1991, 0.1407, 0.1209] **
max =  0.1991 | max_idx =  4
**pseudo_label ->  [0.1485, 0.0852, 0.1605, 0.1448, 0.1987, 0.1419, 0.1204] **
max =  0.1987 | max_idx =  4
**pseudo_label ->  [0.1479, 0.0854, 0.1626, 0.1439, 0.1983, 0.1407, 0.1211] **
max =  0.1983 | max_idx =  4
**pseudo_label ->  [0.1521, 0.0852, 0.1598, 0.1454, 0.1976, 0.1398, 0.1201] **
max =  0.1976 | max_idx =  4
**pseudo_label ->  [0.1112, 0.2353, 0.1206, 0.1422, 0.1049, 0.1177, 0.168] **
max =  0.2353 | max_idx =  1
**pseudo_label ->  [0.1113, 0.236, 0.1209, 0.1417, 0.1047, 0.1188, 0.1666] **
max =  0.236 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.8279, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.7982, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 30, Time: 0:23:08
Train F1: 0.0621, Val F1: 0.0239, Test F1: 0.0206
Epoch 3/20, Train Acc: 0.1571, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1209, 0.0747, 0.1514, 0.1651, 0.2181, 0.1414, 0.1283] **
max =  0.2181 | max_idx =  4
**pseudo_label ->  [0.1231, 0.0739, 0.1508, 0.1662, 0.2166, 0.142, 0.1275] **
max =  0.2166 | max_idx =  4
**pseudo_label ->  [0.1606, 0.2566, 0.12, 0.1159, 0.0864, 0.1284, 0.1319] **
max =  0.2566 | max_idx =  1
**pseudo_label ->  [0.1209, 0.0745, 0.1513, 0.1656, 0.2174, 0.1419, 0.1284] **
max =  0.2174 | max_idx =  4
**pseudo_label ->  [0.1208, 0.0744, 0.1514, 0.1667, 0.2168, 0.1406, 0.1293] **
max =  0.2168 | max_idx =  4
**pseudo_label ->  [0.1221, 0.0743, 0.1497, 0.1666, 0.2175, 0.1416, 0.1283] **
max =  0.2175 | max_idx =  4
**pseudo_label ->  [0.1224, 0.0742, 0.1499, 0.1665, 0.2169, 0.1421, 0.128] **
max =  0.2169 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9900, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8066, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 40, Time: 0:28:32
Train F1: 0.1019, Val F1: 0.0683, Test F1: 0.1167
Epoch 4/20, Train Acc: 0.2286, Val Acc: 0.1466, Test Acc: 0.2992, Test F1(macro): 0.1167, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1092, 0.1018, 0.159, 0.1517, 0.1648, 0.1529, 0.1608] **
max =  0.1648 | max_idx =  4
**pseudo_label ->  [0.1077, 0.1041, 0.1591, 0.1549, 0.1602, 0.1499, 0.164] **
max =  0.164 | max_idx =  6
**pseudo_label ->  [0.1095, 0.1021, 0.1597, 0.152, 0.1623, 0.1544, 0.16] **
max =  0.1623 | max_idx =  4
**pseudo_label ->  [0.1098, 0.1013, 0.1587, 0.1526, 0.1627, 0.1534, 0.1615] **
max =  0.1627 | max_idx =  4
**pseudo_label ->  [0.1098, 0.1014, 0.1599, 0.1524, 0.1629, 0.1541, 0.1594] **
max =  0.1629 | max_idx =  4
**pseudo_label ->  [0.1101, 0.1005, 0.1597, 0.1525, 0.1643, 0.1533, 0.1596] **
max =  0.1643 | max_idx =  4
**pseudo_label ->  [0.1102, 0.1007, 0.1594, 0.1518, 0.1638, 0.1548, 0.1593] **
max =  0.1638 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9649, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9818, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 50, Time: 0:33:18
Train F1: 0.0357, Val F1: 0.0073, Test F1: 0.0651
Epoch 5/20, Train Acc: 0.1429, Val Acc: 0.0261, Test Acc: 0.2951, Test F1(macro): 0.0651, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.136, 0.1494, 0.1484, 0.1339, 0.1338, 0.1532, 0.1454] **
max =  0.1532 | max_idx =  5
**pseudo_label ->  [0.1356, 0.1511, 0.1507, 0.1329, 0.1337, 0.1547, 0.1413] **
max =  0.1547 | max_idx =  5
**pseudo_label ->  [0.1369, 0.1474, 0.1468, 0.1382, 0.1324, 0.1512, 0.1471] **
max =  0.1512 | max_idx =  5
**pseudo_label ->  [0.1456, 0.2332, 0.1166, 0.1253, 0.0985, 0.1338, 0.1471] **
max =  0.2332 | max_idx =  1
**pseudo_label ->  [0.135, 0.1487, 0.1479, 0.1356, 0.1347, 0.1522, 0.1459] **
max =  0.1522 | max_idx =  5
**pseudo_label ->  [0.1376, 0.1513, 0.1481, 0.1342, 0.1298, 0.1563, 0.1428] **
max =  0.1563 | max_idx =  5
**pseudo_label ->  [0.1355, 0.1457, 0.1464, 0.1358, 0.1365, 0.1517, 0.1484] **
max =  0.1517 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9410, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9470, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 60, Time: 0:38:00
Train F1: 0.0357, Val F1: 0.0018, Test F1: 0.0623
Epoch 6/20, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1622, 0.0965, 0.1469, 0.1341, 0.2, 0.146, 0.1144] **
max =  0.2 | max_idx =  4
**pseudo_label ->  [0.157, 0.1644, 0.1154, 0.1409, 0.1337, 0.1171, 0.1715] **
max =  0.1715 | max_idx =  6
**pseudo_label ->  [0.1624, 0.1489, 0.1173, 0.1431, 0.1395, 0.1211, 0.1677] **
max =  0.1677 | max_idx =  6
**pseudo_label ->  [0.1621, 0.0976, 0.148, 0.1293, 0.2032, 0.1479, 0.1119] **
max =  0.2032 | max_idx =  4
**pseudo_label ->  [0.1614, 0.0995, 0.1458, 0.1311, 0.2029, 0.1411, 0.1183] **
max =  0.2029 | max_idx =  4
**pseudo_label ->  [0.1625, 0.0967, 0.1481, 0.1335, 0.1983, 0.1474, 0.1135] **
max =  0.1983 | max_idx =  4
**pseudo_label ->  [0.1593, 0.1069, 0.1396, 0.1277, 0.204, 0.1302, 0.1323] **
max =  0.204 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.2, 0.3, 0.0, 0.2, 0.0, 0.0, 0.1]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9382, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9650, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 70, Time: 0:42:41
Train F1: 0.0859, Val F1: 0.0777, Test F1: 0.0633
Epoch 7/20, Train Acc: 0.1143, Val Acc: 0.1303, Test Acc: 0.0963, Test F1(macro): 0.0633, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1485, 0.1447, 0.141, 0.1492, 0.1376, 0.1362, 0.1429] **
max =  0.1492 | max_idx =  3
**pseudo_label ->  [0.1504, 0.1409, 0.143, 0.1493, 0.1381, 0.1385, 0.1398] **
max =  0.1504 | max_idx =  0
**pseudo_label ->  [0.1496, 0.1417, 0.1433, 0.1489, 0.1387, 0.1378, 0.14] **
max =  0.1496 | max_idx =  0
**pseudo_label ->  [0.1501, 0.1423, 0.1439, 0.1471, 0.1388, 0.1382, 0.1397] **
max =  0.1501 | max_idx =  0
**pseudo_label ->  [0.1495, 0.144, 0.1425, 0.1473, 0.138, 0.1376, 0.1411] **
max =  0.1495 | max_idx =  0
**pseudo_label ->  [0.1508, 0.1403, 0.1446, 0.148, 0.1387, 0.1384, 0.1393] **
max =  0.1508 | max_idx =  0
**pseudo_label ->  [0.1495, 0.143, 0.1428, 0.1484, 0.1388, 0.1373, 0.14] **
max =  0.1495 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9472, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9486, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 80, Time: 0:47:23
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 8/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1424, 0.1408, 0.1421, 0.1404, 0.1453, 0.143, 0.1461] **
max =  0.1461 | max_idx =  6
**pseudo_label ->  [0.1422, 0.141, 0.1422, 0.1396, 0.1457, 0.1433, 0.146] **
max =  0.146 | max_idx =  6
**pseudo_label ->  [0.1422, 0.1403, 0.1427, 0.1394, 0.147, 0.143, 0.1455] **
max =  0.147 | max_idx =  4
**pseudo_label ->  [0.1422, 0.1409, 0.1426, 0.1394, 0.1462, 0.1427, 0.1459] **
max =  0.1462 | max_idx =  4
**pseudo_label ->  [0.1418, 0.1411, 0.142, 0.1398, 0.1465, 0.142, 0.1468] **
max =  0.1468 | max_idx =  6
**pseudo_label ->  [0.1413, 0.1413, 0.1418, 0.141, 0.1458, 0.1414, 0.1473] **
max =  0.1473 | max_idx =  6
**pseudo_label ->  [0.1411, 0.1415, 0.1426, 0.1401, 0.1474, 0.1417, 0.1456] **
max =  0.1474 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.7, 0.0, 0.7, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9463, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9463, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 90, Time: 0:52:23
Train F1: 0.0918, Val F1: 0.0756, Test F1: 0.0581
Epoch 9/20, Train Acc: 0.2000, Val Acc: 0.2182, Test Acc: 0.1496, Test F1(macro): 0.0581, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1442, 0.1414, 0.1441, 0.1433, 0.1418, 0.1453, 0.1399] **
max =  0.1453 | max_idx =  5
**pseudo_label ->  [0.1446, 0.1416, 0.1452, 0.1441, 0.141, 0.1458, 0.1377] **
max =  0.1458 | max_idx =  5
**pseudo_label ->  [0.1446, 0.1407, 0.1446, 0.1446, 0.1409, 0.1455, 0.1391] **
max =  0.1455 | max_idx =  5
**pseudo_label ->  [0.1434, 0.1436, 0.1437, 0.1423, 0.1418, 0.1438, 0.1415] **
max =  0.1438 | max_idx =  5
**pseudo_label ->  [0.1437, 0.1424, 0.1439, 0.1431, 0.1417, 0.1455, 0.1397] **
max =  0.1455 | max_idx =  5
**pseudo_label ->  [0.1428, 0.1433, 0.1443, 0.1428, 0.1425, 0.1435, 0.1408] **
max =  0.1443 | max_idx =  2
**pseudo_label ->  [0.1446, 0.1419, 0.1449, 0.1441, 0.1411, 0.1446, 0.1389] **
max =  0.1449 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9436, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9462, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 100, Time: 0:57:07
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 10/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.138, 0.1542, 0.1402, 0.1385, 0.1423, 0.1375, 0.1493] **
max =  0.1542 | max_idx =  1
**pseudo_label ->  [0.1234, 0.1721, 0.1281, 0.1214, 0.1514, 0.1165, 0.1871] **
max =  0.1871 | max_idx =  6
**pseudo_label ->  [0.1241, 0.1732, 0.1295, 0.1225, 0.1509, 0.1189, 0.1809] **
max =  0.1809 | max_idx =  6
**pseudo_label ->  [0.1447, 0.1442, 0.1438, 0.1522, 0.1341, 0.1454, 0.1355] **
max =  0.1522 | max_idx =  3
**pseudo_label ->  [0.1487, 0.1378, 0.147, 0.1559, 0.1337, 0.1494, 0.1275] **
max =  0.1559 | max_idx =  3
**pseudo_label ->  [0.149, 0.1364, 0.1463, 0.1551, 0.1339, 0.1507, 0.1285] **
max =  0.1551 | max_idx =  3
**pseudo_label ->  [0.1258, 0.1653, 0.1308, 0.1256, 0.1522, 0.1206, 0.1797] **
max =  0.1797 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 0.1, 0.0, 0.3, 0.0, 0.0, 0.8]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9035, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9424, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 110, Time: 1:01:48
Train F1: 0.0981, Val F1: 0.0617, Test F1: 0.0296
Epoch 11/20, Train Acc: 0.1714, Val Acc: 0.1433, Test Acc: 0.0451, Test F1(macro): 0.0296, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1314, 0.1501, 0.1522, 0.1162, 0.165, 0.1318, 0.1534] **
max =  0.165 | max_idx =  4
**pseudo_label ->  [0.1305, 0.1503, 0.1514, 0.1163, 0.1663, 0.1319, 0.1533] **
max =  0.1663 | max_idx =  4
**pseudo_label ->  [0.1322, 0.1482, 0.1528, 0.1166, 0.1659, 0.1328, 0.1514] **
max =  0.1659 | max_idx =  4
**pseudo_label ->  [0.1315, 0.1497, 0.152, 0.1174, 0.1655, 0.1326, 0.1514] **
max =  0.1655 | max_idx =  4
**pseudo_label ->  [0.1328, 0.147, 0.1516, 0.1174, 0.1656, 0.1337, 0.1519] **
max =  0.1656 | max_idx =  4
**pseudo_label ->  [0.1322, 0.1487, 0.1513, 0.1168, 0.1651, 0.1326, 0.1532] **
max =  0.1651 | max_idx =  4
**pseudo_label ->  [0.1332, 0.1479, 0.1525, 0.1169, 0.1646, 0.1337, 0.1511] **
max =  0.1646 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.9, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9550, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9487, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 120, Time: 1:06:30
Train F1: 0.0622, Val F1: 0.0467, Test F1: 0.0644
Epoch 12/20, Train Acc: 0.1571, Val Acc: 0.0879, Test Acc: 0.1373, Test F1(macro): 0.0644, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1421, 0.1381, 0.1498, 0.1426, 0.1433, 0.1449, 0.1393] **
max =  0.1498 | max_idx =  2
**pseudo_label ->  [0.1424, 0.1379, 0.1483, 0.1438, 0.1427, 0.1461, 0.1389] **
max =  0.1483 | max_idx =  2
**pseudo_label ->  [0.1418, 0.1382, 0.1487, 0.1426, 0.1433, 0.1458, 0.1396] **
max =  0.1487 | max_idx =  2
**pseudo_label ->  [0.142, 0.1369, 0.1478, 0.1448, 0.1423, 0.1458, 0.1404] **
max =  0.1478 | max_idx =  2
**pseudo_label ->  [0.142, 0.1373, 0.149, 0.1426, 0.1436, 0.1459, 0.1396] **
max =  0.149 | max_idx =  2
**pseudo_label ->  [0.1416, 0.1372, 0.1489, 0.1417, 0.1442, 0.1461, 0.1404] **
max =  0.1489 | max_idx =  2
**pseudo_label ->  [0.1426, 0.1375, 0.1485, 0.1438, 0.1425, 0.1457, 0.1393] **
max =  0.1485 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9497, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9409, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 130, Time: 1:11:11
Train F1: 0.0357, Val F1: 0.0018, Test F1: 0.0623
Epoch 13/20, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1402, 0.1465, 0.141, 0.1412, 0.1448, 0.1409, 0.1453] **
max =  0.1465 | max_idx =  1
**pseudo_label ->  [0.14, 0.1464, 0.1422, 0.1408, 0.1451, 0.1403, 0.1453] **
max =  0.1464 | max_idx =  1
**pseudo_label ->  [0.1387, 0.1496, 0.1423, 0.141, 0.1421, 0.1393, 0.1471] **
max =  0.1496 | max_idx =  1
**pseudo_label ->  [0.1399, 0.1477, 0.1407, 0.1412, 0.1434, 0.1412, 0.1458] **
max =  0.1477 | max_idx =  1
**pseudo_label ->  [0.1405, 0.1473, 0.1409, 0.1419, 0.1434, 0.1404, 0.1456] **
max =  0.1473 | max_idx =  1
**pseudo_label ->  [0.1404, 0.1477, 0.1409, 0.1421, 0.1433, 0.1409, 0.1447] **
max =  0.1477 | max_idx =  1
**pseudo_label ->  [0.1395, 0.1482, 0.1415, 0.1415, 0.1432, 0.1399, 0.1463] **
max =  0.1482 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.3, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9446, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9289, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 140, Time: 1:15:53
Train F1: 0.0822, Val F1: 0.0741, Test F1: 0.0513
Epoch 14/20, Train Acc: 0.1857, Val Acc: 0.1531, Test Acc: 0.0963, Test F1(macro): 0.0513, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.144, 0.1421, 0.1453, 0.1421, 0.1423, 0.1434, 0.1407] **
max =  0.1453 | max_idx =  2
**pseudo_label ->  [0.144, 0.1414, 0.1448, 0.1428, 0.1426, 0.1434, 0.1409] **
max =  0.1448 | max_idx =  2
**pseudo_label ->  [0.144, 0.1408, 0.1445, 0.1442, 0.1424, 0.1434, 0.1408] **
max =  0.1445 | max_idx =  2
**pseudo_label ->  [0.1429, 0.1417, 0.1436, 0.1443, 0.1419, 0.1437, 0.1419] **
max =  0.1443 | max_idx =  3
**pseudo_label ->  [0.1438, 0.141, 0.1441, 0.1434, 0.1426, 0.1438, 0.1414] **
max =  0.1441 | max_idx =  2
**pseudo_label ->  [0.1438, 0.1411, 0.1451, 0.1426, 0.1428, 0.1432, 0.1415] **
max =  0.1451 | max_idx =  2
**pseudo_label ->  [0.144, 0.1409, 0.1454, 0.1421, 0.1434, 0.143, 0.1412] **
max =  0.1454 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.8, 0.6, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9429, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9069, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 150, Time: 1:20:34
Train F1: 0.0897, Val F1: 0.0536, Test F1: 0.0435
Epoch 15/20, Train Acc: 0.2000, Val Acc: 0.1238, Test Acc: 0.0922, Test F1(macro): 0.0435, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1484, 0.1427, 0.1374, 0.1516, 0.1374, 0.1468, 0.1358] **
max =  0.1516 | max_idx =  3
**pseudo_label ->  [0.1425, 0.1399, 0.1411, 0.1408, 0.1468, 0.1446, 0.1443] **
max =  0.1468 | max_idx =  4
**pseudo_label ->  [0.1478, 0.1446, 0.1373, 0.1531, 0.1354, 0.1466, 0.1353] **
max =  0.1531 | max_idx =  3
**pseudo_label ->  [0.1476, 0.1446, 0.138, 0.1495, 0.1373, 0.1464, 0.1365] **
max =  0.1495 | max_idx =  3
**pseudo_label ->  [0.147, 0.1431, 0.1389, 0.1495, 0.1388, 0.1449, 0.1378] **
max =  0.1495 | max_idx =  3
**pseudo_label ->  [0.1476, 0.1467, 0.137, 0.1549, 0.1342, 0.1455, 0.1342] **
max =  0.1549 | max_idx =  3
**pseudo_label ->  [0.1433, 0.1385, 0.1414, 0.1402, 0.1466, 0.1449, 0.145] **
max =  0.1466 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9358, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8247, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 160, Time: 1:25:15
Train F1: 0.0190, Val F1: 0.0051, Test F1: 0.1003
Epoch 16/20, Train Acc: 0.0571, Val Acc: 0.0065, Test Acc: 0.2643, Test F1(macro): 0.1003, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1278, 0.1097, 0.1441, 0.1122, 0.1794, 0.1524, 0.1744] **
max =  0.1794 | max_idx =  4
**pseudo_label ->  [0.128, 0.1099, 0.1442, 0.1122, 0.1782, 0.1534, 0.1742] **
max =  0.1782 | max_idx =  4
**pseudo_label ->  [0.1274, 0.1089, 0.1439, 0.1124, 0.1795, 0.153, 0.1749] **
max =  0.1795 | max_idx =  4
**pseudo_label ->  [0.1273, 0.1107, 0.1454, 0.1116, 0.18, 0.152, 0.173] **
max =  0.18 | max_idx =  4
**pseudo_label ->  [0.1282, 0.1101, 0.145, 0.1112, 0.1797, 0.1528, 0.173] **
max =  0.1797 | max_idx =  4
**pseudo_label ->  [0.1278, 0.1093, 0.1432, 0.1124, 0.1803, 0.1548, 0.1722] **
max =  0.1803 | max_idx =  4
**pseudo_label ->  [0.1275, 0.1101, 0.1444, 0.112, 0.1793, 0.1532, 0.1734] **
max =  0.1793 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9675, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9223, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 170, Time: 1:29:56
Train F1: 0.0952, Val F1: 0.0533, Test F1: 0.0412
Epoch 17/20, Train Acc: 0.2143, Val Acc: 0.1336, Test Acc: 0.0902, Test F1(macro): 0.0412, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1386, 0.1426, 0.1479, 0.1393, 0.1425, 0.1451, 0.144] **
max =  0.1479 | max_idx =  2
**pseudo_label ->  [0.1385, 0.1413, 0.1467, 0.1404, 0.143, 0.1453, 0.1447] **
max =  0.1467 | max_idx =  2
**pseudo_label ->  [0.1388, 0.1421, 0.1477, 0.1404, 0.1424, 0.1453, 0.1433] **
max =  0.1477 | max_idx =  2
**pseudo_label ->  [0.1391, 0.1409, 0.148, 0.1404, 0.1428, 0.1447, 0.1441] **
max =  0.148 | max_idx =  2
**pseudo_label ->  [0.1389, 0.1422, 0.1484, 0.1405, 0.1425, 0.1439, 0.1436] **
max =  0.1484 | max_idx =  2
**pseudo_label ->  [0.139, 0.1434, 0.1484, 0.1416, 0.141, 0.1442, 0.1424] **
max =  0.1484 | max_idx =  2
**pseudo_label ->  [0.1387, 0.1415, 0.1472, 0.14, 0.1426, 0.1454, 0.1447] **
max =  0.1472 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.8, 0.3, 0.0, 0.8, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9448, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8041, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 180, Time: 1:34:38
Train F1: 0.1654, Val F1: 0.0497, Test F1: 0.0890
Epoch 18/20, Train Acc: 0.2714, Val Acc: 0.1075, Test Acc: 0.2213, Test F1(macro): 0.0890, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1434, 0.1397, 0.14, 0.141, 0.1452, 0.1442, 0.1466] **
max =  0.1466 | max_idx =  6
**pseudo_label ->  [0.1434, 0.1402, 0.1394, 0.1426, 0.1451, 0.144, 0.1454] **
max =  0.1454 | max_idx =  6
**pseudo_label ->  [0.143, 0.1396, 0.1388, 0.1428, 0.1453, 0.144, 0.1466] **
max =  0.1466 | max_idx =  6
**pseudo_label ->  [0.1444, 0.14, 0.138, 0.1426, 0.1442, 0.1451, 0.1455] **
max =  0.1455 | max_idx =  6
**pseudo_label ->  [0.1435, 0.1406, 0.1402, 0.1429, 0.1439, 0.1431, 0.1458] **
max =  0.1458 | max_idx =  6
**pseudo_label ->  [0.1434, 0.1409, 0.1392, 0.1436, 0.1442, 0.1446, 0.1441] **
max =  0.1446 | max_idx =  5
**pseudo_label ->  [0.1433, 0.1411, 0.1403, 0.143, 0.144, 0.1436, 0.1446] **
max =  0.1446 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.7, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9435, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.7900, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 190, Time: 1:39:19
Train F1: 0.1091, Val F1: 0.0580, Test F1: 0.0889
Epoch 19/20, Train Acc: 0.2429, Val Acc: 0.1238, Test Acc: 0.2541, Test F1(macro): 0.0889, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1415, 0.1464, 0.1459, 0.1441, 0.142, 0.14, 0.1401] **
max =  0.1464 | max_idx =  1
**pseudo_label ->  [0.1435, 0.1442, 0.1465, 0.1427, 0.142, 0.1409, 0.1403] **
max =  0.1465 | max_idx =  2
**pseudo_label ->  [0.1417, 0.144, 0.1457, 0.1438, 0.1426, 0.141, 0.1412] **
max =  0.1457 | max_idx =  2
**pseudo_label ->  [0.143, 0.1463, 0.1467, 0.1437, 0.1412, 0.1401, 0.139] **
max =  0.1467 | max_idx =  2
**pseudo_label ->  [0.1421, 0.1455, 0.1454, 0.1434, 0.1423, 0.1412, 0.14] **
max =  0.1455 | max_idx =  1
**pseudo_label ->  [0.1429, 0.1441, 0.1447, 0.1436, 0.1424, 0.1418, 0.1405] **
max =  0.1447 | max_idx =  2
**pseudo_label ->  [0.1432, 0.1444, 0.1451, 0.1428, 0.1415, 0.1418, 0.1412] **
max =  0.1451 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.7, 1.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9450, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.8050, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 200, Time: 1:44:01
Train F1: 0.1076, Val F1: 0.0557, Test F1: 0.0861
Epoch 20/20, Train Acc: 0.2429, Val Acc: 0.1205, Test Acc: 0.2439, Test F1(macro): 0.0861, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70


Training complete!
Total training took 1:44:01 (h:mm:ss)
Load model from ./experiment/jointmatch/output/10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_20_[43]_{'python'}_net0.pth
Load model from ./experiment/jointmatch/output/10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_20_[43]_{'python'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/codet5p/joint_match//10_['codet5p', 'codet5p']_[0.0003, 0.00025]_0.7_jointmatch_20_[43]_{'python'}/training_statistics.csv


Best_step:  90 
Best_val_epoch:  9 
best_val_acc:  0.2182410423452769 
best_val_test_acc:  0.14959016393442623 
best_val_test_f1:  0.05808562793583686
Save best record in:  ./experiment/jointmatch/log/codet5p/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
