current work directory:  /home/imsuhan22/few-shot-tc/custom_ssl/code

bs =>  7
Data set -> jointmatch
save_name: 10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'python'}

data_path:  ../data/jointmatch/python

There are 1 GPU(s) available.
We will use the GPU- 0 Quadro RTX 8000

**line 107 모델 =>  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base']
**tokenizer type =  ['microsoft/unixcoder-base', 'microsoft/unixcoder-base'] 

n_labeled_per_class:  10
train_df samples: 3974
train_labeled_df samples: 70
train_unlabeled_df samples: 3904
Check n_smaples_per_class in the original training set:  OrderedDict([(1, 704), (2, 514), (3, 707), (4, 585), (5, 580), (6, 426), (7, 458)])
Check n_smaples_per_class in the labeled training set:  OrderedDict([(1, 10), (2, 10), (3, 10), (4, 10), (5, 10), (6, 10), (7, 10)])
Check n_smaples_per_class in the unlabeled training set:  OrderedDict([(1, 694), (2, 504), (3, 697), (4, 575), (5, 570), (6, 416), (7, 448)])
n_classes:  7

net_arch:  microsoft/unixcoder-base 
lr:  0.0004 
lr_linear:  0.001 


net_arch:  microsoft/unixcoder-base 
lr:  0.0002 
lr_linear:  0.001 

**pseudo_label ->  [0.134, 0.1505, 0.1655, 0.0902, 0.1304, 0.1617, 0.1677] **
max =  0.1677 | max_idx =  6
**pseudo_label ->  [0.1343, 0.1706, 0.1614, 0.12, 0.1736, 0.0876, 0.1525] **
max =  0.1736 | max_idx =  4
**pseudo_label ->  [0.1359, 0.1406, 0.144, 0.1445, 0.1877, 0.1704, 0.077] **
max =  0.1877 | max_idx =  4
**pseudo_label ->  [0.143, 0.1197, 0.112, 0.1361, 0.1847, 0.145, 0.1594] **
max =  0.1847 | max_idx =  4
**pseudo_label ->  [0.15, 0.1501, 0.1579, 0.1307, 0.1253, 0.1119, 0.174] **
max =  0.174 | max_idx =  6
**pseudo_label ->  [0.1187, 0.1602, 0.1348, 0.1188, 0.1348, 0.0959, 0.2368] **
max =  0.2368 | max_idx =  6
**pseudo_label ->  [0.0955, 0.1389, 0.1635, 0.1416, 0.1937, 0.1216, 0.1451] **
max =  0.1937 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(1.9598, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9131, device='cuda:0', grad_fn=<NllLossBackward0>)
Save model to ./experiment/jointmatch/output/
Step 10, Time: 0:04:47
Train F1: 0.0357, Val F1: 0.0798, Test F1: 0.0398
Epoch 1/20, Train Acc: 0.1429, Val Acc: 0.3876, Test Acc: 0.1619, Test F1(macro): 0.0398, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1102, 0.0895, 0.1085, 0.1928, 0.2451, 0.1332, 0.1206] **
max =  0.2451 | max_idx =  4
**pseudo_label ->  [0.1228, 0.1312, 0.0972, 0.1242, 0.2327, 0.1232, 0.1686] **
max =  0.2327 | max_idx =  4
**pseudo_label ->  [0.1454, 0.1259, 0.1474, 0.1179, 0.1842, 0.1384, 0.1407] **
max =  0.1842 | max_idx =  4
**pseudo_label ->  [0.1364, 0.13, 0.1168, 0.1203, 0.222, 0.1139, 0.1606] **
max =  0.222 | max_idx =  4
**pseudo_label ->  [0.089, 0.1513, 0.1191, 0.1007, 0.2714, 0.129, 0.1395] **
max =  0.2714 | max_idx =  4
**pseudo_label ->  [0.1625, 0.1618, 0.1175, 0.0872, 0.2166, 0.1141, 0.1404] **
max =  0.2166 | max_idx =  4
**pseudo_label ->  [0.1026, 0.1387, 0.1242, 0.1275, 0.2271, 0.1393, 0.1405] **
max =  0.2271 | max_idx =  4
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0301, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1187, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 20, Time: 0:09:29
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 2/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.065, 0.0988, 0.117, 0.2417, 0.1019, 0.2112, 0.1644] **
max =  0.2417 | max_idx =  3
**pseudo_label ->  [0.0734, 0.0777, 0.1569, 0.1982, 0.1571, 0.1444, 0.1923] **
max =  0.1982 | max_idx =  3
**pseudo_label ->  [0.0494, 0.1135, 0.1447, 0.1682, 0.2124, 0.1591, 0.1527] **
max =  0.2124 | max_idx =  4
**pseudo_label ->  [0.0658, 0.1047, 0.1394, 0.1297, 0.0912, 0.2027, 0.2666] **
max =  0.2666 | max_idx =  6
**pseudo_label ->  [0.0591, 0.1225, 0.1129, 0.1796, 0.0823, 0.2711, 0.1725] **
max =  0.2711 | max_idx =  5
**pseudo_label ->  [0.0615, 0.0954, 0.1185, 0.1554, 0.1465, 0.2855, 0.1372] **
max =  0.2855 | max_idx =  5
**pseudo_label ->  [0.0697, 0.1031, 0.1386, 0.2153, 0.153, 0.1365, 0.1838] **
max =  0.2153 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3805, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 551, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.145 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.14480945467948914, nan, nan]
loss for labeled data =>  tensor(1.8852, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9359, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 30, Time: 0:14:13
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 3/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 70

**pseudo_label ->  [0.0872, 0.2592, 0.1198, 0.137, 0.155, 0.0955, 0.1463] **
max =  0.2592 | max_idx =  1
**pseudo_label ->  [0.0716, 0.1538, 0.172, 0.1396, 0.1827, 0.1402, 0.1401] **
max =  0.1827 | max_idx =  4
**pseudo_label ->  [0.0885, 0.2364, 0.1571, 0.1234, 0.1425, 0.1242, 0.128] **
max =  0.2364 | max_idx =  1
**pseudo_label ->  [0.0681, 0.2554, 0.178, 0.128, 0.121, 0.1189, 0.1305] **
max =  0.2554 | max_idx =  1
**pseudo_label ->  [0.0854, 0.1967, 0.1583, 0.149, 0.1554, 0.117, 0.1382] **
max =  0.1967 | max_idx =  1
**pseudo_label ->  [0.0823, 0.1615, 0.178, 0.1323, 0.1711, 0.1088, 0.166] **
max =  0.178 | max_idx =  2
**pseudo_label ->  [0.0799, 0.1996, 0.1241, 0.1573, 0.1468, 0.1374, 0.1548] **
max =  0.1996 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3824, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 554, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.145 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.1448744833469391, nan, nan]
loss for labeled data =>  tensor(2.0513, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1418, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 40, Time: 0:18:59
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 4/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1045, 0.1412, 0.0663, 0.2506, 0.0001, 0.2356, 0.2017] **
max =  0.2506 | max_idx =  3
**pseudo_label ->  [0.108, 0.1397, 0.0866, 0.2505, 0.0001, 0.2806, 0.1346] **
max =  0.2806 | max_idx =  5
**pseudo_label ->  [0.0752, 0.236, 0.0524, 0.1979, 0.0001, 0.3081, 0.1304] **
max =  0.3081 | max_idx =  5
**pseudo_label ->  [0.1167, 0.133, 0.0832, 0.2253, 0.0001, 0.2632, 0.1786] **
max =  0.2632 | max_idx =  5
**pseudo_label ->  [0.1169, 0.1787, 0.0911, 0.2144, 0.0001, 0.2237, 0.1751] **
max =  0.2237 | max_idx =  5
**pseudo_label ->  [0.1003, 0.1916, 0.0652, 0.2351, 0.0001, 0.2362, 0.1715] **
max =  0.2362 | max_idx =  5
**pseudo_label ->  [0.0998, 0.1577, 0.0636, 0.2396, 0.0001, 0.2474, 0.1918] **
max =  0.2474 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3725, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 668, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.179 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.17932885885238647, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.8394, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1883, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 50, Time: 0:27:22
Train F1: 0.0357, Val F1: 0.0531, Test F1: 0.0313
Epoch 5/20, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 70

**pseudo_label ->  [0.216, 0.2449, 0.0001, 0.1868, 0.0, 0.1499, 0.2023] **
max =  0.2449 | max_idx =  1
**pseudo_label ->  [0.1497, 0.2197, 0.0001, 0.167, 0.0, 0.1237, 0.3398] **
max =  0.3398 | max_idx =  6
**pseudo_label ->  [0.1863, 0.2601, 0.0001, 0.1306, 0.0, 0.157, 0.2659] **
max =  0.2659 | max_idx =  6
**pseudo_label ->  [0.173, 0.2928, 0.0001, 0.1821, 0.0, 0.1543, 0.1978] **
max =  0.2928 | max_idx =  1
**pseudo_label ->  [0.1636, 0.296, 0.0001, 0.2092, 0.0, 0.1344, 0.1968] **
max =  0.296 | max_idx =  1
**pseudo_label ->  [0.1576, 0.3638, 0.0001, 0.1219, 0.0, 0.1219, 0.2347] **
max =  0.3638 | max_idx =  1
**pseudo_label ->  [0.1559, 0.3015, 0.0001, 0.1368, 0.0, 0.1732, 0.2325] **
max =  0.3015 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3300, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 478, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.145 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.14484848082065582, nan, nan]
loss for labeled data =>  tensor(4.7666, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.6790, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 60, Time: 0:35:43
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 6/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.2708, 0.4654, 0.0155, 0.1145, 0.0007, 0.0938, 0.0394] **
max =  0.4654 | max_idx =  1
**pseudo_label ->  [0.4044, 0.3112, 0.0242, 0.1222, 0.0009, 0.0973, 0.0399] **
max =  0.4044 | max_idx =  0
**pseudo_label ->  [0.2506, 0.5051, 0.0175, 0.1094, 0.0004, 0.0852, 0.0318] **
max =  0.5051 | max_idx =  1
**pseudo_label ->  [0.3084, 0.4312, 0.0188, 0.1297, 0.0005, 0.0852, 0.0262] **
max =  0.4312 | max_idx =  1
**pseudo_label ->  [0.3671, 0.3915, 0.0106, 0.1002, 0.0005, 0.1021, 0.0281] **
max =  0.3915 | max_idx =  1
**pseudo_label ->  [0.2567, 0.5047, 0.022, 0.0965, 0.0005, 0.0798, 0.0398] **
max =  0.5047 | max_idx =  1
**pseudo_label ->  [0.2904, 0.4293, 0.0138, 0.1317, 0.0006, 0.1109, 0.0232] **
max =  0.4293 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 3878, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 503, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.13 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.12970604002475739, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.4461, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.3701, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 70, Time: 0:44:05
Train F1: 0.0357, Val F1: 0.0018, Test F1: 0.0623
Epoch 7/20, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 2, Train Data Number: 70

**pseudo_label ->  [0.0861, 0.0047, 0.0189, 0.0813, 0.0129, 0.1271, 0.669] **
max =  0.669 | max_idx =  6
**pseudo_label ->  [0.1264, 0.0062, 0.0249, 0.0981, 0.0281, 0.1626, 0.5538] **
max =  0.5538 | max_idx =  6
**pseudo_label ->  [0.0788, 0.0037, 0.0159, 0.0542, 0.0103, 0.1074, 0.7298] **
max =  0.7298 | max_idx =  6
**pseudo_label ->  [0.0954, 0.0043, 0.0138, 0.0783, 0.0138, 0.1727, 0.6216] **
max =  0.6216 | max_idx =  6
**pseudo_label ->  [0.075, 0.0039, 0.0279, 0.0589, 0.0119, 0.1914, 0.6311] **
max =  0.6311 | max_idx =  6
**pseudo_label ->  [0.0924, 0.0059, 0.0155, 0.062, 0.0083, 0.0794, 0.7365] **
max =  0.7365 | max_idx =  6
**pseudo_label ->  [0.0669, 0.0037, 0.013, 0.0451, 0.0098, 0.0782, 0.7832] **
max =  0.7832 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 3900]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 448]
psl_acc(PSL 평가에서의 정확도):  0.115 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1148717924952507]
loss for labeled data =>  tensor(2.7425, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.1147, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 80, Time: 0:52:31
Train F1: 0.0357, Val F1: 0.0300, Test F1: 0.0052
Epoch 8/20, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.2246, 0.0056, 0.0798, 0.3016, 0.1586, 0.2289, 0.0008] **
max =  0.3016 | max_idx =  3
**pseudo_label ->  [0.1423, 0.0056, 0.1183, 0.2717, 0.2283, 0.2329, 0.0008] **
max =  0.2717 | max_idx =  3
**pseudo_label ->  [0.1949, 0.0051, 0.0512, 0.3435, 0.1722, 0.2325, 0.0006] **
max =  0.3435 | max_idx =  3
**pseudo_label ->  [0.135, 0.0081, 0.1011, 0.3036, 0.1988, 0.2529, 0.0006] **
max =  0.3036 | max_idx =  3
**pseudo_label ->  [0.1832, 0.0064, 0.0877, 0.3709, 0.1511, 0.1999, 0.0008] **
max =  0.3709 | max_idx =  3
**pseudo_label ->  [0.1596, 0.0054, 0.1062, 0.3337, 0.1694, 0.2249, 0.0009] **
max =  0.3337 | max_idx =  3
**pseudo_label ->  [0.2176, 0.0071, 0.0926, 0.2183, 0.1544, 0.3094, 0.0005] **
max =  0.3094 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 3840, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 562, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.146 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, 0.14635416865348816, nan, nan]
loss for labeled data =>  tensor(3.2027, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.1231, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 90, Time: 1:00:54
Train F1: 0.0357, Val F1: 0.0358, Test F1: 0.0118
Epoch 9/20, Train Acc: 0.1429, Val Acc: 0.1433, Test Acc: 0.0430, Test F1(macro): 0.0118, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1841, 0.0743, 0.3692, 0.1709, 0.0004, 0.2011, 0.0001] **
max =  0.3692 | max_idx =  2
**pseudo_label ->  [0.1896, 0.2109, 0.2649, 0.1625, 0.0005, 0.1716, 0.0] **
max =  0.2649 | max_idx =  2
**pseudo_label ->  [0.1842, 0.1585, 0.2425, 0.1887, 0.0006, 0.2255, 0.0] **
max =  0.2425 | max_idx =  2
**pseudo_label ->  [0.1818, 0.1472, 0.3182, 0.1708, 0.0003, 0.1817, 0.0] **
max =  0.3182 | max_idx =  2
**pseudo_label ->  [0.1887, 0.1561, 0.3372, 0.1389, 0.0008, 0.1783, 0.0] **
max =  0.3372 | max_idx =  2
**pseudo_label ->  [0.1975, 0.1532, 0.2213, 0.2308, 0.0004, 0.1968, 0.0001] **
max =  0.2308 | max_idx =  3
**pseudo_label ->  [0.1927, 0.157, 0.3002, 0.1927, 0.0003, 0.1571, 0.0] **
max =  0.3002 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3854, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 687, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.178 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.17825636267662048, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.7326, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0127, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 100, Time: 1:09:22
Train F1: 0.0357, Val F1: 0.0531, Test F1: 0.0313
Epoch 10/20, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.17, 0.3158, 0.0003, 0.2241, 0.0, 0.1329, 0.1569] **
max =  0.3158 | max_idx =  1
**pseudo_label ->  [0.1614, 0.235, 0.0005, 0.1472, 0.0, 0.179, 0.2768] **
max =  0.2768 | max_idx =  6
**pseudo_label ->  [0.2153, 0.22, 0.0007, 0.1492, 0.0, 0.1979, 0.2169] **
max =  0.22 | max_idx =  1
**pseudo_label ->  [0.1446, 0.2901, 0.0005, 0.0981, 0.0, 0.1481, 0.3185] **
max =  0.3185 | max_idx =  6
**pseudo_label ->  [0.1761, 0.2115, 0.0004, 0.2087, 0.0, 0.241, 0.1622] **
max =  0.241 | max_idx =  5
**pseudo_label ->  [0.1736, 0.243, 0.0003, 0.1663, 0.0, 0.2645, 0.1523] **
max =  0.2645 | max_idx =  5
**pseudo_label ->  [0.1846, 0.3225, 0.0002, 0.1402, 0.0, 0.1732, 0.1792] **
max =  0.3225 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 3874]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 446]
psl_acc(PSL 평가에서의 정확도):  0.115 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.11512648314237595]
loss for labeled data =>  tensor(3.8768, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9990, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 110, Time: 1:17:49
Train F1: 0.0357, Val F1: 0.0300, Test F1: 0.0052
Epoch 11/20, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 70

**pseudo_label ->  [0.2044, 0.1529, 0.2943, 0.0926, 0.0531, 0.1843, 0.0185] **
max =  0.2943 | max_idx =  2
**pseudo_label ->  [0.1941, 0.0967, 0.3621, 0.1357, 0.0628, 0.1243, 0.0243] **
max =  0.3621 | max_idx =  2
**pseudo_label ->  [0.1915, 0.1094, 0.3827, 0.0703, 0.0746, 0.147, 0.0246] **
max =  0.3827 | max_idx =  2
**pseudo_label ->  [0.2581, 0.101, 0.2632, 0.0925, 0.0985, 0.1697, 0.017] **
max =  0.2632 | max_idx =  2
**pseudo_label ->  [0.1692, 0.0861, 0.4033, 0.0932, 0.098, 0.1231, 0.0272] **
max =  0.4033 | max_idx =  2
**pseudo_label ->  [0.2268, 0.1306, 0.2543, 0.0839, 0.0554, 0.2222, 0.0269] **
max =  0.2543 | max_idx =  2
**pseudo_label ->  [0.2306, 0.1172, 0.2738, 0.1146, 0.0668, 0.1749, 0.0221] **
max =  0.2738 | max_idx =  2
acc_train_cw(현재 train의 class별 acc) [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.2568, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.2348, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 120, Time: 1:26:10
Train F1: 0.0357, Val F1: 0.0239, Test F1: 0.0206
Epoch 12/20, Train Acc: 0.1429, Val Acc: 0.0912, Test Acc: 0.0779, Test F1(macro): 0.0206, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0768, 0.1706, 0.1201, 0.1376, 0.1346, 0.1656, 0.1947] **
max =  0.1947 | max_idx =  6
**pseudo_label ->  [0.0675, 0.1798, 0.0783, 0.1462, 0.0921, 0.1398, 0.2963] **
max =  0.2963 | max_idx =  6
**pseudo_label ->  [0.1019, 0.1221, 0.0799, 0.1451, 0.1063, 0.2474, 0.1973] **
max =  0.2474 | max_idx =  5
**pseudo_label ->  [0.0796, 0.1096, 0.1126, 0.1451, 0.1243, 0.1656, 0.2632] **
max =  0.2632 | max_idx =  6
**pseudo_label ->  [0.0968, 0.1102, 0.1471, 0.1593, 0.1544, 0.1586, 0.1736] **
max =  0.1736 | max_idx =  6
**pseudo_label ->  [0.0744, 0.158, 0.1343, 0.1633, 0.1372, 0.1443, 0.1886] **
max =  0.1886 | max_idx =  6
**pseudo_label ->  [0.0954, 0.1987, 0.091, 0.1405, 0.1069, 0.1081, 0.2596] **
max =  0.2596 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도): None 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(2.0630, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0664, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 130, Time: 1:34:26
Train F1: 0.0357, Val F1: 0.0300, Test F1: 0.0052
Epoch 13/20, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 0, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.1038, 0.1805, 0.1296, 0.2155, 0.0923, 0.1483, 0.1302] **
max =  0.2155 | max_idx =  3
**pseudo_label ->  [0.08, 0.1761, 0.2253, 0.1823, 0.0898, 0.1014, 0.1452] **
max =  0.2253 | max_idx =  2
**pseudo_label ->  [0.0875, 0.1499, 0.1406, 0.1635, 0.1848, 0.1, 0.1736] **
max =  0.1848 | max_idx =  4
**pseudo_label ->  [0.0928, 0.1364, 0.1433, 0.1773, 0.1568, 0.1373, 0.1561] **
max =  0.1773 | max_idx =  3
**pseudo_label ->  [0.0913, 0.1476, 0.1419, 0.2402, 0.129, 0.1364, 0.1135] **
max =  0.2402 | max_idx =  3
**pseudo_label ->  [0.099, 0.1783, 0.1807, 0.178, 0.1588, 0.0951, 0.1101] **
max =  0.1807 | max_idx =  2
**pseudo_label ->  [0.1531, 0.1544, 0.1013, 0.2045, 0.1129, 0.1658, 0.108] **
max =  0.2045 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 3804, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 562, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.148 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.1477392166852951, nan, nan, nan]
loss for labeled data =>  tensor(1.9858, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.0165, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 140, Time: 1:42:49
Train F1: 0.0357, Val F1: 0.0798, Test F1: 0.0398
Epoch 14/20, Train Acc: 0.1429, Val Acc: 0.3876, Test Acc: 0.1619, Test F1(macro): 0.0398, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.0726, 0.0801, 0.216, 0.0001, 0.3006, 0.0847, 0.2459] **
max =  0.3006 | max_idx =  4
**pseudo_label ->  [0.0731, 0.1069, 0.1862, 0.0001, 0.3234, 0.0585, 0.2518] **
max =  0.3234 | max_idx =  4
**pseudo_label ->  [0.1213, 0.1118, 0.1857, 0.0001, 0.2886, 0.0749, 0.2176] **
max =  0.2886 | max_idx =  4
**pseudo_label ->  [0.0987, 0.1378, 0.2502, 0.0001, 0.2048, 0.0949, 0.2136] **
max =  0.2502 | max_idx =  2
**pseudo_label ->  [0.0691, 0.0699, 0.3149, 0.0001, 0.3001, 0.0761, 0.1698] **
max =  0.3149 | max_idx =  2
**pseudo_label ->  [0.0963, 0.0781, 0.3071, 0.0001, 0.2911, 0.0703, 0.157] **
max =  0.3071 | max_idx =  2
**pseudo_label ->  [0.1231, 0.1019, 0.207, 0.0001, 0.2175, 0.1222, 0.2282] **
max =  0.2282 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 0, 0, 0, 3850]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 0, 0, 0, 442]
psl_acc(PSL 평가에서의 정확도):  0.115 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, nan, nan, nan, 0.1148051917552948]
loss for labeled data =>  tensor(2.8394, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(1.9796, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 150, Time: 1:51:16
Train F1: 0.0357, Val F1: 0.0300, Test F1: 0.0052
Epoch 15/20, Train Acc: 0.1429, Val Acc: 0.1173, Test Acc: 0.0184, Test F1(macro): 0.0052, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.2465, 0.2932, 0.1305, 0.0, 0.1354, 0.1942, 0.0001] **
max =  0.2932 | max_idx =  1
**pseudo_label ->  [0.3224, 0.3664, 0.0707, 0.0, 0.0914, 0.1489, 0.0001] **
max =  0.3664 | max_idx =  1
**pseudo_label ->  [0.3101, 0.2709, 0.1433, 0.0, 0.1316, 0.1439, 0.0001] **
max =  0.3101 | max_idx =  0
**pseudo_label ->  [0.3308, 0.3182, 0.0991, 0.0, 0.1225, 0.1294, 0.0001] **
max =  0.3308 | max_idx =  0
**pseudo_label ->  [0.3439, 0.2476, 0.111, 0.0, 0.1311, 0.1664, 0.0001] **
max =  0.3439 | max_idx =  0
**pseudo_label ->  [0.3158, 0.3354, 0.095, 0.0, 0.1065, 0.1472, 0.0001] **
max =  0.3354 | max_idx =  1
**pseudo_label ->  [0.3404, 0.2372, 0.1111, 0.0, 0.0908, 0.2204, 0.0001] **
max =  0.3404 | max_idx =  0
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 3797, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 679, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.179 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, 0.17882539331912994, nan, nan, nan, nan]
loss for labeled data =>  tensor(4.9208, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.1970, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 160, Time: 1:59:45
Train F1: 0.0357, Val F1: 0.0531, Test F1: 0.0313
Epoch 16/20, Train Acc: 0.1429, Val Acc: 0.2280, Test Acc: 0.1230, Test F1(macro): 0.0313, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.2061, 0.4469, 0.0002, 0.0001, 0.238, 0.1087, 0.0] **
max =  0.4469 | max_idx =  1
**pseudo_label ->  [0.2832, 0.4195, 0.0001, 0.0001, 0.1734, 0.1237, 0.0] **
max =  0.4195 | max_idx =  1
**pseudo_label ->  [0.2717, 0.4375, 0.0002, 0.0001, 0.1981, 0.0923, 0.0] **
max =  0.4375 | max_idx =  1
**pseudo_label ->  [0.2917, 0.3661, 0.0003, 0.0002, 0.206, 0.1357, 0.0] **
max =  0.3661 | max_idx =  1
**pseudo_label ->  [0.2957, 0.3792, 0.0003, 0.0001, 0.2037, 0.121, 0.0] **
max =  0.3792 | max_idx =  1
**pseudo_label ->  [0.2698, 0.3574, 0.0002, 0.0001, 0.2399, 0.1326, 0.0] **
max =  0.3574 | max_idx =  1
**pseudo_label ->  [0.2767, 0.3947, 0.0001, 0.0001, 0.2188, 0.1096, 0.0] **
max =  0.3947 | max_idx =  1
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 3684, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 477, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.129 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1294788271188736, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(5.4318, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(2.2830, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 170, Time: 2:08:11
Train F1: 0.0357, Val F1: 0.0018, Test F1: 0.0623
Epoch 17/20, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70

**pseudo_label ->  [0.2618, 0.0006, 0.0, 0.335, 0.2582, 0.1425, 0.002] **
max =  0.335 | max_idx =  3
**pseudo_label ->  [0.2074, 0.0005, 0.0, 0.4386, 0.1428, 0.2073, 0.0035] **
max =  0.4386 | max_idx =  3
**pseudo_label ->  [0.1627, 0.0005, 0.0, 0.4543, 0.1912, 0.1884, 0.0029] **
max =  0.4543 | max_idx =  3
**pseudo_label ->  [0.1498, 0.0005, 0.0, 0.491, 0.1741, 0.1809, 0.0036] **
max =  0.491 | max_idx =  3
**pseudo_label ->  [0.2336, 0.0006, 0.0, 0.386, 0.1941, 0.1816, 0.0042] **
max =  0.386 | max_idx =  3
**pseudo_label ->  [0.1827, 0.0006, 0.0, 0.3992, 0.289, 0.1247, 0.0038] **
max =  0.3992 | max_idx =  3
**pseudo_label ->  [0.1266, 0.0004, 0.0, 0.4836, 0.1757, 0.2096, 0.0039] **
max =  0.4836 | max_idx =  3
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 3708, 0, 0, 2]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 552, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.149 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.14886730909347534, nan, nan, 0.0]
loss for labeled data =>  tensor(4.7979, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.2913, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 180, Time: 2:16:36
Train F1: 0.0357, Val F1: 0.0798, Test F1: 0.0398
Epoch 18/20, Train Acc: 0.1429, Val Acc: 0.3876, Test Acc: 0.1619, Test F1(macro): 0.0398, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 2, Train Data Number: 70

**pseudo_label ->  [0.1752, 0.0025, 0.0154, 0.0101, 0.3491, 0.2426, 0.205] **
max =  0.3491 | max_idx =  4
**pseudo_label ->  [0.1675, 0.0012, 0.0099, 0.0045, 0.2692, 0.3052, 0.2425] **
max =  0.3052 | max_idx =  5
**pseudo_label ->  [0.1527, 0.002, 0.0071, 0.006, 0.2929, 0.1999, 0.3394] **
max =  0.3394 | max_idx =  6
**pseudo_label ->  [0.2145, 0.0022, 0.0169, 0.0053, 0.2245, 0.2386, 0.2981] **
max =  0.2981 | max_idx =  6
**pseudo_label ->  [0.1536, 0.0036, 0.0096, 0.0069, 0.2291, 0.2648, 0.3323] **
max =  0.3323 | max_idx =  6
**pseudo_label ->  [0.1837, 0.0034, 0.0084, 0.0076, 0.1941, 0.3357, 0.2671] **
max =  0.3357 | max_idx =  5
**pseudo_label ->  [0.193, 0.0027, 0.0102, 0.006, 0.2639, 0.25, 0.2743] **
max =  0.2743 | max_idx =  6
acc_train_cw(현재 train의 class별 acc) [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 3778, 0, 0, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 484, 0, 0, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.128 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, 0.1281101107597351, nan, nan, nan, nan, nan]
loss for labeled data =>  tensor(3.4887, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(3.2728, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 190, Time: 2:25:04
Train F1: 0.0357, Val F1: 0.0018, Test F1: 0.0623
Epoch 19/20, Train Acc: 0.1429, Val Acc: 0.0065, Test Acc: 0.2787, Test F1(macro): 0.0623, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 1, Train Data Number: 70

**pseudo_label ->  [0.1181, 0.0024, 0.0745, 0.0385, 0.1714, 0.3499, 0.2452] **
max =  0.3499 | max_idx =  5
**pseudo_label ->  [0.0724, 0.0027, 0.1072, 0.0388, 0.1248, 0.3748, 0.2793] **
max =  0.3748 | max_idx =  5
**pseudo_label ->  [0.1329, 0.0057, 0.0618, 0.0566, 0.2232, 0.3265, 0.1933] **
max =  0.3265 | max_idx =  5
**pseudo_label ->  [0.0933, 0.0024, 0.0724, 0.0222, 0.1889, 0.3927, 0.2281] **
max =  0.3927 | max_idx =  5
**pseudo_label ->  [0.1188, 0.0026, 0.1023, 0.0455, 0.1236, 0.3833, 0.2239] **
max =  0.3833 | max_idx =  5
**pseudo_label ->  [0.107, 0.0022, 0.0915, 0.0321, 0.1723, 0.3171, 0.2777] **
max =  0.3171 | max_idx =  5
**pseudo_label ->  [0.0841, 0.0023, 0.0884, 0.0335, 0.1694, 0.4372, 0.1851] **
max =  0.4372 | max_idx =  5
acc_train_cw(현재 train의 class별 acc) [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]
cw_psl_total_eval(pseudo label 클래스별 총 샘플 수):  [0, 0, 0, 3832, 0, 0, 0]
cw_psl_correct_eval(pseudo label 클래스별 맞은 샘플 수):  [0, 0, 0, 565, 0, 0, 0]
psl_acc(PSL 평가에서의 정확도):  0.147 
cw_psl_acc(클래스별 PSL 평가에서의 정확도):  [nan, nan, nan, 0.14744259417057037, nan, nan, nan]
loss for labeled data =>  tensor(2.6496, device='cuda:0', grad_fn=<NllLossBackward0>)
loss for labeled data =>  tensor(4.3563, device='cuda:0', grad_fn=<NllLossBackward0>)
Step 200, Time: 2:33:32
Train F1: 0.0357, Val F1: 0.0798, Test F1: 0.0398
Epoch 20/20, Train Acc: 0.1429, Val Acc: 0.3876, Test Acc: 0.1619, Test F1(macro): 0.0398, Total Pseudo-Labels: 5, Correct Pseudo-Labels: 0, Train Data Number: 70


Training complete!
Total training took 2:33:32 (h:mm:ss)
Load model from ./experiment/jointmatch/output/10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'python'}_net0.pth
Load model from ./experiment/jointmatch/output/10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'python'}_net1.pth
Save training statistics in:  ./experiment/jointmatch/log/unixcoder/joint_match//10_['unixcoder', 'unixcoder']_[0.0004, 0.0002]_0.7_jointmatch_20_[42]_{'python'}/training_statistics.csv


Best_step:  10 
Best_val_epoch:  1 
best_val_acc:  0.38762214983713356 
best_val_test_acc:  0.16188524590163936 
best_val_test_f1:  0.0398085159989922
Save best record in:  ./experiment/jointmatch/log/unixcoder/joint_match/summary.csv
Save best record in:  ./experiment/jointmatch/log/summary_avgrun.csv
